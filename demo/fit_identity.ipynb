{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Environment\n",
    "\n",
    "Prerequisite:\n",
    "\n",
    "- PyTorch (tested on 1.8.1/1.10.1)\n",
    "- Pyro (tested on 1.6.0)\n",
    "\n",
    "We recommend PyTorch 1.8.1, on which the current implementation of the PnP solver runs significantly faster than PyTorch 1.10.1.\n",
    "\n",
    "Install the python packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# CUDA 11.1\n",
    "%pip install torch==1.8.1+cu111 torchvision==0.9.1+cu111 torchaudio==0.8.1 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "%pip install pyro-ppl==1.6.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clone and enter this project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/tjiiv-cprg/EPro-PnP\n",
    "%cd EPro-PnP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the Identity Function\n",
    "\n",
    "Here we demonstrate the usage of EPro-PnP by fitting a simple model `out_pose = EProPnP(MLP(in_pose))` to data points generated from the indentity function $I: SE(3) \\to SE(3)$. The model takes `in_pose = [x, y, z, w, i, j, k]` as input, which is converted into a 2D-3D correspondence set by a plain MLP, and outputs the probabilistic pose through the EPro-PnP layer. 65536 data points are generated with additional noise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "\n",
    "from epropnp.epropnp import EProPnP6DoF\n",
    "from epropnp.levenberg_marquardt import LMSolver, RSLMSolver\n",
    "from epropnp.camera import PerspectiveCamera\n",
    "from epropnp.cost_fun import AdaptiveHuberPnPCost\n",
    "from epropnp.common import quaternion_to_rot_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "n_data = 65536\n",
    "batch_size = 256\n",
    "n_epoch = 10\n",
    "noise = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_points=64,  # number of 2D-3D pairs\n",
    "            mlp_layers=[1024],  # a single hidden layer\n",
    "            epropnp=EProPnP6DoF(\n",
    "                mc_samples=512,\n",
    "                num_iter=4,\n",
    "                solver=LMSolver(\n",
    "                    dof=6,\n",
    "                    num_iter=10,\n",
    "                    initial_trust_region_radius=1e3,\n",
    "                    init_solver=RSLMSolver(\n",
    "                        dof=6,\n",
    "                        num_points=8,\n",
    "                        num_proposals=128,\n",
    "                        num_iter=5,\n",
    "                        initial_trust_region_radius=1e3))),\n",
    "            camera=PerspectiveCamera(),\n",
    "            cost_fun=AdaptiveHuberPnPCost(\n",
    "                relative_delta=0.5)):\n",
    "        super().__init__()\n",
    "        self.num_points = num_points\n",
    "        mlp_layers = [7] + mlp_layers\n",
    "        mlp = []\n",
    "        for i in range(len(mlp_layers) - 1):\n",
    "            mlp.append(nn.Linear(mlp_layers[i], mlp_layers[i + 1]))\n",
    "            mlp.append(nn.LeakyReLU())\n",
    "        mlp.append(nn.Linear(mlp_layers[-1], num_points * (3 + 2 + 2)))\n",
    "        self.mlp = nn.Sequential(*mlp)\n",
    "        # Here we use static weight_scale because the data noise is homoscedastic\n",
    "        self.log_weight_scale = nn.Parameter(torch.zeros(2))\n",
    "        self.epropnp = epropnp\n",
    "        self.camera = camera\n",
    "        self.cost_fun = cost_fun\n",
    "\n",
    "    def forward_correspondence(self, in_pose):\n",
    "        x3d, x2d, w2d = self.mlp(in_pose).reshape(-1, self.num_points, 7).split([3, 2, 2], dim=-1)\n",
    "        w2d = (w2d.log_softmax(dim=-2) + self.log_weight_scale).exp()\n",
    "        # equivalant to:\n",
    "        # w2d = w2d.softmax(dim=-2) * self.log_weight_scale.exp()\n",
    "        # alternatively we can use mean substract instead of log_softmax, both serves the purpose of \n",
    "        # normalizing scale of the weights, e.g.:\n",
    "        # w2d = (w2d - w2d.mean(dim=-2, keepdim=True) - math.log(w2d.size(-2))\n",
    "        #        + self.log_weight_scale).exp()\n",
    "        return x3d, x2d, w2d\n",
    "\n",
    "    def forward_train(self, in_pose, cam_mats, out_pose):\n",
    "        x3d, x2d, w2d = self.forward_correspondence(in_pose)\n",
    "        self.camera.set_param(cam_mats)\n",
    "        self.cost_fun.set_param(x2d.detach(), w2d)  # compute dynamic delta\n",
    "        pose_opt, cost, pose_opt_plus, pose_samples, pose_sample_logweights, cost_tgt = self.epropnp.monte_carlo_forward(\n",
    "            x3d,\n",
    "            x2d,\n",
    "            w2d,\n",
    "            self.camera,\n",
    "            self.cost_fun,\n",
    "            pose_init=out_pose,\n",
    "            force_init_solve=True,\n",
    "            with_pose_opt_plus=True)  # True for derivative regularization loss\n",
    "        norm_factor = model.log_weight_scale.detach().exp().mean()\n",
    "        return pose_opt, cost, pose_opt_plus, pose_samples, pose_sample_logweights, cost_tgt, norm_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MonteCarloPoseLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, init_norm_factor=1.0, momentum=0.1):\n",
    "        super(MonteCarloPoseLoss, self).__init__()\n",
    "        self.register_buffer('norm_factor', torch.tensor(init_norm_factor, dtype=torch.float))\n",
    "        self.momentum = momentum\n",
    "\n",
    "    def forward(self, pose_sample_logweights, cost_target, norm_factor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            pose_sample_logweights: Shape (mc_samples, num_obj)\n",
    "            cost_target: Shape (num_obj, )\n",
    "            norm_factor: Shape ()\n",
    "        \"\"\"\n",
    "        if self.training:\n",
    "            with torch.no_grad():\n",
    "                self.norm_factor.mul_(\n",
    "                    1 - self.momentum).add_(self.momentum * norm_factor)\n",
    "\n",
    "        loss_tgt = cost_target\n",
    "        loss_pred = torch.logsumexp(pose_sample_logweights, dim=0)  # (num_obj, )\n",
    "\n",
    "        loss_pose = loss_tgt + loss_pred  # (num_obj, )\n",
    "        loss_pose[torch.isnan(loss_pose)] = 0\n",
    "        loss_pose = loss_pose.mean() / self.norm_factor\n",
    "\n",
    "        return loss_pose.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data points\n",
    "in_pose = torch.randn([n_data, 7], device=device)\n",
    "in_pose[:, 2] += 5  # positive z, avoid points falling behind the camera plane\n",
    "in_pose[:, 3:] = F.normalize(in_pose[:, 3:], dim=-1)  # normalize to unit quaternion\n",
    "\n",
    "out_pose = in_pose + torch.randn([n_data, 7], device=device) * noise\n",
    "out_pose[:, 3:] = F.normalize(out_pose[:, 3:], dim=-1)  # normalize to unit quaternion\n",
    "\n",
    "cam_mats = torch.eye(3, device=device)\n",
    "\n",
    "dataset = Data.TensorDataset(in_pose, out_pose)\n",
    "loader = Data.DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True)\n",
    "\n",
    "# setup model\n",
    "model = Model().to(device)\n",
    "mc_loss_fun = MonteCarloPoseLoss().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam([\n",
    "                {'params': model.mlp.parameters()},\n",
    "                {'params': model.log_weight_scale, 'lr': 1e-2}\n",
    "            ], lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/hdd/home/chenhansheng/src/EPro-PnP-rel/venv/lib/python3.8/site-packages/torch/distributions/distribution.py:271: UserWarning: <class 'epropnp.distributions.AngularCentralGaussian'> does not define `support` to enable sample validation. Please initialize the distribution with `validate_args=False` to turn off validation.\n",
      "  warnings.warn(f'{self.__class__} does not define `support` to enable ' +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 1/256 - loss_mc=33.2071, loss_t=1.6915, loss_r=1.4542, loss=33.5217, norm_factor=1.0000, grad_norm=3.9409\n",
      "Epoch 1: 2/256 - loss_mc=34.8328, loss_t=2.1324, loss_r=1.5369, loss=35.1998, norm_factor=1.0101, grad_norm=1.4019\n",
      "Epoch 1: 3/256 - loss_mc=32.6467, loss_t=1.7092, loss_r=1.5730, loss=32.9749, norm_factor=1.0188, grad_norm=2.4692\n",
      "Epoch 1: 4/256 - loss_mc=33.1540, loss_t=1.3633, loss_r=1.5264, loss=33.4429, norm_factor=1.0277, grad_norm=2.2266\n",
      "Epoch 1: 5/256 - loss_mc=33.8417, loss_t=1.1837, loss_r=1.4941, loss=34.1095, norm_factor=1.0368, grad_norm=0.8866\n",
      "Epoch 1: 6/256 - loss_mc=33.7920, loss_t=1.4051, loss_r=1.4958, loss=34.0820, norm_factor=1.0457, grad_norm=1.0419\n",
      "Epoch 1: 7/256 - loss_mc=33.4611, loss_t=1.2668, loss_r=1.5197, loss=33.7398, norm_factor=1.0550, grad_norm=0.9438\n",
      "Epoch 1: 8/256 - loss_mc=32.9867, loss_t=1.0734, loss_r=1.4590, loss=33.2400, norm_factor=1.0640, grad_norm=0.8413\n",
      "Epoch 1: 9/256 - loss_mc=32.8414, loss_t=0.9253, loss_r=1.5326, loss=33.0872, norm_factor=1.0733, grad_norm=1.3487\n",
      "Epoch 1: 10/256 - loss_mc=32.5836, loss_t=0.8723, loss_r=1.5151, loss=32.8223, norm_factor=1.0828, grad_norm=1.4119\n",
      "Epoch 1: 11/256 - loss_mc=32.3908, loss_t=0.7318, loss_r=1.5187, loss=32.6158, norm_factor=1.0923, grad_norm=0.6427\n",
      "Epoch 1: 12/256 - loss_mc=32.0253, loss_t=0.6717, loss_r=1.5009, loss=32.2426, norm_factor=1.1019, grad_norm=1.1065\n",
      "Epoch 1: 13/256 - loss_mc=32.0988, loss_t=0.6407, loss_r=1.5511, loss=32.3180, norm_factor=1.1117, grad_norm=1.1939\n",
      "Epoch 1: 14/256 - loss_mc=31.2080, loss_t=0.5617, loss_r=1.5194, loss=31.4161, norm_factor=1.1216, grad_norm=0.7807\n",
      "Epoch 1: 15/256 - loss_mc=31.0222, loss_t=0.6245, loss_r=1.4731, loss=31.2319, norm_factor=1.1317, grad_norm=2.3528\n",
      "Epoch 1: 16/256 - loss_mc=31.1110, loss_t=0.4665, loss_r=1.5385, loss=31.3115, norm_factor=1.1415, grad_norm=0.9125\n",
      "Epoch 1: 17/256 - loss_mc=30.8170, loss_t=0.5009, loss_r=1.4364, loss=31.0108, norm_factor=1.1515, grad_norm=2.4699\n",
      "Epoch 1: 18/256 - loss_mc=30.6255, loss_t=0.3854, loss_r=1.4966, loss=30.8137, norm_factor=1.1608, grad_norm=1.1062\n",
      "Epoch 1: 19/256 - loss_mc=30.0675, loss_t=0.3944, loss_r=1.4382, loss=30.2508, norm_factor=1.1703, grad_norm=1.9240\n",
      "Epoch 1: 20/256 - loss_mc=30.0564, loss_t=0.3578, loss_r=1.5005, loss=30.2422, norm_factor=1.1793, grad_norm=1.3818\n",
      "Epoch 1: 21/256 - loss_mc=29.7628, loss_t=0.3277, loss_r=1.4358, loss=29.9392, norm_factor=1.1888, grad_norm=1.0688\n",
      "Epoch 1: 22/256 - loss_mc=29.7435, loss_t=0.3300, loss_r=1.4813, loss=29.9247, norm_factor=1.1982, grad_norm=2.5301\n",
      "Epoch 1: 23/256 - loss_mc=29.2333, loss_t=0.2452, loss_r=1.5086, loss=29.4087, norm_factor=1.2069, grad_norm=0.5743\n",
      "Epoch 1: 24/256 - loss_mc=29.0467, loss_t=0.2363, loss_r=1.4723, loss=29.2176, norm_factor=1.2158, grad_norm=1.8982\n",
      "Epoch 1: 25/256 - loss_mc=28.9328, loss_t=0.2006, loss_r=1.5284, loss=29.1057, norm_factor=1.2245, grad_norm=1.4914\n",
      "Epoch 1: 26/256 - loss_mc=28.7569, loss_t=0.2293, loss_r=1.4655, loss=28.9264, norm_factor=1.2333, grad_norm=3.0076\n",
      "Epoch 1: 27/256 - loss_mc=28.3174, loss_t=0.1604, loss_r=1.4912, loss=28.4826, norm_factor=1.2418, grad_norm=1.1089\n",
      "Epoch 1: 28/256 - loss_mc=28.1462, loss_t=0.1918, loss_r=1.4986, loss=28.3152, norm_factor=1.2507, grad_norm=2.1875\n",
      "Epoch 1: 29/256 - loss_mc=27.8516, loss_t=0.1644, loss_r=1.5069, loss=28.0187, norm_factor=1.2595, grad_norm=1.9132\n",
      "Epoch 1: 30/256 - loss_mc=27.8872, loss_t=0.1611, loss_r=1.4416, loss=28.0475, norm_factor=1.2686, grad_norm=1.9853\n",
      "Epoch 1: 31/256 - loss_mc=27.3214, loss_t=0.1448, loss_r=1.4473, loss=27.4806, norm_factor=1.2777, grad_norm=1.1093\n",
      "Epoch 1: 32/256 - loss_mc=27.1703, loss_t=0.1354, loss_r=1.5033, loss=27.3341, norm_factor=1.2867, grad_norm=1.0217\n",
      "Epoch 1: 33/256 - loss_mc=26.9702, loss_t=0.1489, loss_r=1.4803, loss=27.1332, norm_factor=1.2960, grad_norm=1.4816\n",
      "Epoch 1: 34/256 - loss_mc=26.7767, loss_t=0.1378, loss_r=1.3804, loss=26.9285, norm_factor=1.3055, grad_norm=0.8480\n",
      "Epoch 1: 35/256 - loss_mc=26.7110, loss_t=0.1340, loss_r=1.4463, loss=26.8691, norm_factor=1.3149, grad_norm=1.2338\n",
      "Epoch 1: 36/256 - loss_mc=26.5086, loss_t=0.1196, loss_r=1.4142, loss=26.6620, norm_factor=1.3247, grad_norm=0.5400\n",
      "Epoch 1: 37/256 - loss_mc=26.0482, loss_t=0.1123, loss_r=1.4334, loss=26.2028, norm_factor=1.3345, grad_norm=0.8404\n",
      "Epoch 1: 38/256 - loss_mc=25.9528, loss_t=0.1201, loss_r=1.4596, loss=26.1108, norm_factor=1.3445, grad_norm=0.9883\n",
      "Epoch 1: 39/256 - loss_mc=25.7448, loss_t=0.1298, loss_r=1.3932, loss=25.8971, norm_factor=1.3545, grad_norm=0.9519\n",
      "Epoch 1: 40/256 - loss_mc=25.4605, loss_t=0.1121, loss_r=1.3936, loss=25.6111, norm_factor=1.3647, grad_norm=0.8169\n",
      "Epoch 1: 41/256 - loss_mc=25.3290, loss_t=0.1147, loss_r=1.3738, loss=25.4778, norm_factor=1.3752, grad_norm=0.9681\n",
      "Epoch 1: 42/256 - loss_mc=25.1549, loss_t=0.1130, loss_r=1.4035, loss=25.3065, norm_factor=1.3856, grad_norm=0.6902\n",
      "Epoch 1: 43/256 - loss_mc=24.6239, loss_t=0.0993, loss_r=1.4193, loss=24.7757, norm_factor=1.3962, grad_norm=0.6157\n",
      "Epoch 1: 44/256 - loss_mc=24.4798, loss_t=0.0957, loss_r=1.3991, loss=24.6293, norm_factor=1.4070, grad_norm=0.4367\n",
      "Epoch 1: 45/256 - loss_mc=24.2938, loss_t=0.1067, loss_r=1.3605, loss=24.4405, norm_factor=1.4183, grad_norm=0.5027\n",
      "Epoch 1: 46/256 - loss_mc=24.1613, loss_t=0.1092, loss_r=1.4434, loss=24.3166, norm_factor=1.4300, grad_norm=0.6099\n",
      "Epoch 1: 47/256 - loss_mc=24.0958, loss_t=0.1046, loss_r=1.3617, loss=24.2424, norm_factor=1.4422, grad_norm=0.7700\n",
      "Epoch 1: 48/256 - loss_mc=23.7494, loss_t=0.1123, loss_r=1.3718, loss=23.8978, norm_factor=1.4547, grad_norm=0.5326\n",
      "Epoch 1: 49/256 - loss_mc=23.5407, loss_t=0.0964, loss_r=1.3733, loss=23.6877, norm_factor=1.4670, grad_norm=0.5586\n",
      "Epoch 1: 50/256 - loss_mc=23.4931, loss_t=0.0808, loss_r=1.3455, loss=23.6358, norm_factor=1.4796, grad_norm=0.3308\n",
      "Epoch 1: 51/256 - loss_mc=23.2353, loss_t=0.0782, loss_r=1.3578, loss=23.3789, norm_factor=1.4926, grad_norm=0.7449\n",
      "Epoch 1: 52/256 - loss_mc=23.1734, loss_t=0.0873, loss_r=1.3984, loss=23.3220, norm_factor=1.5058, grad_norm=0.6548\n",
      "Epoch 1: 53/256 - loss_mc=23.0042, loss_t=0.0797, loss_r=1.3481, loss=23.1470, norm_factor=1.5192, grad_norm=0.7117\n",
      "Epoch 1: 54/256 - loss_mc=22.3668, loss_t=0.0728, loss_r=1.3345, loss=22.5075, norm_factor=1.5327, grad_norm=0.7638\n",
      "Epoch 1: 55/256 - loss_mc=22.4864, loss_t=0.0845, loss_r=1.4018, loss=22.6350, norm_factor=1.5463, grad_norm=0.8569\n",
      "Epoch 1: 56/256 - loss_mc=22.1477, loss_t=0.0643, loss_r=1.3867, loss=22.2928, norm_factor=1.5601, grad_norm=0.6801\n",
      "Epoch 1: 57/256 - loss_mc=21.8047, loss_t=0.0786, loss_r=1.3236, loss=21.9449, norm_factor=1.5740, grad_norm=0.6581\n",
      "Epoch 1: 58/256 - loss_mc=21.5387, loss_t=0.0843, loss_r=1.3451, loss=21.6816, norm_factor=1.5879, grad_norm=1.0391\n",
      "Epoch 1: 59/256 - loss_mc=21.5870, loss_t=0.0825, loss_r=1.2986, loss=21.7251, norm_factor=1.6024, grad_norm=0.5647\n",
      "Epoch 1: 60/256 - loss_mc=21.4202, loss_t=0.0820, loss_r=1.3438, loss=21.5628, norm_factor=1.6171, grad_norm=0.8181\n",
      "Epoch 1: 61/256 - loss_mc=21.2207, loss_t=0.0854, loss_r=1.3039, loss=21.3596, norm_factor=1.6319, grad_norm=0.5512\n",
      "Epoch 1: 62/256 - loss_mc=20.9687, loss_t=0.0814, loss_r=1.3303, loss=21.1098, norm_factor=1.6471, grad_norm=1.0416\n",
      "Epoch 1: 63/256 - loss_mc=20.6070, loss_t=0.0909, loss_r=1.3020, loss=20.7463, norm_factor=1.6630, grad_norm=0.9824\n",
      "Epoch 1: 64/256 - loss_mc=20.6937, loss_t=0.0788, loss_r=1.3520, loss=20.8368, norm_factor=1.6794, grad_norm=0.9801\n",
      "Epoch 1: 65/256 - loss_mc=20.3524, loss_t=0.0881, loss_r=1.3674, loss=20.4980, norm_factor=1.6957, grad_norm=1.0226\n",
      "Epoch 1: 66/256 - loss_mc=19.7946, loss_t=0.0853, loss_r=1.4169, loss=19.9448, norm_factor=1.7119, grad_norm=1.2578\n",
      "Epoch 1: 67/256 - loss_mc=19.7875, loss_t=0.0808, loss_r=1.2967, loss=19.9253, norm_factor=1.7283, grad_norm=1.0601\n",
      "Epoch 1: 68/256 - loss_mc=19.8361, loss_t=0.0755, loss_r=1.3539, loss=19.9790, norm_factor=1.7458, grad_norm=1.0312\n",
      "Epoch 1: 69/256 - loss_mc=19.5693, loss_t=0.1030, loss_r=1.2903, loss=19.7086, norm_factor=1.7638, grad_norm=1.5807\n",
      "Epoch 1: 70/256 - loss_mc=19.2524, loss_t=0.0886, loss_r=1.3884, loss=19.4001, norm_factor=1.7820, grad_norm=0.9734\n",
      "Epoch 1: 71/256 - loss_mc=19.1894, loss_t=0.0900, loss_r=1.3062, loss=19.3291, norm_factor=1.8002, grad_norm=1.6733\n",
      "Epoch 1: 72/256 - loss_mc=18.7339, loss_t=0.0743, loss_r=1.3200, loss=18.8733, norm_factor=1.8188, grad_norm=0.4495\n",
      "Epoch 1: 73/256 - loss_mc=18.6915, loss_t=0.1030, loss_r=1.3357, loss=18.8354, norm_factor=1.8376, grad_norm=2.0412\n",
      "Epoch 1: 74/256 - loss_mc=18.3340, loss_t=0.0667, loss_r=1.3786, loss=18.4785, norm_factor=1.8562, grad_norm=0.3498\n",
      "Epoch 1: 75/256 - loss_mc=18.1288, loss_t=0.0794, loss_r=1.3255, loss=18.2693, norm_factor=1.8749, grad_norm=1.3852\n",
      "Epoch 1: 76/256 - loss_mc=17.9400, loss_t=0.0724, loss_r=1.3114, loss=18.0784, norm_factor=1.8942, grad_norm=0.6778\n",
      "Epoch 1: 77/256 - loss_mc=18.1154, loss_t=0.0935, loss_r=1.3780, loss=18.2625, norm_factor=1.9135, grad_norm=1.5954\n",
      "Epoch 1: 78/256 - loss_mc=17.7420, loss_t=0.0811, loss_r=1.3248, loss=17.8826, norm_factor=1.9325, grad_norm=0.5529\n",
      "Epoch 1: 79/256 - loss_mc=17.4783, loss_t=0.0748, loss_r=1.3623, loss=17.6220, norm_factor=1.9515, grad_norm=0.9652\n",
      "Epoch 1: 80/256 - loss_mc=17.2243, loss_t=0.0625, loss_r=1.3116, loss=17.3617, norm_factor=1.9708, grad_norm=0.5380\n",
      "Epoch 1: 81/256 - loss_mc=17.1637, loss_t=0.0756, loss_r=1.2358, loss=17.2948, norm_factor=1.9902, grad_norm=0.9606\n",
      "Epoch 1: 82/256 - loss_mc=16.9281, loss_t=0.0725, loss_r=1.2734, loss=17.0627, norm_factor=2.0095, grad_norm=0.6556\n",
      "Epoch 1: 83/256 - loss_mc=16.5103, loss_t=0.0630, loss_r=1.2905, loss=16.6457, norm_factor=2.0292, grad_norm=0.7644\n",
      "Epoch 1: 84/256 - loss_mc=16.5775, loss_t=0.0750, loss_r=1.3062, loss=16.7157, norm_factor=2.0489, grad_norm=0.8821\n",
      "Epoch 1: 85/256 - loss_mc=16.5256, loss_t=0.0852, loss_r=1.3200, loss=16.6661, norm_factor=2.0689, grad_norm=0.7782\n",
      "Epoch 1: 86/256 - loss_mc=16.1245, loss_t=0.0558, loss_r=1.2368, loss=16.2537, norm_factor=2.0896, grad_norm=0.6403\n",
      "Epoch 1: 87/256 - loss_mc=16.1862, loss_t=0.0897, loss_r=1.3347, loss=16.3286, norm_factor=2.1106, grad_norm=0.8612\n",
      "Epoch 1: 88/256 - loss_mc=15.8929, loss_t=0.0790, loss_r=1.2251, loss=16.0233, norm_factor=2.1318, grad_norm=1.0995\n",
      "Epoch 1: 89/256 - loss_mc=15.6122, loss_t=0.0744, loss_r=1.2534, loss=15.7450, norm_factor=2.1534, grad_norm=0.9854\n",
      "Epoch 1: 90/256 - loss_mc=15.5004, loss_t=0.0714, loss_r=1.1911, loss=15.6267, norm_factor=2.1756, grad_norm=1.0994\n",
      "Epoch 1: 91/256 - loss_mc=15.3299, loss_t=0.0875, loss_r=1.3317, loss=15.4718, norm_factor=2.1979, grad_norm=0.5063\n",
      "Epoch 1: 92/256 - loss_mc=15.1279, loss_t=0.0754, loss_r=1.2877, loss=15.2642, norm_factor=2.2204, grad_norm=1.6489\n",
      "Epoch 1: 93/256 - loss_mc=15.1283, loss_t=0.0839, loss_r=1.3092, loss=15.2676, norm_factor=2.2437, grad_norm=0.5595\n",
      "Epoch 1: 94/256 - loss_mc=14.8376, loss_t=0.0881, loss_r=1.2108, loss=14.9675, norm_factor=2.2671, grad_norm=1.7346\n",
      "Epoch 1: 95/256 - loss_mc=14.7286, loss_t=0.0653, loss_r=1.2084, loss=14.8560, norm_factor=2.2909, grad_norm=0.5778\n",
      "Epoch 1: 96/256 - loss_mc=14.3927, loss_t=0.0888, loss_r=1.1967, loss=14.5212, norm_factor=2.3150, grad_norm=2.1181\n",
      "Epoch 1: 97/256 - loss_mc=14.4129, loss_t=0.0825, loss_r=1.2271, loss=14.5439, norm_factor=2.3390, grad_norm=0.7057\n",
      "Epoch 1: 98/256 - loss_mc=14.1271, loss_t=0.0892, loss_r=1.2149, loss=14.2575, norm_factor=2.3637, grad_norm=2.0178\n",
      "Epoch 1: 99/256 - loss_mc=13.9364, loss_t=0.0630, loss_r=1.2474, loss=14.0675, norm_factor=2.3891, grad_norm=0.5139\n",
      "Epoch 1: 100/256 - loss_mc=13.6915, loss_t=0.0836, loss_r=1.1777, loss=13.8176, norm_factor=2.4146, grad_norm=1.7869\n",
      "Epoch 1: 101/256 - loss_mc=13.8434, loss_t=0.0629, loss_r=1.2942, loss=13.9791, norm_factor=2.4400, grad_norm=0.4933\n",
      "Epoch 1: 102/256 - loss_mc=13.5074, loss_t=0.0857, loss_r=1.2410, loss=13.6401, norm_factor=2.4669, grad_norm=1.4930\n",
      "Epoch 1: 103/256 - loss_mc=13.3392, loss_t=0.0715, loss_r=1.1779, loss=13.4641, norm_factor=2.4938, grad_norm=0.5645\n",
      "Epoch 1: 104/256 - loss_mc=13.1459, loss_t=0.0650, loss_r=1.1695, loss=13.2694, norm_factor=2.5214, grad_norm=0.9622\n",
      "Epoch 1: 105/256 - loss_mc=12.9417, loss_t=0.0663, loss_r=1.2145, loss=13.0698, norm_factor=2.5490, grad_norm=1.1707\n",
      "Epoch 1: 106/256 - loss_mc=12.7953, loss_t=0.0769, loss_r=1.2293, loss=12.9259, norm_factor=2.5769, grad_norm=1.3459\n",
      "Epoch 1: 107/256 - loss_mc=12.9375, loss_t=0.0738, loss_r=1.1711, loss=13.0620, norm_factor=2.6046, grad_norm=1.6148\n",
      "Epoch 1: 108/256 - loss_mc=12.5980, loss_t=0.0679, loss_r=1.1494, loss=12.7197, norm_factor=2.6327, grad_norm=1.1740\n",
      "Epoch 1: 109/256 - loss_mc=12.4178, loss_t=0.0796, loss_r=1.1477, loss=12.5405, norm_factor=2.6608, grad_norm=1.6881\n",
      "Epoch 1: 110/256 - loss_mc=12.4094, loss_t=0.0644, loss_r=1.1867, loss=12.5345, norm_factor=2.6889, grad_norm=0.6052\n",
      "Epoch 1: 111/256 - loss_mc=12.1884, loss_t=0.0772, loss_r=1.1297, loss=12.3091, norm_factor=2.7172, grad_norm=0.9601\n",
      "Epoch 1: 112/256 - loss_mc=12.0621, loss_t=0.0758, loss_r=1.1549, loss=12.1851, norm_factor=2.7458, grad_norm=1.4513\n",
      "Epoch 1: 113/256 - loss_mc=11.8524, loss_t=0.0741, loss_r=1.0875, loss=11.9686, norm_factor=2.7741, grad_norm=1.4817\n",
      "Epoch 1: 114/256 - loss_mc=11.6939, loss_t=0.0778, loss_r=1.1256, loss=11.8142, norm_factor=2.8027, grad_norm=1.5097\n",
      "Epoch 1: 115/256 - loss_mc=11.7926, loss_t=0.0873, loss_r=1.0702, loss=11.9084, norm_factor=2.8318, grad_norm=1.6529\n",
      "Epoch 1: 116/256 - loss_mc=11.6123, loss_t=0.0766, loss_r=1.1008, loss=11.7301, norm_factor=2.8617, grad_norm=0.8266\n",
      "Epoch 1: 117/256 - loss_mc=11.3998, loss_t=0.0789, loss_r=1.1236, loss=11.5201, norm_factor=2.8916, grad_norm=1.0395\n",
      "Epoch 1: 118/256 - loss_mc=11.1900, loss_t=0.0672, loss_r=1.0377, loss=11.3005, norm_factor=2.9221, grad_norm=1.7528\n",
      "Epoch 1: 119/256 - loss_mc=11.1143, loss_t=0.0747, loss_r=1.0697, loss=11.2288, norm_factor=2.9527, grad_norm=0.7258\n",
      "Epoch 1: 120/256 - loss_mc=11.1019, loss_t=0.1067, loss_r=1.0324, loss=11.2158, norm_factor=2.9838, grad_norm=1.7891\n",
      "Epoch 1: 121/256 - loss_mc=10.8964, loss_t=0.0874, loss_r=1.0459, loss=11.0097, norm_factor=3.0148, grad_norm=0.9118\n",
      "Epoch 1: 122/256 - loss_mc=10.8054, loss_t=0.0751, loss_r=0.9914, loss=10.9121, norm_factor=3.0459, grad_norm=0.9840\n",
      "Epoch 1: 123/256 - loss_mc=10.5307, loss_t=0.0785, loss_r=1.0808, loss=10.6467, norm_factor=3.0776, grad_norm=1.0157\n",
      "Epoch 1: 124/256 - loss_mc=10.5955, loss_t=0.0974, loss_r=1.1114, loss=10.7164, norm_factor=3.1092, grad_norm=0.7271\n",
      "Epoch 1: 125/256 - loss_mc=10.4345, loss_t=0.0882, loss_r=1.0132, loss=10.5446, norm_factor=3.1411, grad_norm=1.0114\n",
      "Epoch 1: 126/256 - loss_mc=10.2985, loss_t=0.0687, loss_r=0.9869, loss=10.4041, norm_factor=3.1733, grad_norm=0.5986\n",
      "Epoch 1: 127/256 - loss_mc=10.0444, loss_t=0.0991, loss_r=0.9859, loss=10.1530, norm_factor=3.2055, grad_norm=1.2798\n",
      "Epoch 1: 128/256 - loss_mc=9.9971, loss_t=0.0905, loss_r=0.9454, loss=10.1007, norm_factor=3.2383, grad_norm=1.3032\n",
      "Epoch 1: 129/256 - loss_mc=9.9854, loss_t=0.0825, loss_r=0.8827, loss=10.0819, norm_factor=3.2712, grad_norm=0.8055\n",
      "Epoch 1: 130/256 - loss_mc=9.7617, loss_t=0.0781, loss_r=0.9312, loss=9.8626, norm_factor=3.3051, grad_norm=0.6459\n",
      "Epoch 1: 131/256 - loss_mc=9.6712, loss_t=0.0972, loss_r=0.9394, loss=9.7748, norm_factor=3.3401, grad_norm=1.6336\n",
      "Epoch 1: 132/256 - loss_mc=9.5067, loss_t=0.0938, loss_r=0.9780, loss=9.6139, norm_factor=3.3760, grad_norm=1.5611\n",
      "Epoch 1: 133/256 - loss_mc=9.3946, loss_t=0.0922, loss_r=0.9329, loss=9.4971, norm_factor=3.4119, grad_norm=1.1249\n",
      "Epoch 1: 134/256 - loss_mc=9.3979, loss_t=0.0909, loss_r=0.9278, loss=9.4997, norm_factor=3.4476, grad_norm=1.8086\n",
      "Epoch 1: 135/256 - loss_mc=9.2695, loss_t=0.0845, loss_r=0.9109, loss=9.3691, norm_factor=3.4836, grad_norm=0.8440\n",
      "Epoch 1: 136/256 - loss_mc=9.2423, loss_t=0.0792, loss_r=0.9361, loss=9.3438, norm_factor=3.5203, grad_norm=0.7623\n",
      "Epoch 1: 137/256 - loss_mc=8.9789, loss_t=0.0867, loss_r=0.9333, loss=9.0809, norm_factor=3.5588, grad_norm=0.9037\n",
      "Epoch 1: 138/256 - loss_mc=8.9350, loss_t=0.0852, loss_r=0.8021, loss=9.0237, norm_factor=3.5968, grad_norm=1.1459\n",
      "Epoch 1: 139/256 - loss_mc=8.9362, loss_t=0.1084, loss_r=0.8463, loss=9.0317, norm_factor=3.6352, grad_norm=1.9050\n",
      "Epoch 1: 140/256 - loss_mc=8.7640, loss_t=0.0926, loss_r=0.8875, loss=8.8620, norm_factor=3.6735, grad_norm=1.1468\n",
      "Epoch 1: 141/256 - loss_mc=8.6472, loss_t=0.1038, loss_r=0.8952, loss=8.7471, norm_factor=3.7117, grad_norm=1.4744\n",
      "Epoch 1: 142/256 - loss_mc=8.5033, loss_t=0.1041, loss_r=0.8691, loss=8.6006, norm_factor=3.7499, grad_norm=0.8473\n",
      "Epoch 1: 143/256 - loss_mc=8.3835, loss_t=0.0988, loss_r=0.9264, loss=8.4861, norm_factor=3.7901, grad_norm=0.7525\n",
      "Epoch 1: 144/256 - loss_mc=8.3284, loss_t=0.1079, loss_r=0.9135, loss=8.4305, norm_factor=3.8299, grad_norm=1.4648\n",
      "Epoch 1: 145/256 - loss_mc=8.2380, loss_t=0.0976, loss_r=0.7910, loss=8.3269, norm_factor=3.8701, grad_norm=1.3671\n",
      "Epoch 1: 146/256 - loss_mc=8.1209, loss_t=0.0999, loss_r=0.8476, loss=8.2156, norm_factor=3.9108, grad_norm=1.2310\n",
      "Epoch 1: 147/256 - loss_mc=8.0010, loss_t=0.0969, loss_r=0.8789, loss=8.0986, norm_factor=3.9524, grad_norm=1.3594\n",
      "Epoch 1: 148/256 - loss_mc=7.8912, loss_t=0.1058, loss_r=0.8161, loss=7.9834, norm_factor=3.9942, grad_norm=1.0441\n",
      "Epoch 1: 149/256 - loss_mc=7.7844, loss_t=0.1162, loss_r=0.8278, loss=7.8788, norm_factor=4.0362, grad_norm=1.4873\n",
      "Epoch 1: 150/256 - loss_mc=7.8052, loss_t=0.0888, loss_r=0.8018, loss=7.8943, norm_factor=4.0792, grad_norm=0.9271\n",
      "Epoch 1: 151/256 - loss_mc=7.6951, loss_t=0.1233, loss_r=0.7677, loss=7.7842, norm_factor=4.1226, grad_norm=1.0809\n",
      "Epoch 1: 152/256 - loss_mc=7.5920, loss_t=0.1211, loss_r=0.9090, loss=7.6950, norm_factor=4.1668, grad_norm=1.9628\n",
      "Epoch 1: 153/256 - loss_mc=7.5010, loss_t=0.0889, loss_r=0.8258, loss=7.5925, norm_factor=4.2114, grad_norm=0.9037\n",
      "Epoch 1: 154/256 - loss_mc=7.3450, loss_t=0.1225, loss_r=0.8088, loss=7.4381, norm_factor=4.2572, grad_norm=2.5303\n",
      "Epoch 1: 155/256 - loss_mc=7.4102, loss_t=0.1349, loss_r=0.8393, loss=7.5077, norm_factor=4.3032, grad_norm=1.2672\n",
      "Epoch 1: 156/256 - loss_mc=7.2582, loss_t=0.0898, loss_r=0.8385, loss=7.3510, norm_factor=4.3503, grad_norm=1.1697\n",
      "Epoch 1: 157/256 - loss_mc=7.1121, loss_t=0.0986, loss_r=0.7992, loss=7.2019, norm_factor=4.3975, grad_norm=1.7825\n",
      "Epoch 1: 158/256 - loss_mc=7.0161, loss_t=0.1142, loss_r=0.7841, loss=7.1059, norm_factor=4.4453, grad_norm=1.4101\n",
      "Epoch 1: 159/256 - loss_mc=7.0060, loss_t=0.1165, loss_r=0.7863, loss=7.0963, norm_factor=4.4936, grad_norm=1.3289\n",
      "Epoch 1: 160/256 - loss_mc=6.8625, loss_t=0.1217, loss_r=0.6928, loss=6.9440, norm_factor=4.5426, grad_norm=1.8584\n",
      "Epoch 1: 161/256 - loss_mc=6.8362, loss_t=0.1488, loss_r=0.7795, loss=6.9290, norm_factor=4.5918, grad_norm=1.5403\n",
      "Epoch 1: 162/256 - loss_mc=6.6543, loss_t=0.1111, loss_r=0.7431, loss=6.7397, norm_factor=4.6412, grad_norm=1.1102\n",
      "Epoch 1: 163/256 - loss_mc=6.6356, loss_t=0.1294, loss_r=0.7871, loss=6.7273, norm_factor=4.6909, grad_norm=1.4511\n",
      "Epoch 1: 164/256 - loss_mc=6.4978, loss_t=0.1174, loss_r=0.7488, loss=6.5844, norm_factor=4.7404, grad_norm=1.2769\n",
      "Epoch 1: 165/256 - loss_mc=6.4296, loss_t=0.1238, loss_r=0.6465, loss=6.5067, norm_factor=4.7904, grad_norm=1.3218\n",
      "Epoch 1: 166/256 - loss_mc=6.4138, loss_t=0.1460, loss_r=0.7423, loss=6.5026, norm_factor=4.8413, grad_norm=1.3043\n",
      "Epoch 1: 167/256 - loss_mc=6.3959, loss_t=0.1541, loss_r=0.7268, loss=6.4840, norm_factor=4.8936, grad_norm=1.4661\n",
      "Epoch 1: 168/256 - loss_mc=6.3507, loss_t=0.1658, loss_r=0.7071, loss=6.4380, norm_factor=4.9474, grad_norm=1.0897\n",
      "Epoch 1: 169/256 - loss_mc=6.0876, loss_t=0.1447, loss_r=0.6304, loss=6.1651, norm_factor=5.0022, grad_norm=1.7858\n",
      "Epoch 1: 170/256 - loss_mc=6.1158, loss_t=0.1242, loss_r=0.6199, loss=6.1902, norm_factor=5.0567, grad_norm=0.9579\n",
      "Epoch 1: 171/256 - loss_mc=6.0137, loss_t=0.1188, loss_r=0.7033, loss=6.0959, norm_factor=5.1126, grad_norm=1.7792\n",
      "Epoch 1: 172/256 - loss_mc=5.9591, loss_t=0.1210, loss_r=0.6542, loss=6.0367, norm_factor=5.1688, grad_norm=1.1617\n",
      "Epoch 1: 173/256 - loss_mc=5.9098, loss_t=0.1147, loss_r=0.6857, loss=5.9899, norm_factor=5.2260, grad_norm=1.0933\n",
      "Epoch 1: 174/256 - loss_mc=5.7585, loss_t=0.1072, loss_r=0.6837, loss=5.8376, norm_factor=5.2842, grad_norm=1.5987\n",
      "Epoch 1: 175/256 - loss_mc=5.7541, loss_t=0.1157, loss_r=0.7407, loss=5.8397, norm_factor=5.3427, grad_norm=1.4510\n",
      "Epoch 1: 176/256 - loss_mc=5.6840, loss_t=0.1378, loss_r=0.6039, loss=5.7582, norm_factor=5.4009, grad_norm=1.4301\n",
      "Epoch 1: 177/256 - loss_mc=5.6417, loss_t=0.1152, loss_r=0.6901, loss=5.7222, norm_factor=5.4601, grad_norm=1.5384\n",
      "Epoch 1: 178/256 - loss_mc=5.5088, loss_t=0.1491, loss_r=0.6158, loss=5.5853, norm_factor=5.5189, grad_norm=1.8164\n",
      "Epoch 1: 179/256 - loss_mc=5.4724, loss_t=0.1349, loss_r=0.6334, loss=5.5493, norm_factor=5.5784, grad_norm=1.7539\n",
      "Epoch 1: 180/256 - loss_mc=5.3822, loss_t=0.1503, loss_r=0.6681, loss=5.4641, norm_factor=5.6392, grad_norm=1.5317\n",
      "Epoch 1: 181/256 - loss_mc=5.3146, loss_t=0.1769, loss_r=0.6176, loss=5.3941, norm_factor=5.7001, grad_norm=1.8611\n",
      "Epoch 1: 182/256 - loss_mc=5.3213, loss_t=0.1677, loss_r=0.6262, loss=5.4007, norm_factor=5.7619, grad_norm=1.9914\n",
      "Epoch 1: 183/256 - loss_mc=5.2397, loss_t=0.1636, loss_r=0.6212, loss=5.3182, norm_factor=5.8241, grad_norm=1.5489\n",
      "Epoch 1: 184/256 - loss_mc=5.1874, loss_t=0.1684, loss_r=0.6109, loss=5.2653, norm_factor=5.8877, grad_norm=1.8781\n",
      "Epoch 1: 185/256 - loss_mc=5.1383, loss_t=0.1401, loss_r=0.6059, loss=5.2129, norm_factor=5.9532, grad_norm=1.3968\n",
      "Epoch 1: 186/256 - loss_mc=5.0652, loss_t=0.1581, loss_r=0.6522, loss=5.1462, norm_factor=6.0189, grad_norm=1.8248\n",
      "Epoch 1: 187/256 - loss_mc=5.0092, loss_t=0.1265, loss_r=0.6654, loss=5.0884, norm_factor=6.0854, grad_norm=1.4964\n",
      "Epoch 1: 188/256 - loss_mc=4.8721, loss_t=0.1286, loss_r=0.5461, loss=4.9396, norm_factor=6.1522, grad_norm=1.3522\n",
      "Epoch 1: 189/256 - loss_mc=4.8593, loss_t=0.1147, loss_r=0.6522, loss=4.9360, norm_factor=6.2197, grad_norm=1.8775\n",
      "Epoch 1: 190/256 - loss_mc=4.7558, loss_t=0.1325, loss_r=0.6630, loss=4.8354, norm_factor=6.2875, grad_norm=1.4801\n",
      "Epoch 1: 191/256 - loss_mc=4.7434, loss_t=0.1169, loss_r=0.6429, loss=4.8193, norm_factor=6.3575, grad_norm=1.3687\n",
      "Epoch 1: 192/256 - loss_mc=4.6700, loss_t=0.1519, loss_r=0.5831, loss=4.7435, norm_factor=6.4282, grad_norm=1.4810\n",
      "Epoch 1: 193/256 - loss_mc=4.6149, loss_t=0.1010, loss_r=0.6111, loss=4.6861, norm_factor=6.5001, grad_norm=1.0709\n",
      "Epoch 1: 194/256 - loss_mc=4.5498, loss_t=0.1435, loss_r=0.6257, loss=4.6267, norm_factor=6.5724, grad_norm=1.4279\n",
      "Epoch 1: 195/256 - loss_mc=4.4949, loss_t=0.1376, loss_r=0.5773, loss=4.5664, norm_factor=6.6456, grad_norm=1.6377\n",
      "Epoch 1: 196/256 - loss_mc=4.4856, loss_t=0.1118, loss_r=0.6156, loss=4.5583, norm_factor=6.7183, grad_norm=1.2102\n",
      "Epoch 1: 197/256 - loss_mc=4.3773, loss_t=0.1243, loss_r=0.5654, loss=4.4463, norm_factor=6.7919, grad_norm=1.1479\n",
      "Epoch 1: 198/256 - loss_mc=4.2970, loss_t=0.1306, loss_r=0.5738, loss=4.3675, norm_factor=6.8664, grad_norm=0.9931\n",
      "Epoch 1: 199/256 - loss_mc=4.3401, loss_t=0.1147, loss_r=0.6160, loss=4.4131, norm_factor=6.9426, grad_norm=1.7299\n",
      "Epoch 1: 200/256 - loss_mc=4.1951, loss_t=0.1074, loss_r=0.5279, loss=4.2587, norm_factor=7.0202, grad_norm=1.5131\n",
      "Epoch 1: 201/256 - loss_mc=4.1487, loss_t=0.1507, loss_r=0.5209, loss=4.2159, norm_factor=7.0997, grad_norm=1.4954\n",
      "Epoch 1: 202/256 - loss_mc=4.0900, loss_t=0.1292, loss_r=0.5602, loss=4.1590, norm_factor=7.1806, grad_norm=1.4189\n",
      "Epoch 1: 203/256 - loss_mc=4.0474, loss_t=0.1653, loss_r=0.5395, loss=4.1178, norm_factor=7.2623, grad_norm=2.7181\n",
      "Epoch 1: 204/256 - loss_mc=3.9957, loss_t=0.1398, loss_r=0.4493, loss=4.0546, norm_factor=7.3457, grad_norm=1.2401\n",
      "Epoch 1: 205/256 - loss_mc=3.9441, loss_t=0.1305, loss_r=0.5013, loss=4.0073, norm_factor=7.4318, grad_norm=2.2777\n",
      "Epoch 1: 206/256 - loss_mc=3.8559, loss_t=0.1962, loss_r=0.4899, loss=3.9245, norm_factor=7.5206, grad_norm=2.2629\n",
      "Epoch 1: 207/256 - loss_mc=3.8316, loss_t=0.1820, loss_r=0.5663, loss=3.9065, norm_factor=7.6114, grad_norm=2.6608\n",
      "Epoch 1: 208/256 - loss_mc=3.7986, loss_t=0.1531, loss_r=0.5959, loss=3.8735, norm_factor=7.7027, grad_norm=2.7614\n",
      "Epoch 1: 209/256 - loss_mc=3.7152, loss_t=0.1670, loss_r=0.6105, loss=3.7929, norm_factor=7.7955, grad_norm=2.9603\n",
      "Epoch 1: 210/256 - loss_mc=3.6826, loss_t=0.1350, loss_r=0.5409, loss=3.7502, norm_factor=7.8901, grad_norm=2.5119\n",
      "Epoch 1: 211/256 - loss_mc=3.6551, loss_t=0.1311, loss_r=0.5706, loss=3.7253, norm_factor=7.9865, grad_norm=2.1835\n",
      "Epoch 1: 212/256 - loss_mc=3.5551, loss_t=0.2048, loss_r=0.5386, loss=3.6295, norm_factor=8.0849, grad_norm=2.5989\n",
      "Epoch 1: 213/256 - loss_mc=3.5518, loss_t=0.2108, loss_r=0.5920, loss=3.6321, norm_factor=8.1857, grad_norm=3.9805\n",
      "Epoch 1: 214/256 - loss_mc=3.5124, loss_t=0.1689, loss_r=0.5468, loss=3.5840, norm_factor=8.2884, grad_norm=2.0069\n",
      "Epoch 1: 215/256 - loss_mc=3.4414, loss_t=0.2366, loss_r=0.5373, loss=3.5188, norm_factor=8.3931, grad_norm=2.7123\n",
      "Epoch 1: 216/256 - loss_mc=3.3935, loss_t=0.1757, loss_r=0.5553, loss=3.4666, norm_factor=8.4989, grad_norm=2.6485\n",
      "Epoch 1: 217/256 - loss_mc=3.3665, loss_t=0.1779, loss_r=0.5560, loss=3.4399, norm_factor=8.6088, grad_norm=1.8755\n",
      "Epoch 1: 218/256 - loss_mc=3.3240, loss_t=0.1710, loss_r=0.5057, loss=3.3916, norm_factor=8.7181, grad_norm=1.8032\n",
      "Epoch 1: 219/256 - loss_mc=3.2279, loss_t=0.1893, loss_r=0.5334, loss=3.3002, norm_factor=8.8282, grad_norm=2.3009\n",
      "Epoch 1: 220/256 - loss_mc=3.2118, loss_t=0.1719, loss_r=0.5581, loss=3.2848, norm_factor=8.9403, grad_norm=2.0281\n",
      "Epoch 1: 221/256 - loss_mc=3.1491, loss_t=0.1473, loss_r=0.5516, loss=3.2190, norm_factor=9.0535, grad_norm=1.4662\n",
      "Epoch 1: 222/256 - loss_mc=3.1201, loss_t=0.1664, loss_r=0.5347, loss=3.1903, norm_factor=9.1680, grad_norm=2.0545\n",
      "Epoch 1: 223/256 - loss_mc=3.0676, loss_t=0.1357, loss_r=0.5808, loss=3.1392, norm_factor=9.2846, grad_norm=1.4292\n",
      "Epoch 1: 224/256 - loss_mc=3.0115, loss_t=0.1423, loss_r=0.5348, loss=3.0793, norm_factor=9.4047, grad_norm=1.4193\n",
      "Epoch 1: 225/256 - loss_mc=3.0111, loss_t=0.1239, loss_r=0.5503, loss=3.0785, norm_factor=9.5281, grad_norm=1.4254\n",
      "Epoch 1: 226/256 - loss_mc=2.9066, loss_t=0.1845, loss_r=0.4525, loss=2.9703, norm_factor=9.6547, grad_norm=1.5717\n",
      "Epoch 1: 227/256 - loss_mc=2.8604, loss_t=0.1439, loss_r=0.5215, loss=2.9269, norm_factor=9.7836, grad_norm=1.5538\n",
      "Epoch 1: 228/256 - loss_mc=2.8500, loss_t=0.1608, loss_r=0.4711, loss=2.9132, norm_factor=9.9130, grad_norm=1.3281\n",
      "Epoch 1: 229/256 - loss_mc=2.8083, loss_t=0.1641, loss_r=0.5211, loss=2.8768, norm_factor=10.0458, grad_norm=1.2964\n",
      "Epoch 1: 230/256 - loss_mc=2.7813, loss_t=0.1733, loss_r=0.5703, loss=2.8557, norm_factor=10.1827, grad_norm=2.0768\n",
      "Epoch 1: 231/256 - loss_mc=2.7180, loss_t=0.1615, loss_r=0.5309, loss=2.7873, norm_factor=10.3250, grad_norm=1.2054\n",
      "Epoch 1: 232/256 - loss_mc=2.6703, loss_t=0.1713, loss_r=0.5126, loss=2.7387, norm_factor=10.4700, grad_norm=1.7457\n",
      "Epoch 1: 233/256 - loss_mc=2.6466, loss_t=0.1400, loss_r=0.4926, loss=2.7098, norm_factor=10.6179, grad_norm=1.2420\n",
      "Epoch 1: 234/256 - loss_mc=2.5961, loss_t=0.2451, loss_r=0.5503, loss=2.6756, norm_factor=10.7698, grad_norm=2.6873\n",
      "Epoch 1: 235/256 - loss_mc=2.5472, loss_t=0.1637, loss_r=0.5117, loss=2.6148, norm_factor=10.9270, grad_norm=2.0988\n",
      "Epoch 1: 236/256 - loss_mc=2.4892, loss_t=0.1903, loss_r=0.4978, loss=2.5580, norm_factor=11.0869, grad_norm=1.9373\n",
      "Epoch 1: 237/256 - loss_mc=2.4409, loss_t=0.1712, loss_r=0.4815, loss=2.5061, norm_factor=11.2517, grad_norm=1.6461\n",
      "Epoch 1: 238/256 - loss_mc=2.4090, loss_t=0.1689, loss_r=0.6014, loss=2.4861, norm_factor=11.4213, grad_norm=1.2533\n",
      "Epoch 1: 239/256 - loss_mc=2.3785, loss_t=0.1482, loss_r=0.5250, loss=2.4458, norm_factor=11.5926, grad_norm=2.1809\n",
      "Epoch 1: 240/256 - loss_mc=2.3259, loss_t=0.1635, loss_r=0.5488, loss=2.3972, norm_factor=11.7688, grad_norm=1.5487\n",
      "Epoch 1: 241/256 - loss_mc=2.2864, loss_t=0.1257, loss_r=0.5547, loss=2.3544, norm_factor=11.9489, grad_norm=1.6508\n",
      "Epoch 1: 242/256 - loss_mc=2.2556, loss_t=0.1516, loss_r=0.5389, loss=2.3246, norm_factor=12.1336, grad_norm=2.2083\n",
      "Epoch 1: 243/256 - loss_mc=2.2012, loss_t=0.1184, loss_r=0.5042, loss=2.2634, norm_factor=12.3241, grad_norm=1.5167\n",
      "Epoch 1: 244/256 - loss_mc=2.1705, loss_t=0.1040, loss_r=0.5703, loss=2.2379, norm_factor=12.5178, grad_norm=1.1138\n",
      "Epoch 1: 245/256 - loss_mc=2.1275, loss_t=0.1312, loss_r=0.5708, loss=2.1977, norm_factor=12.7167, grad_norm=1.3595\n",
      "Epoch 1: 246/256 - loss_mc=2.1135, loss_t=0.1327, loss_r=0.5073, loss=2.1775, norm_factor=12.9188, grad_norm=2.1632\n",
      "Epoch 1: 247/256 - loss_mc=2.0697, loss_t=0.2380, loss_r=0.5049, loss=2.1440, norm_factor=13.1253, grad_norm=3.4649\n",
      "Epoch 1: 248/256 - loss_mc=2.0327, loss_t=0.1080, loss_r=0.5038, loss=2.0939, norm_factor=13.3333, grad_norm=1.2965\n",
      "Epoch 1: 249/256 - loss_mc=1.9925, loss_t=0.1980, loss_r=0.5120, loss=2.0635, norm_factor=13.5446, grad_norm=2.6314\n",
      "Epoch 1: 250/256 - loss_mc=1.9936, loss_t=0.1583, loss_r=0.4780, loss=2.0573, norm_factor=13.7596, grad_norm=1.9783\n",
      "Epoch 1: 251/256 - loss_mc=1.9406, loss_t=0.3217, loss_r=0.4793, loss=2.0207, norm_factor=13.9807, grad_norm=2.7226\n",
      "Epoch 1: 252/256 - loss_mc=1.8926, loss_t=0.1877, loss_r=0.4660, loss=1.9579, norm_factor=14.2093, grad_norm=2.0732\n",
      "Epoch 1: 253/256 - loss_mc=1.8731, loss_t=0.1883, loss_r=0.5042, loss=1.9424, norm_factor=14.4396, grad_norm=2.1885\n",
      "Epoch 1: 254/256 - loss_mc=1.8339, loss_t=0.2035, loss_r=0.4857, loss=1.9029, norm_factor=14.6748, grad_norm=1.9563\n",
      "Epoch 1: 255/256 - loss_mc=1.7774, loss_t=0.1733, loss_r=0.4575, loss=1.8404, norm_factor=14.9135, grad_norm=1.7620\n",
      "Epoch 1: 256/256 - loss_mc=1.7573, loss_t=0.2947, loss_r=0.4444, loss=1.8312, norm_factor=15.1545, grad_norm=3.1550\n",
      "Epoch 2: 1/256 - loss_mc=1.7485, loss_t=0.2539, loss_r=0.3730, loss=1.8112, norm_factor=15.4033, grad_norm=1.9195\n",
      "Epoch 2: 2/256 - loss_mc=1.7030, loss_t=0.2481, loss_r=0.4643, loss=1.7743, norm_factor=15.6593, grad_norm=4.1100\n",
      "Epoch 2: 3/256 - loss_mc=1.6764, loss_t=0.2787, loss_r=0.4806, loss=1.7524, norm_factor=15.9168, grad_norm=3.0151\n",
      "Epoch 2: 4/256 - loss_mc=1.6326, loss_t=0.1550, loss_r=0.5311, loss=1.7012, norm_factor=16.1784, grad_norm=1.9074\n",
      "Epoch 2: 5/256 - loss_mc=1.6020, loss_t=0.2838, loss_r=0.6152, loss=1.6919, norm_factor=16.4417, grad_norm=1.9561\n",
      "Epoch 2: 6/256 - loss_mc=1.5666, loss_t=0.2660, loss_r=0.4573, loss=1.6389, norm_factor=16.7077, grad_norm=4.0028\n",
      "Epoch 2: 7/256 - loss_mc=1.5381, loss_t=0.3157, loss_r=0.5142, loss=1.6211, norm_factor=16.9759, grad_norm=2.2890\n",
      "Epoch 2: 8/256 - loss_mc=1.5271, loss_t=0.3031, loss_r=0.5303, loss=1.6104, norm_factor=17.2470, grad_norm=3.5364\n",
      "Epoch 2: 9/256 - loss_mc=1.4863, loss_t=0.2590, loss_r=0.4707, loss=1.5593, norm_factor=17.5098, grad_norm=3.6556\n",
      "Epoch 2: 10/256 - loss_mc=1.4746, loss_t=0.2190, loss_r=0.4803, loss=1.5445, norm_factor=17.7740, grad_norm=4.0318\n",
      "Epoch 2: 11/256 - loss_mc=1.4228, loss_t=0.1661, loss_r=0.4502, loss=1.4845, norm_factor=18.0404, grad_norm=2.3199\n",
      "Epoch 2: 12/256 - loss_mc=1.3836, loss_t=0.2334, loss_r=0.5494, loss=1.4619, norm_factor=18.3102, grad_norm=2.5346\n",
      "Epoch 2: 13/256 - loss_mc=1.3612, loss_t=0.1876, loss_r=0.5134, loss=1.4313, norm_factor=18.5812, grad_norm=3.9415\n",
      "Epoch 2: 14/256 - loss_mc=1.3514, loss_t=0.3896, loss_r=0.5048, loss=1.4408, norm_factor=18.8569, grad_norm=3.8025\n",
      "Epoch 2: 15/256 - loss_mc=1.3323, loss_t=0.1813, loss_r=0.5114, loss=1.4016, norm_factor=19.1435, grad_norm=3.9883\n",
      "Epoch 2: 16/256 - loss_mc=1.3111, loss_t=0.1720, loss_r=0.5156, loss=1.3799, norm_factor=19.4337, grad_norm=2.4357\n",
      "Epoch 2: 17/256 - loss_mc=1.2829, loss_t=0.1562, loss_r=0.4725, loss=1.3458, norm_factor=19.7268, grad_norm=2.5870\n",
      "Epoch 2: 18/256 - loss_mc=1.2405, loss_t=0.1916, loss_r=0.5049, loss=1.3101, norm_factor=20.0238, grad_norm=2.8323\n",
      "Epoch 2: 19/256 - loss_mc=1.2247, loss_t=0.1551, loss_r=0.4881, loss=1.2891, norm_factor=20.3264, grad_norm=2.0561\n",
      "Epoch 2: 20/256 - loss_mc=1.2190, loss_t=0.2633, loss_r=0.5674, loss=1.3021, norm_factor=20.6296, grad_norm=3.4609\n",
      "Epoch 2: 21/256 - loss_mc=1.1731, loss_t=0.3003, loss_r=0.5553, loss=1.2586, norm_factor=20.9301, grad_norm=3.1719\n",
      "Epoch 2: 22/256 - loss_mc=1.1777, loss_t=0.3179, loss_r=0.5898, loss=1.2684, norm_factor=21.2385, grad_norm=4.6392\n",
      "Epoch 2: 23/256 - loss_mc=1.1669, loss_t=0.3845, loss_r=0.5399, loss=1.2594, norm_factor=21.5464, grad_norm=5.9619\n",
      "Epoch 2: 24/256 - loss_mc=1.1420, loss_t=0.2611, loss_r=0.5522, loss=1.2233, norm_factor=21.8694, grad_norm=3.6254\n",
      "Epoch 2: 25/256 - loss_mc=1.1185, loss_t=0.5082, loss_r=0.5309, loss=1.2224, norm_factor=22.1917, grad_norm=7.0515\n",
      "Epoch 2: 26/256 - loss_mc=1.0929, loss_t=0.4586, loss_r=0.5915, loss=1.1979, norm_factor=22.5094, grad_norm=4.1597\n",
      "Epoch 2: 27/256 - loss_mc=1.0750, loss_t=0.3425, loss_r=0.5193, loss=1.1612, norm_factor=22.8261, grad_norm=4.0301\n",
      "Epoch 2: 28/256 - loss_mc=1.0604, loss_t=0.3371, loss_r=0.4701, loss=1.1411, norm_factor=23.1435, grad_norm=4.6179\n",
      "Epoch 2: 29/256 - loss_mc=1.0378, loss_t=0.4078, loss_r=0.4524, loss=1.1238, norm_factor=23.4588, grad_norm=5.4822\n",
      "Epoch 2: 30/256 - loss_mc=1.0159, loss_t=0.4222, loss_r=0.5137, loss=1.1095, norm_factor=23.7669, grad_norm=2.8113\n",
      "Epoch 2: 31/256 - loss_mc=1.0058, loss_t=0.3598, loss_r=0.6088, loss=1.1026, norm_factor=24.0797, grad_norm=4.3132\n",
      "Epoch 2: 32/256 - loss_mc=0.9825, loss_t=0.3722, loss_r=0.5793, loss=1.0777, norm_factor=24.3950, grad_norm=2.9425\n",
      "Epoch 2: 33/256 - loss_mc=0.9516, loss_t=0.3170, loss_r=0.6422, loss=1.0475, norm_factor=24.7132, grad_norm=2.1421\n",
      "Epoch 2: 34/256 - loss_mc=0.9435, loss_t=0.2691, loss_r=0.6689, loss=1.0373, norm_factor=25.0349, grad_norm=2.6608\n",
      "Epoch 2: 35/256 - loss_mc=0.9370, loss_t=0.5104, loss_r=0.6438, loss=1.0525, norm_factor=25.3630, grad_norm=3.7400\n",
      "Epoch 2: 36/256 - loss_mc=0.9254, loss_t=0.2819, loss_r=0.6516, loss=1.0187, norm_factor=25.7036, grad_norm=3.3780\n",
      "Epoch 2: 37/256 - loss_mc=0.8891, loss_t=0.3286, loss_r=0.6746, loss=0.9895, norm_factor=26.0518, grad_norm=2.8447\n",
      "Epoch 2: 38/256 - loss_mc=0.8989, loss_t=0.4282, loss_r=0.7967, loss=1.0214, norm_factor=26.3977, grad_norm=6.8172\n",
      "Epoch 2: 39/256 - loss_mc=0.8793, loss_t=0.3614, loss_r=0.7184, loss=0.9873, norm_factor=26.7499, grad_norm=3.0329\n",
      "Epoch 2: 40/256 - loss_mc=0.8718, loss_t=0.6700, loss_r=0.7310, loss=1.0119, norm_factor=27.1075, grad_norm=6.9108\n",
      "Epoch 2: 41/256 - loss_mc=0.8471, loss_t=0.3415, loss_r=0.6904, loss=0.9503, norm_factor=27.4557, grad_norm=2.0513\n",
      "Epoch 2: 42/256 - loss_mc=0.8350, loss_t=0.4310, loss_r=0.7716, loss=0.9553, norm_factor=27.8106, grad_norm=4.7948\n",
      "Epoch 2: 43/256 - loss_mc=0.8186, loss_t=0.3559, loss_r=0.7203, loss=0.9262, norm_factor=28.1514, grad_norm=3.7759\n",
      "Epoch 2: 44/256 - loss_mc=0.7967, loss_t=0.3972, loss_r=0.8253, loss=0.9190, norm_factor=28.4957, grad_norm=4.3257\n",
      "Epoch 2: 45/256 - loss_mc=0.7942, loss_t=0.4985, loss_r=0.8048, loss=0.9245, norm_factor=28.8396, grad_norm=4.3925\n",
      "Epoch 2: 46/256 - loss_mc=0.7750, loss_t=0.3107, loss_r=0.6942, loss=0.8755, norm_factor=29.1839, grad_norm=3.9791\n",
      "Epoch 2: 47/256 - loss_mc=0.7734, loss_t=0.3843, loss_r=0.6980, loss=0.8816, norm_factor=29.5319, grad_norm=7.9967\n",
      "Epoch 2: 48/256 - loss_mc=0.7637, loss_t=0.6240, loss_r=0.5735, loss=0.8835, norm_factor=29.8775, grad_norm=5.6352\n",
      "Epoch 2: 49/256 - loss_mc=0.7433, loss_t=0.2659, loss_r=0.6101, loss=0.8309, norm_factor=30.2315, grad_norm=4.3195\n",
      "Epoch 2: 50/256 - loss_mc=0.7322, loss_t=0.2364, loss_r=0.5293, loss=0.8088, norm_factor=30.5927, grad_norm=3.2178\n",
      "Epoch 2: 51/256 - loss_mc=0.7216, loss_t=0.3813, loss_r=0.5438, loss=0.8141, norm_factor=30.9530, grad_norm=5.2174\n",
      "Epoch 2: 52/256 - loss_mc=0.7100, loss_t=0.4014, loss_r=0.4908, loss=0.7992, norm_factor=31.3243, grad_norm=4.8006\n",
      "Epoch 2: 53/256 - loss_mc=0.7012, loss_t=0.3801, loss_r=0.4570, loss=0.7849, norm_factor=31.6871, grad_norm=4.9453\n",
      "Epoch 2: 54/256 - loss_mc=0.7155, loss_t=0.3711, loss_r=0.4521, loss=0.7978, norm_factor=32.0482, grad_norm=5.3563\n",
      "Epoch 2: 55/256 - loss_mc=0.6924, loss_t=0.7084, loss_r=0.4920, loss=0.8124, norm_factor=32.4099, grad_norm=7.5710\n",
      "Epoch 2: 56/256 - loss_mc=0.6732, loss_t=0.3436, loss_r=0.5105, loss=0.7586, norm_factor=32.7767, grad_norm=3.6959\n",
      "Epoch 2: 57/256 - loss_mc=0.6635, loss_t=0.3783, loss_r=0.4831, loss=0.7496, norm_factor=33.1511, grad_norm=5.4482\n",
      "Epoch 2: 58/256 - loss_mc=0.6403, loss_t=0.4213, loss_r=0.4553, loss=0.7279, norm_factor=33.5487, grad_norm=4.7065\n",
      "Epoch 2: 59/256 - loss_mc=0.6379, loss_t=0.4682, loss_r=0.5475, loss=0.7395, norm_factor=33.9496, grad_norm=5.3260\n",
      "Epoch 2: 60/256 - loss_mc=0.6377, loss_t=0.3465, loss_r=0.4555, loss=0.7179, norm_factor=34.3605, grad_norm=3.7202\n",
      "Epoch 2: 61/256 - loss_mc=0.6308, loss_t=0.4109, loss_r=0.5636, loss=0.7282, norm_factor=34.7841, grad_norm=9.2144\n",
      "Epoch 2: 62/256 - loss_mc=0.6195, loss_t=0.3176, loss_r=0.4945, loss=0.7008, norm_factor=35.2070, grad_norm=4.9271\n",
      "Epoch 2: 63/256 - loss_mc=0.6059, loss_t=0.3468, loss_r=0.5027, loss=0.6908, norm_factor=35.6277, grad_norm=4.8267\n",
      "Epoch 2: 64/256 - loss_mc=0.5943, loss_t=0.3575, loss_r=0.5942, loss=0.6895, norm_factor=36.0467, grad_norm=5.5729\n",
      "Epoch 2: 65/256 - loss_mc=0.5905, loss_t=0.3251, loss_r=0.5980, loss=0.6828, norm_factor=36.4690, grad_norm=4.0319\n",
      "Epoch 2: 66/256 - loss_mc=0.5860, loss_t=0.3959, loss_r=0.6382, loss=0.6894, norm_factor=36.8939, grad_norm=2.8807\n",
      "Epoch 2: 67/256 - loss_mc=0.5665, loss_t=0.4906, loss_r=0.6618, loss=0.6818, norm_factor=37.3170, grad_norm=6.1005\n",
      "Epoch 2: 68/256 - loss_mc=0.5549, loss_t=0.4333, loss_r=0.6978, loss=0.6680, norm_factor=37.7426, grad_norm=6.3868\n",
      "Epoch 2: 69/256 - loss_mc=0.5440, loss_t=0.4067, loss_r=0.7270, loss=0.6574, norm_factor=38.1782, grad_norm=2.5842\n",
      "Epoch 2: 70/256 - loss_mc=0.5404, loss_t=0.4611, loss_r=0.7293, loss=0.6594, norm_factor=38.6153, grad_norm=2.8336\n",
      "Epoch 2: 71/256 - loss_mc=0.5334, loss_t=0.4094, loss_r=0.6604, loss=0.6404, norm_factor=39.0675, grad_norm=4.0692\n",
      "Epoch 2: 72/256 - loss_mc=0.5255, loss_t=0.4588, loss_r=0.8163, loss=0.6531, norm_factor=39.5307, grad_norm=3.7493\n",
      "Epoch 2: 73/256 - loss_mc=0.5120, loss_t=0.3858, loss_r=0.7782, loss=0.6284, norm_factor=39.9934, grad_norm=2.9451\n",
      "Epoch 2: 74/256 - loss_mc=0.5016, loss_t=0.3885, loss_r=0.6839, loss=0.6088, norm_factor=40.4551, grad_norm=4.2673\n",
      "Epoch 2: 75/256 - loss_mc=0.5003, loss_t=0.3474, loss_r=0.7082, loss=0.6058, norm_factor=40.9075, grad_norm=5.8841\n",
      "Epoch 2: 76/256 - loss_mc=0.4953, loss_t=0.3900, loss_r=0.6531, loss=0.5996, norm_factor=41.3607, grad_norm=2.7200\n",
      "Epoch 2: 77/256 - loss_mc=0.4802, loss_t=0.2952, loss_r=0.5228, loss=0.5620, norm_factor=41.8165, grad_norm=2.4371\n",
      "Epoch 2: 78/256 - loss_mc=0.4716, loss_t=0.3532, loss_r=0.5189, loss=0.5588, norm_factor=42.2773, grad_norm=2.9062\n",
      "Epoch 2: 79/256 - loss_mc=0.4662, loss_t=0.2615, loss_r=0.5055, loss=0.5429, norm_factor=42.7448, grad_norm=3.6810\n",
      "Epoch 2: 80/256 - loss_mc=0.4635, loss_t=0.2961, loss_r=0.5495, loss=0.5481, norm_factor=43.2172, grad_norm=2.3133\n",
      "Epoch 2: 81/256 - loss_mc=0.4545, loss_t=0.2588, loss_r=0.5323, loss=0.5336, norm_factor=43.7108, grad_norm=2.3540\n",
      "Epoch 2: 82/256 - loss_mc=0.4476, loss_t=0.2765, loss_r=0.5647, loss=0.5317, norm_factor=44.2060, grad_norm=2.0790\n",
      "Epoch 2: 83/256 - loss_mc=0.4457, loss_t=0.3091, loss_r=0.5621, loss=0.5328, norm_factor=44.7017, grad_norm=2.1784\n",
      "Epoch 2: 84/256 - loss_mc=0.4356, loss_t=0.2684, loss_r=0.5032, loss=0.5128, norm_factor=45.1988, grad_norm=3.1047\n",
      "Epoch 2: 85/256 - loss_mc=0.4292, loss_t=0.3512, loss_r=0.4703, loss=0.5114, norm_factor=45.7005, grad_norm=2.7726\n",
      "Epoch 2: 86/256 - loss_mc=0.4236, loss_t=0.2600, loss_r=0.5009, loss=0.4996, norm_factor=46.2012, grad_norm=2.5353\n",
      "Epoch 2: 87/256 - loss_mc=0.4169, loss_t=0.3355, loss_r=0.4398, loss=0.4944, norm_factor=46.7071, grad_norm=5.2949\n",
      "Epoch 2: 88/256 - loss_mc=0.4073, loss_t=0.4454, loss_r=0.4787, loss=0.4997, norm_factor=47.2163, grad_norm=3.1659\n",
      "Epoch 2: 89/256 - loss_mc=0.4070, loss_t=0.2780, loss_r=0.3875, loss=0.4736, norm_factor=47.7421, grad_norm=4.9169\n",
      "Epoch 2: 90/256 - loss_mc=0.3973, loss_t=0.7401, loss_r=0.3861, loss=0.5099, norm_factor=48.2649, grad_norm=4.9093\n",
      "Epoch 2: 91/256 - loss_mc=0.3992, loss_t=0.8863, loss_r=0.3181, loss=0.5196, norm_factor=48.7909, grad_norm=7.5210\n",
      "Epoch 2: 92/256 - loss_mc=0.3898, loss_t=0.2748, loss_r=0.3514, loss=0.4524, norm_factor=49.3157, grad_norm=4.3703\n",
      "Epoch 2: 93/256 - loss_mc=0.3859, loss_t=0.3092, loss_r=0.3407, loss=0.4509, norm_factor=49.8492, grad_norm=4.0965\n",
      "Epoch 2: 94/256 - loss_mc=0.3708, loss_t=0.2422, loss_r=0.3510, loss=0.4301, norm_factor=50.3851, grad_norm=2.9758\n",
      "Epoch 2: 95/256 - loss_mc=0.3698, loss_t=0.3375, loss_r=0.3196, loss=0.4355, norm_factor=50.9229, grad_norm=5.9601\n",
      "Epoch 2: 96/256 - loss_mc=0.3673, loss_t=0.3967, loss_r=0.2791, loss=0.4349, norm_factor=51.4666, grad_norm=6.0682\n",
      "Epoch 2: 97/256 - loss_mc=0.3577, loss_t=0.3692, loss_r=0.3348, loss=0.4281, norm_factor=52.0133, grad_norm=4.1032\n",
      "Epoch 2: 98/256 - loss_mc=0.3527, loss_t=0.6789, loss_r=0.2728, loss=0.4478, norm_factor=52.5656, grad_norm=7.8405\n",
      "Epoch 2: 99/256 - loss_mc=0.3528, loss_t=0.3949, loss_r=0.3237, loss=0.4247, norm_factor=53.1006, grad_norm=5.0225\n",
      "Epoch 2: 100/256 - loss_mc=0.3436, loss_t=0.3829, loss_r=0.4080, loss=0.4227, norm_factor=53.6402, grad_norm=4.1928\n",
      "Epoch 2: 101/256 - loss_mc=0.3396, loss_t=0.3537, loss_r=0.3683, loss=0.4119, norm_factor=54.1849, grad_norm=3.1248\n",
      "Epoch 2: 102/256 - loss_mc=0.3367, loss_t=0.4034, loss_r=0.4329, loss=0.4203, norm_factor=54.7358, grad_norm=7.3811\n",
      "Epoch 2: 103/256 - loss_mc=0.3272, loss_t=0.3004, loss_r=0.3385, loss=0.3911, norm_factor=55.2891, grad_norm=3.9328\n",
      "Epoch 2: 104/256 - loss_mc=0.3233, loss_t=0.3181, loss_r=0.2740, loss=0.3825, norm_factor=55.8503, grad_norm=4.6009\n",
      "Epoch 2: 105/256 - loss_mc=0.3258, loss_t=0.6351, loss_r=0.3432, loss=0.4236, norm_factor=56.4169, grad_norm=12.6877\n",
      "Epoch 2: 106/256 - loss_mc=0.3217, loss_t=0.4817, loss_r=0.3312, loss=0.4030, norm_factor=56.9148, grad_norm=11.9710\n",
      "Epoch 2: 107/256 - loss_mc=0.3161, loss_t=0.5190, loss_r=0.4171, loss=0.4097, norm_factor=57.4252, grad_norm=8.5509\n",
      "Epoch 2: 108/256 - loss_mc=0.3083, loss_t=0.6074, loss_r=0.4860, loss=0.4177, norm_factor=57.9303, grad_norm=9.3336\n",
      "Epoch 2: 109/256 - loss_mc=0.2989, loss_t=0.6450, loss_r=0.4847, loss=0.4119, norm_factor=58.4395, grad_norm=7.5360\n",
      "Epoch 2: 110/256 - loss_mc=0.3003, loss_t=0.5804, loss_r=0.4882, loss=0.4071, norm_factor=58.9862, grad_norm=15.2853\n",
      "Epoch 2: 111/256 - loss_mc=0.2986, loss_t=0.6047, loss_r=0.3655, loss=0.3956, norm_factor=59.4910, grad_norm=7.3248\n",
      "Epoch 2: 112/256 - loss_mc=0.2953, loss_t=0.4886, loss_r=0.3526, loss=0.3794, norm_factor=59.9835, grad_norm=5.6094\n",
      "Epoch 2: 113/256 - loss_mc=0.3015, loss_t=0.6839, loss_r=0.5424, loss=0.4242, norm_factor=60.4864, grad_norm=12.4890\n",
      "Epoch 2: 114/256 - loss_mc=0.2931, loss_t=0.4777, loss_r=0.5841, loss=0.3993, norm_factor=60.9731, grad_norm=4.6679\n",
      "Epoch 2: 115/256 - loss_mc=0.2855, loss_t=0.7092, loss_r=0.5780, loss=0.4142, norm_factor=61.4641, grad_norm=16.1201\n",
      "Epoch 2: 116/256 - loss_mc=0.2815, loss_t=0.6403, loss_r=0.7172, loss=0.4172, norm_factor=61.9515, grad_norm=9.1167\n",
      "Epoch 2: 117/256 - loss_mc=0.2711, loss_t=0.6527, loss_r=0.7508, loss=0.4115, norm_factor=62.4726, grad_norm=10.7859\n",
      "Epoch 2: 118/256 - loss_mc=0.2708, loss_t=0.4677, loss_r=0.7856, loss=0.3961, norm_factor=62.9821, grad_norm=7.0549\n",
      "Epoch 2: 119/256 - loss_mc=0.2740, loss_t=0.9286, loss_r=0.8271, loss=0.4495, norm_factor=63.4995, grad_norm=8.5169\n",
      "Epoch 2: 120/256 - loss_mc=0.2726, loss_t=0.4607, loss_r=0.8145, loss=0.4001, norm_factor=63.9772, grad_norm=7.1091\n",
      "Epoch 2: 121/256 - loss_mc=0.2730, loss_t=0.6078, loss_r=0.8433, loss=0.4181, norm_factor=64.4601, grad_norm=4.8277\n",
      "Epoch 2: 122/256 - loss_mc=0.2706, loss_t=0.5172, loss_r=0.9225, loss=0.4145, norm_factor=64.9319, grad_norm=5.8045\n",
      "Epoch 2: 123/256 - loss_mc=0.2618, loss_t=0.5573, loss_r=0.9116, loss=0.4087, norm_factor=65.4015, grad_norm=5.5603\n",
      "Epoch 2: 124/256 - loss_mc=0.2656, loss_t=1.3907, loss_r=0.9486, loss=0.4995, norm_factor=65.8667, grad_norm=11.8037\n",
      "Epoch 2: 125/256 - loss_mc=0.2608, loss_t=0.5277, loss_r=1.0321, loss=0.4168, norm_factor=66.2776, grad_norm=4.4829\n",
      "Epoch 2: 126/256 - loss_mc=0.2533, loss_t=0.4835, loss_r=0.9775, loss=0.3994, norm_factor=66.6869, grad_norm=3.7895\n",
      "Epoch 2: 127/256 - loss_mc=0.2520, loss_t=0.5919, loss_r=1.0300, loss=0.4142, norm_factor=67.0965, grad_norm=5.1993\n",
      "Epoch 2: 128/256 - loss_mc=0.2484, loss_t=0.9813, loss_r=0.9908, loss=0.4456, norm_factor=67.4237, grad_norm=6.9129\n",
      "Epoch 2: 129/256 - loss_mc=0.2528, loss_t=1.2759, loss_r=0.9605, loss=0.4764, norm_factor=67.7472, grad_norm=12.5177\n",
      "Epoch 2: 130/256 - loss_mc=0.2550, loss_t=0.8338, loss_r=0.9853, loss=0.4369, norm_factor=68.0211, grad_norm=11.3587\n",
      "Epoch 2: 131/256 - loss_mc=0.2556, loss_t=0.8799, loss_r=1.0626, loss=0.4498, norm_factor=68.2922, grad_norm=10.0900\n",
      "Epoch 2: 132/256 - loss_mc=0.2519, loss_t=1.8579, loss_r=1.1275, loss=0.5504, norm_factor=68.5618, grad_norm=6.0561\n",
      "Epoch 2: 133/256 - loss_mc=0.2518, loss_t=1.2588, loss_r=1.1654, loss=0.4943, norm_factor=68.8666, grad_norm=11.1980\n",
      "Epoch 2: 134/256 - loss_mc=0.2481, loss_t=1.8924, loss_r=1.1524, loss=0.5526, norm_factor=69.1677, grad_norm=6.7195\n",
      "Epoch 2: 135/256 - loss_mc=0.2477, loss_t=0.7996, loss_r=1.1604, loss=0.4437, norm_factor=69.4581, grad_norm=6.1089\n",
      "Epoch 2: 136/256 - loss_mc=0.2399, loss_t=0.7962, loss_r=1.1353, loss=0.4331, norm_factor=69.7782, grad_norm=5.7932\n",
      "Epoch 2: 137/256 - loss_mc=0.2475, loss_t=1.0150, loss_r=1.2095, loss=0.4700, norm_factor=70.0898, grad_norm=7.1722\n",
      "Epoch 2: 138/256 - loss_mc=0.2408, loss_t=1.4154, loss_r=1.1209, loss=0.4944, norm_factor=70.3753, grad_norm=8.6977\n",
      "Epoch 2: 139/256 - loss_mc=0.2433, loss_t=0.7975, loss_r=1.0948, loss=0.4325, norm_factor=70.5929, grad_norm=5.2092\n",
      "Epoch 2: 140/256 - loss_mc=0.2414, loss_t=0.5913, loss_r=1.1256, loss=0.4131, norm_factor=70.7360, grad_norm=4.5009\n",
      "Epoch 2: 141/256 - loss_mc=0.2386, loss_t=0.6309, loss_r=1.1731, loss=0.4190, norm_factor=70.8832, grad_norm=4.2047\n",
      "Epoch 2: 142/256 - loss_mc=0.2253, loss_t=1.0012, loss_r=1.1093, loss=0.4364, norm_factor=71.0353, grad_norm=4.6005\n",
      "Epoch 2: 143/256 - loss_mc=0.2223, loss_t=0.4793, loss_r=1.0748, loss=0.3777, norm_factor=71.2176, grad_norm=3.6263\n",
      "Epoch 2: 144/256 - loss_mc=0.2168, loss_t=0.3488, loss_r=1.0279, loss=0.3544, norm_factor=71.4112, grad_norm=2.5178\n",
      "Epoch 2: 145/256 - loss_mc=0.2118, loss_t=0.7059, loss_r=1.0554, loss=0.3880, norm_factor=71.6240, grad_norm=7.4161\n",
      "Epoch 2: 146/256 - loss_mc=0.2139, loss_t=0.3489, loss_r=1.1763, loss=0.3665, norm_factor=71.8842, grad_norm=4.2063\n",
      "Epoch 2: 147/256 - loss_mc=0.2130, loss_t=0.3977, loss_r=1.1093, loss=0.3637, norm_factor=72.1466, grad_norm=3.7451\n",
      "Epoch 2: 148/256 - loss_mc=0.2124, loss_t=1.3184, loss_r=1.0116, loss=0.4454, norm_factor=72.4166, grad_norm=7.0008\n",
      "Epoch 2: 149/256 - loss_mc=0.2101, loss_t=0.3969, loss_r=0.9999, loss=0.3498, norm_factor=72.7483, grad_norm=3.2253\n",
      "Epoch 2: 150/256 - loss_mc=0.2020, loss_t=0.3098, loss_r=1.0077, loss=0.3337, norm_factor=73.0764, grad_norm=3.1699\n",
      "Epoch 2: 151/256 - loss_mc=0.2113, loss_t=0.7027, loss_r=0.9934, loss=0.3809, norm_factor=73.4164, grad_norm=10.7173\n",
      "Epoch 2: 152/256 - loss_mc=0.2033, loss_t=0.3139, loss_r=0.8517, loss=0.3199, norm_factor=73.7011, grad_norm=2.8086\n",
      "Epoch 2: 153/256 - loss_mc=0.2029, loss_t=0.4234, loss_r=0.7659, loss=0.3219, norm_factor=74.0062, grad_norm=8.6477\n",
      "Epoch 2: 154/256 - loss_mc=0.2016, loss_t=0.3481, loss_r=0.7687, loss=0.3133, norm_factor=74.3222, grad_norm=2.7769\n",
      "Epoch 2: 155/256 - loss_mc=0.2044, loss_t=0.3605, loss_r=0.8597, loss=0.3265, norm_factor=74.6594, grad_norm=4.0855\n",
      "Epoch 2: 156/256 - loss_mc=0.2099, loss_t=0.4413, loss_r=0.8854, loss=0.3426, norm_factor=74.9955, grad_norm=5.5134\n",
      "Epoch 2: 157/256 - loss_mc=0.1993, loss_t=0.4212, loss_r=0.8257, loss=0.3240, norm_factor=75.3357, grad_norm=4.5244\n",
      "Epoch 2: 158/256 - loss_mc=0.2006, loss_t=0.3322, loss_r=0.8652, loss=0.3203, norm_factor=75.6831, grad_norm=4.2127\n",
      "Epoch 2: 159/256 - loss_mc=0.1917, loss_t=0.3247, loss_r=0.7567, loss=0.2998, norm_factor=76.0405, grad_norm=4.0372\n",
      "Epoch 2: 160/256 - loss_mc=0.1914, loss_t=0.5714, loss_r=0.6630, loss=0.3148, norm_factor=76.4108, grad_norm=7.0329\n",
      "Epoch 2: 161/256 - loss_mc=0.1914, loss_t=0.4427, loss_r=0.6713, loss=0.3028, norm_factor=76.7923, grad_norm=2.9085\n",
      "Epoch 2: 162/256 - loss_mc=0.1943, loss_t=0.5074, loss_r=0.7455, loss=0.3195, norm_factor=77.1929, grad_norm=3.8894\n",
      "Epoch 2: 163/256 - loss_mc=0.1922, loss_t=0.7178, loss_r=0.7003, loss=0.3341, norm_factor=77.6048, grad_norm=11.5399\n",
      "Epoch 2: 164/256 - loss_mc=0.1861, loss_t=0.6492, loss_r=0.6645, loss=0.3175, norm_factor=77.9961, grad_norm=10.1103\n",
      "Epoch 2: 165/256 - loss_mc=0.1857, loss_t=0.6105, loss_r=0.7389, loss=0.3206, norm_factor=78.4259, grad_norm=3.6961\n",
      "Epoch 2: 166/256 - loss_mc=0.1909, loss_t=0.7825, loss_r=0.7721, loss=0.3464, norm_factor=78.8684, grad_norm=13.9579\n",
      "Epoch 2: 167/256 - loss_mc=0.1890, loss_t=1.1194, loss_r=0.7685, loss=0.3778, norm_factor=79.3334, grad_norm=16.0067\n",
      "Epoch 2: 168/256 - loss_mc=0.1843, loss_t=0.5107, loss_r=0.6340, loss=0.2987, norm_factor=79.7608, grad_norm=4.4630\n",
      "Epoch 2: 169/256 - loss_mc=0.1830, loss_t=0.6162, loss_r=0.6537, loss=0.3100, norm_factor=80.2062, grad_norm=9.5477\n",
      "Epoch 2: 170/256 - loss_mc=0.1865, loss_t=0.6368, loss_r=0.6387, loss=0.3141, norm_factor=80.6059, grad_norm=5.6700\n",
      "Epoch 2: 171/256 - loss_mc=0.1850, loss_t=0.7251, loss_r=0.7092, loss=0.3284, norm_factor=81.0300, grad_norm=16.4860\n",
      "Epoch 2: 172/256 - loss_mc=0.1856, loss_t=0.6614, loss_r=0.7309, loss=0.3248, norm_factor=81.3911, grad_norm=6.9897\n",
      "Epoch 2: 173/256 - loss_mc=0.1916, loss_t=0.9522, loss_r=0.7869, loss=0.3655, norm_factor=81.8034, grad_norm=7.0750\n",
      "Epoch 2: 174/256 - loss_mc=0.1939, loss_t=1.3093, loss_r=0.7565, loss=0.4005, norm_factor=82.2480, grad_norm=11.7945\n",
      "Epoch 2: 175/256 - loss_mc=0.1922, loss_t=1.9873, loss_r=0.8031, loss=0.4713, norm_factor=82.5167, grad_norm=20.2345\n",
      "Epoch 2: 176/256 - loss_mc=0.1826, loss_t=1.1894, loss_r=0.6624, loss=0.3678, norm_factor=82.5856, grad_norm=15.9862\n",
      "Epoch 2: 177/256 - loss_mc=0.1871, loss_t=0.4374, loss_r=0.8269, loss=0.3135, norm_factor=82.6234, grad_norm=3.1459\n",
      "Epoch 2: 178/256 - loss_mc=0.1785, loss_t=0.7696, loss_r=0.8977, loss=0.3453, norm_factor=82.6887, grad_norm=4.8726\n",
      "Epoch 2: 179/256 - loss_mc=0.1758, loss_t=1.0084, loss_r=0.9780, loss=0.3744, norm_factor=82.7709, grad_norm=19.0696\n",
      "Epoch 2: 180/256 - loss_mc=0.1774, loss_t=1.9512, loss_r=0.9382, loss=0.4664, norm_factor=82.7402, grad_norm=9.1484\n",
      "Epoch 2: 181/256 - loss_mc=0.1826, loss_t=2.0431, loss_r=0.9579, loss=0.4827, norm_factor=82.7422, grad_norm=17.5857\n",
      "Epoch 2: 182/256 - loss_mc=0.1843, loss_t=1.1694, loss_r=1.0074, loss=0.4020, norm_factor=82.5481, grad_norm=18.4687\n",
      "Epoch 2: 183/256 - loss_mc=0.1874, loss_t=1.5665, loss_r=1.0273, loss=0.4467, norm_factor=82.2715, grad_norm=12.3879\n",
      "Epoch 2: 184/256 - loss_mc=0.2002, loss_t=1.6429, loss_r=1.1038, loss=0.4749, norm_factor=81.9942, grad_norm=21.4727\n",
      "Epoch 2: 185/256 - loss_mc=0.2018, loss_t=1.3124, loss_r=1.1367, loss=0.4467, norm_factor=81.8016, grad_norm=16.3785\n",
      "Epoch 2: 186/256 - loss_mc=0.2009, loss_t=0.7986, loss_r=1.1581, loss=0.3965, norm_factor=81.4458, grad_norm=7.4998\n",
      "Epoch 2: 187/256 - loss_mc=0.1988, loss_t=0.7510, loss_r=1.1622, loss=0.3901, norm_factor=81.0896, grad_norm=3.8496\n",
      "Epoch 2: 188/256 - loss_mc=0.2029, loss_t=0.8640, loss_r=1.2215, loss=0.4115, norm_factor=80.7325, grad_norm=4.0189\n",
      "Epoch 2: 189/256 - loss_mc=0.2060, loss_t=0.5166, loss_r=1.2153, loss=0.3792, norm_factor=80.4128, grad_norm=6.5260\n",
      "Epoch 2: 190/256 - loss_mc=0.2086, loss_t=1.1823, loss_r=1.2396, loss=0.4508, norm_factor=80.0854, grad_norm=6.9729\n",
      "Epoch 2: 191/256 - loss_mc=0.2103, loss_t=0.8644, loss_r=1.2217, loss=0.4189, norm_factor=79.7280, grad_norm=9.3924\n",
      "Epoch 2: 192/256 - loss_mc=0.2157, loss_t=0.6261, loss_r=1.2489, loss=0.4032, norm_factor=79.4195, grad_norm=6.1532\n",
      "Epoch 2: 193/256 - loss_mc=0.2122, loss_t=0.6445, loss_r=1.2620, loss=0.4028, norm_factor=79.0861, grad_norm=4.4841\n",
      "Epoch 2: 194/256 - loss_mc=0.2044, loss_t=0.5094, loss_r=1.2221, loss=0.3776, norm_factor=78.7237, grad_norm=1.4907\n",
      "Epoch 2: 195/256 - loss_mc=0.2079, loss_t=0.4604, loss_r=1.3179, loss=0.3858, norm_factor=78.3497, grad_norm=2.7440\n",
      "Epoch 2: 196/256 - loss_mc=0.2072, loss_t=0.5148, loss_r=1.3016, loss=0.3888, norm_factor=77.9430, grad_norm=2.7166\n",
      "Epoch 2: 197/256 - loss_mc=0.1973, loss_t=0.5495, loss_r=1.2849, loss=0.3807, norm_factor=77.5181, grad_norm=5.8537\n",
      "Epoch 2: 198/256 - loss_mc=0.2050, loss_t=0.5045, loss_r=1.3573, loss=0.3912, norm_factor=77.1558, grad_norm=3.1464\n",
      "Epoch 2: 199/256 - loss_mc=0.2090, loss_t=0.5316, loss_r=1.3556, loss=0.3978, norm_factor=76.7705, grad_norm=2.6868\n",
      "Epoch 2: 200/256 - loss_mc=0.2062, loss_t=0.5110, loss_r=1.2842, loss=0.3857, norm_factor=76.3760, grad_norm=6.2236\n",
      "Epoch 2: 201/256 - loss_mc=0.2023, loss_t=0.3523, loss_r=1.2785, loss=0.3654, norm_factor=75.9774, grad_norm=2.4602\n",
      "Epoch 2: 202/256 - loss_mc=0.2064, loss_t=0.4673, loss_r=1.3187, loss=0.3850, norm_factor=75.5908, grad_norm=3.3224\n",
      "Epoch 2: 203/256 - loss_mc=0.2125, loss_t=0.4128, loss_r=1.3055, loss=0.3843, norm_factor=75.2064, grad_norm=2.4062\n",
      "Epoch 2: 204/256 - loss_mc=0.2023, loss_t=0.3494, loss_r=1.2089, loss=0.3581, norm_factor=74.8333, grad_norm=1.6539\n",
      "Epoch 2: 205/256 - loss_mc=0.2043, loss_t=0.6371, loss_r=1.2088, loss=0.3889, norm_factor=74.4929, grad_norm=13.4889\n",
      "Epoch 2: 206/256 - loss_mc=0.2044, loss_t=0.3438, loss_r=1.2507, loss=0.3639, norm_factor=74.2438, grad_norm=2.4208\n",
      "Epoch 2: 207/256 - loss_mc=0.1971, loss_t=0.2959, loss_r=1.1383, loss=0.3405, norm_factor=74.0222, grad_norm=2.0539\n",
      "Epoch 2: 208/256 - loss_mc=0.2002, loss_t=0.2865, loss_r=1.1466, loss=0.3435, norm_factor=73.8339, grad_norm=1.5085\n",
      "Epoch 2: 209/256 - loss_mc=0.1955, loss_t=0.3760, loss_r=1.1705, loss=0.3502, norm_factor=73.6760, grad_norm=2.9036\n",
      "Epoch 2: 210/256 - loss_mc=0.1958, loss_t=1.1762, loss_r=1.1527, loss=0.4287, norm_factor=73.5518, grad_norm=9.9139\n",
      "Epoch 2: 211/256 - loss_mc=0.1963, loss_t=0.2963, loss_r=1.1285, loss=0.3388, norm_factor=73.3389, grad_norm=1.2568\n",
      "Epoch 2: 212/256 - loss_mc=0.1979, loss_t=1.5748, loss_r=1.0539, loss=0.4607, norm_factor=73.1729, grad_norm=11.9905\n",
      "Epoch 2: 213/256 - loss_mc=0.1986, loss_t=0.3197, loss_r=1.0851, loss=0.3391, norm_factor=73.0091, grad_norm=2.4879\n",
      "Epoch 2: 214/256 - loss_mc=0.1989, loss_t=0.8988, loss_r=0.9895, loss=0.3877, norm_factor=72.8841, grad_norm=5.7671\n",
      "Epoch 2: 215/256 - loss_mc=0.1977, loss_t=0.5055, loss_r=1.0136, loss=0.3496, norm_factor=72.8459, grad_norm=3.4796\n",
      "Epoch 2: 216/256 - loss_mc=0.1976, loss_t=0.4174, loss_r=0.9594, loss=0.3352, norm_factor=72.8421, grad_norm=7.4188\n",
      "Epoch 2: 217/256 - loss_mc=0.2039, loss_t=1.8115, loss_r=0.9986, loss=0.4849, norm_factor=72.8465, grad_norm=10.3275\n",
      "Epoch 2: 218/256 - loss_mc=0.2018, loss_t=0.9694, loss_r=0.9811, loss=0.3968, norm_factor=72.8046, grad_norm=13.1617\n",
      "Epoch 2: 219/256 - loss_mc=0.2070, loss_t=1.2095, loss_r=1.0425, loss=0.4322, norm_factor=72.7749, grad_norm=8.4910\n",
      "Epoch 2: 220/256 - loss_mc=0.2033, loss_t=1.8163, loss_r=1.0838, loss=0.4933, norm_factor=72.8337, grad_norm=7.3128\n",
      "Epoch 2: 221/256 - loss_mc=0.2080, loss_t=0.5822, loss_r=1.1714, loss=0.3834, norm_factor=72.9125, grad_norm=5.8574\n",
      "Epoch 2: 222/256 - loss_mc=0.2079, loss_t=1.1237, loss_r=1.1472, loss=0.4350, norm_factor=72.9936, grad_norm=8.1014\n",
      "Epoch 2: 223/256 - loss_mc=0.2091, loss_t=0.5516, loss_r=1.1682, loss=0.3811, norm_factor=73.1656, grad_norm=4.9989\n",
      "Epoch 2: 224/256 - loss_mc=0.2112, loss_t=0.5303, loss_r=1.2316, loss=0.3874, norm_factor=73.3289, grad_norm=4.1791\n",
      "Epoch 2: 225/256 - loss_mc=0.2098, loss_t=1.2744, loss_r=1.1208, loss=0.4494, norm_factor=73.4722, grad_norm=10.8067\n",
      "Epoch 2: 226/256 - loss_mc=0.2160, loss_t=1.0588, loss_r=1.1977, loss=0.4416, norm_factor=73.5344, grad_norm=8.7450\n",
      "Epoch 2: 227/256 - loss_mc=0.2207, loss_t=1.7480, loss_r=1.0614, loss=0.5016, norm_factor=73.4313, grad_norm=4.7955\n",
      "Epoch 2: 228/256 - loss_mc=0.2222, loss_t=1.1564, loss_r=1.0494, loss=0.4428, norm_factor=73.2833, grad_norm=15.4717\n",
      "Epoch 2: 229/256 - loss_mc=0.2160, loss_t=1.4306, loss_r=1.0778, loss=0.4669, norm_factor=73.1831, grad_norm=26.5905\n",
      "Epoch 2: 230/256 - loss_mc=0.2221, loss_t=1.3245, loss_r=1.1094, loss=0.4655, norm_factor=72.9448, grad_norm=23.9726\n",
      "Epoch 2: 231/256 - loss_mc=0.2059, loss_t=0.6686, loss_r=1.0088, loss=0.3736, norm_factor=72.7090, grad_norm=2.6317\n",
      "Epoch 2: 232/256 - loss_mc=0.2070, loss_t=0.7393, loss_r=1.0318, loss=0.3841, norm_factor=72.5199, grad_norm=6.2021\n",
      "Epoch 2: 233/256 - loss_mc=0.2036, loss_t=1.0035, loss_r=1.0258, loss=0.4066, norm_factor=72.3772, grad_norm=13.9907\n",
      "Epoch 2: 234/256 - loss_mc=0.2120, loss_t=1.0771, loss_r=1.0690, loss=0.4266, norm_factor=72.3701, grad_norm=12.6042\n",
      "Epoch 2: 235/256 - loss_mc=0.2034, loss_t=0.8386, loss_r=1.1185, loss=0.3991, norm_factor=72.3743, grad_norm=11.5664\n",
      "Epoch 2: 236/256 - loss_mc=0.2125, loss_t=0.9951, loss_r=1.1020, loss=0.4222, norm_factor=72.3511, grad_norm=11.0779\n",
      "Epoch 2: 237/256 - loss_mc=0.2056, loss_t=0.5738, loss_r=1.1029, loss=0.3733, norm_factor=72.2461, grad_norm=2.6518\n",
      "Epoch 2: 238/256 - loss_mc=0.2128, loss_t=1.2131, loss_r=1.0862, loss=0.4428, norm_factor=72.1628, grad_norm=4.1492\n",
      "Epoch 2: 239/256 - loss_mc=0.2108, loss_t=0.8422, loss_r=1.1133, loss=0.4063, norm_factor=72.1273, grad_norm=3.0232\n",
      "Epoch 2: 240/256 - loss_mc=0.2014, loss_t=0.5061, loss_r=1.0673, loss=0.3588, norm_factor=72.1519, grad_norm=3.0490\n",
      "Epoch 2: 241/256 - loss_mc=0.2054, loss_t=0.5208, loss_r=1.1077, loss=0.3682, norm_factor=72.1944, grad_norm=2.3375\n",
      "Epoch 2: 242/256 - loss_mc=0.2090, loss_t=0.3927, loss_r=1.0577, loss=0.3540, norm_factor=72.2570, grad_norm=3.5582\n",
      "Epoch 2: 243/256 - loss_mc=0.2056, loss_t=0.4685, loss_r=1.0674, loss=0.3592, norm_factor=72.3307, grad_norm=4.9101\n",
      "Epoch 2: 244/256 - loss_mc=0.2086, loss_t=0.3356, loss_r=1.1279, loss=0.3549, norm_factor=72.4238, grad_norm=2.9753\n",
      "Epoch 2: 245/256 - loss_mc=0.2021, loss_t=0.4102, loss_r=1.0460, loss=0.3478, norm_factor=72.5278, grad_norm=2.5763\n",
      "Epoch 2: 246/256 - loss_mc=0.1999, loss_t=0.3061, loss_r=1.0776, loss=0.3383, norm_factor=72.6492, grad_norm=1.9880\n",
      "Epoch 2: 247/256 - loss_mc=0.1976, loss_t=0.4337, loss_r=0.9735, loss=0.3383, norm_factor=72.7864, grad_norm=3.6139\n",
      "Epoch 2: 248/256 - loss_mc=0.2007, loss_t=0.4323, loss_r=0.9622, loss=0.3402, norm_factor=72.9409, grad_norm=2.5253\n",
      "Epoch 2: 249/256 - loss_mc=0.2007, loss_t=0.3627, loss_r=0.9286, loss=0.3299, norm_factor=73.1171, grad_norm=2.5685\n",
      "Epoch 2: 250/256 - loss_mc=0.2056, loss_t=0.7555, loss_r=0.8574, loss=0.3669, norm_factor=73.3099, grad_norm=8.5663\n",
      "Epoch 2: 251/256 - loss_mc=0.2013, loss_t=0.4440, loss_r=0.8121, loss=0.3269, norm_factor=73.4963, grad_norm=3.3737\n",
      "Epoch 2: 252/256 - loss_mc=0.1991, loss_t=0.4550, loss_r=0.7748, loss=0.3220, norm_factor=73.7014, grad_norm=3.3540\n",
      "Epoch 2: 253/256 - loss_mc=0.1982, loss_t=0.4802, loss_r=0.8381, loss=0.3300, norm_factor=73.9304, grad_norm=5.1022\n",
      "Epoch 2: 254/256 - loss_mc=0.1962, loss_t=0.4885, loss_r=0.7771, loss=0.3228, norm_factor=74.1747, grad_norm=7.7740\n",
      "Epoch 2: 255/256 - loss_mc=0.1917, loss_t=0.8385, loss_r=0.7375, loss=0.3493, norm_factor=74.4359, grad_norm=6.7018\n",
      "Epoch 2: 256/256 - loss_mc=0.1922, loss_t=0.3723, loss_r=0.6941, loss=0.2988, norm_factor=74.6102, grad_norm=3.0863\n",
      "Epoch 3: 1/256 - loss_mc=0.1869, loss_t=0.3746, loss_r=0.6751, loss=0.2919, norm_factor=74.8228, grad_norm=2.2704\n",
      "Epoch 3: 2/256 - loss_mc=0.1903, loss_t=0.3440, loss_r=0.7285, loss=0.2975, norm_factor=75.0719, grad_norm=2.4379\n",
      "Epoch 3: 3/256 - loss_mc=0.1872, loss_t=0.3397, loss_r=0.7084, loss=0.2921, norm_factor=75.3539, grad_norm=2.4830\n",
      "Epoch 3: 4/256 - loss_mc=0.1860, loss_t=0.3000, loss_r=0.7120, loss=0.2872, norm_factor=75.6700, grad_norm=2.1091\n",
      "Epoch 3: 5/256 - loss_mc=0.1829, loss_t=0.3206, loss_r=0.7383, loss=0.2888, norm_factor=76.0167, grad_norm=3.7922\n",
      "Epoch 3: 6/256 - loss_mc=0.1795, loss_t=0.2985, loss_r=0.6927, loss=0.2786, norm_factor=76.3937, grad_norm=1.6906\n",
      "Epoch 3: 7/256 - loss_mc=0.1807, loss_t=0.3193, loss_r=0.7403, loss=0.2867, norm_factor=76.7966, grad_norm=3.3074\n",
      "Epoch 3: 8/256 - loss_mc=0.1835, loss_t=0.3219, loss_r=0.7097, loss=0.2867, norm_factor=77.2298, grad_norm=1.5456\n",
      "Epoch 3: 9/256 - loss_mc=0.1784, loss_t=0.2751, loss_r=0.6921, loss=0.2751, norm_factor=77.6863, grad_norm=2.2525\n",
      "Epoch 3: 10/256 - loss_mc=0.1736, loss_t=0.2667, loss_r=0.6417, loss=0.2645, norm_factor=78.1683, grad_norm=1.9032\n",
      "Epoch 3: 11/256 - loss_mc=0.1708, loss_t=0.3083, loss_r=0.6164, loss=0.2633, norm_factor=78.6752, grad_norm=1.7403\n",
      "Epoch 3: 12/256 - loss_mc=0.1719, loss_t=0.2559, loss_r=0.6630, loss=0.2638, norm_factor=79.2049, grad_norm=2.6787\n",
      "Epoch 3: 13/256 - loss_mc=0.1733, loss_t=0.2016, loss_r=0.5754, loss=0.2510, norm_factor=79.7643, grad_norm=1.3664\n",
      "Epoch 3: 14/256 - loss_mc=0.1705, loss_t=0.2837, loss_r=0.6438, loss=0.2632, norm_factor=80.3497, grad_norm=3.8395\n",
      "Epoch 3: 15/256 - loss_mc=0.1694, loss_t=0.2302, loss_r=0.6326, loss=0.2556, norm_factor=80.9585, grad_norm=2.0373\n",
      "Epoch 3: 16/256 - loss_mc=0.1668, loss_t=0.4103, loss_r=0.5066, loss=0.2585, norm_factor=81.5824, grad_norm=3.8060\n",
      "Epoch 3: 17/256 - loss_mc=0.1629, loss_t=0.2123, loss_r=0.4747, loss=0.2316, norm_factor=82.2641, grad_norm=2.4905\n",
      "Epoch 3: 18/256 - loss_mc=0.1673, loss_t=0.2115, loss_r=0.4519, loss=0.2336, norm_factor=82.9680, grad_norm=3.4444\n",
      "Epoch 3: 19/256 - loss_mc=0.1589, loss_t=0.1975, loss_r=0.4377, loss=0.2224, norm_factor=83.6754, grad_norm=1.8042\n",
      "Epoch 3: 20/256 - loss_mc=0.1565, loss_t=0.2484, loss_r=0.4607, loss=0.2274, norm_factor=84.4079, grad_norm=1.9392\n",
      "Epoch 3: 21/256 - loss_mc=0.1542, loss_t=0.2224, loss_r=0.4566, loss=0.2221, norm_factor=85.1673, grad_norm=1.6167\n",
      "Epoch 3: 22/256 - loss_mc=0.1551, loss_t=1.0643, loss_r=0.4821, loss=0.3098, norm_factor=85.9521, grad_norm=3.8800\n",
      "Epoch 3: 23/256 - loss_mc=0.1496, loss_t=0.1978, loss_r=0.4688, loss=0.2162, norm_factor=86.7718, grad_norm=2.1010\n",
      "Epoch 3: 24/256 - loss_mc=0.1483, loss_t=0.2218, loss_r=0.4278, loss=0.2133, norm_factor=87.6123, grad_norm=1.4268\n",
      "Epoch 3: 25/256 - loss_mc=0.1496, loss_t=0.2205, loss_r=0.4541, loss=0.2171, norm_factor=88.4768, grad_norm=1.6428\n",
      "Epoch 3: 26/256 - loss_mc=0.1467, loss_t=0.2158, loss_r=0.4315, loss=0.2115, norm_factor=89.3589, grad_norm=2.3983\n",
      "Epoch 3: 27/256 - loss_mc=0.1426, loss_t=0.2146, loss_r=0.3933, loss=0.2033, norm_factor=90.2549, grad_norm=2.2966\n",
      "Epoch 3: 28/256 - loss_mc=0.1434, loss_t=0.1887, loss_r=0.4418, loss=0.2065, norm_factor=91.1700, grad_norm=2.8646\n",
      "Epoch 3: 29/256 - loss_mc=0.1328, loss_t=0.1554, loss_r=0.3971, loss=0.1881, norm_factor=92.0986, grad_norm=1.7313\n",
      "Epoch 3: 30/256 - loss_mc=0.1344, loss_t=0.2851, loss_r=0.4174, loss=0.2047, norm_factor=93.0479, grad_norm=3.5837\n",
      "Epoch 3: 31/256 - loss_mc=0.1366, loss_t=0.2038, loss_r=0.4297, loss=0.1999, norm_factor=94.0096, grad_norm=1.4041\n",
      "Epoch 3: 32/256 - loss_mc=0.1331, loss_t=0.2512, loss_r=0.3941, loss=0.1976, norm_factor=94.9872, grad_norm=2.1469\n",
      "Epoch 3: 33/256 - loss_mc=0.1297, loss_t=0.2374, loss_r=0.3679, loss=0.1902, norm_factor=95.9938, grad_norm=2.4208\n",
      "Epoch 3: 34/256 - loss_mc=0.1251, loss_t=0.2122, loss_r=0.3470, loss=0.1811, norm_factor=97.0100, grad_norm=2.4936\n",
      "Epoch 3: 35/256 - loss_mc=0.1213, loss_t=0.1976, loss_r=0.4323, loss=0.1843, norm_factor=98.0381, grad_norm=2.4995\n",
      "Epoch 3: 36/256 - loss_mc=0.1214, loss_t=0.1828, loss_r=0.3397, loss=0.1737, norm_factor=99.0851, grad_norm=2.2034\n",
      "Epoch 3: 37/256 - loss_mc=0.1188, loss_t=0.1926, loss_r=0.3637, loss=0.1744, norm_factor=100.1463, grad_norm=1.2145\n",
      "Epoch 3: 38/256 - loss_mc=0.1160, loss_t=0.1956, loss_r=0.3651, loss=0.1721, norm_factor=101.2189, grad_norm=4.0743\n",
      "Epoch 3: 39/256 - loss_mc=0.1170, loss_t=0.2241, loss_r=0.3162, loss=0.1711, norm_factor=102.3118, grad_norm=3.3240\n",
      "Epoch 3: 40/256 - loss_mc=0.1134, loss_t=0.1822, loss_r=0.3287, loss=0.1644, norm_factor=103.4245, grad_norm=2.3695\n",
      "Epoch 3: 41/256 - loss_mc=0.1084, loss_t=0.2024, loss_r=0.2819, loss=0.1568, norm_factor=104.5587, grad_norm=1.2262\n",
      "Epoch 3: 42/256 - loss_mc=0.1056, loss_t=0.1544, loss_r=0.2493, loss=0.1460, norm_factor=105.7137, grad_norm=1.3871\n",
      "Epoch 3: 43/256 - loss_mc=0.1021, loss_t=0.1945, loss_r=0.2578, loss=0.1473, norm_factor=106.8949, grad_norm=2.1247\n",
      "Epoch 3: 44/256 - loss_mc=0.0996, loss_t=0.1855, loss_r=0.2365, loss=0.1418, norm_factor=108.0975, grad_norm=2.3587\n",
      "Epoch 3: 45/256 - loss_mc=0.0999, loss_t=0.1938, loss_r=0.2782, loss=0.1471, norm_factor=109.3229, grad_norm=1.4561\n",
      "Epoch 3: 46/256 - loss_mc=0.0987, loss_t=0.1550, loss_r=0.2494, loss=0.1392, norm_factor=110.5640, grad_norm=1.5707\n",
      "Epoch 3: 47/256 - loss_mc=0.0975, loss_t=0.1499, loss_r=0.2172, loss=0.1342, norm_factor=111.8185, grad_norm=2.0311\n",
      "Epoch 3: 48/256 - loss_mc=0.0923, loss_t=0.1569, loss_r=0.2352, loss=0.1315, norm_factor=113.0944, grad_norm=2.5273\n",
      "Epoch 3: 49/256 - loss_mc=0.0909, loss_t=0.1509, loss_r=0.2170, loss=0.1277, norm_factor=114.3970, grad_norm=1.5965\n",
      "Epoch 3: 50/256 - loss_mc=0.0892, loss_t=0.1945, loss_r=0.2231, loss=0.1309, norm_factor=115.7293, grad_norm=1.3353\n",
      "Epoch 3: 51/256 - loss_mc=0.0843, loss_t=0.1913, loss_r=0.2138, loss=0.1248, norm_factor=117.0719, grad_norm=2.4376\n",
      "Epoch 3: 52/256 - loss_mc=0.0837, loss_t=0.1721, loss_r=0.2136, loss=0.1223, norm_factor=118.4330, grad_norm=1.8870\n",
      "Epoch 3: 53/256 - loss_mc=0.0775, loss_t=0.1342, loss_r=0.1980, loss=0.1107, norm_factor=119.8134, grad_norm=1.2513\n",
      "Epoch 3: 54/256 - loss_mc=0.0781, loss_t=0.1392, loss_r=0.2039, loss=0.1124, norm_factor=121.2176, grad_norm=0.9714\n",
      "Epoch 3: 55/256 - loss_mc=0.0766, loss_t=0.1816, loss_r=0.1839, loss=0.1132, norm_factor=122.6215, grad_norm=1.5441\n",
      "Epoch 3: 56/256 - loss_mc=0.0780, loss_t=0.1688, loss_r=0.2089, loss=0.1158, norm_factor=124.0432, grad_norm=2.3622\n",
      "Epoch 3: 57/256 - loss_mc=0.0720, loss_t=0.1593, loss_r=0.1857, loss=0.1065, norm_factor=125.4722, grad_norm=2.0404\n",
      "Epoch 3: 58/256 - loss_mc=0.0703, loss_t=0.1291, loss_r=0.1771, loss=0.1009, norm_factor=126.9071, grad_norm=1.6310\n",
      "Epoch 3: 59/256 - loss_mc=0.0697, loss_t=0.1355, loss_r=0.1899, loss=0.1022, norm_factor=128.3586, grad_norm=1.4231\n",
      "Epoch 3: 60/256 - loss_mc=0.0654, loss_t=0.1504, loss_r=0.1585, loss=0.0963, norm_factor=129.8224, grad_norm=1.1375\n",
      "Epoch 3: 61/256 - loss_mc=0.0646, loss_t=0.1602, loss_r=0.1433, loss=0.0949, norm_factor=131.2981, grad_norm=1.4598\n",
      "Epoch 3: 62/256 - loss_mc=0.0643, loss_t=0.1515, loss_r=0.1756, loss=0.0971, norm_factor=132.7795, grad_norm=1.7438\n",
      "Epoch 3: 63/256 - loss_mc=0.0640, loss_t=0.1767, loss_r=0.1748, loss=0.0992, norm_factor=134.2424, grad_norm=2.6953\n",
      "Epoch 3: 64/256 - loss_mc=0.0600, loss_t=0.1503, loss_r=0.1721, loss=0.0922, norm_factor=135.6931, grad_norm=2.3348\n",
      "Epoch 3: 65/256 - loss_mc=0.0607, loss_t=0.1290, loss_r=0.1674, loss=0.0903, norm_factor=137.1477, grad_norm=1.5693\n",
      "Epoch 3: 66/256 - loss_mc=0.0568, loss_t=0.1292, loss_r=0.1532, loss=0.0851, norm_factor=138.6099, grad_norm=2.0095\n",
      "Epoch 3: 67/256 - loss_mc=0.0545, loss_t=0.1452, loss_r=0.1660, loss=0.0856, norm_factor=140.0787, grad_norm=1.6541\n",
      "Epoch 3: 68/256 - loss_mc=0.0571, loss_t=0.1285, loss_r=0.1563, loss=0.0856, norm_factor=141.5461, grad_norm=1.7862\n",
      "Epoch 3: 69/256 - loss_mc=0.0531, loss_t=0.1198, loss_r=0.1406, loss=0.0791, norm_factor=142.9940, grad_norm=2.0740\n",
      "Epoch 3: 70/256 - loss_mc=0.0504, loss_t=0.1162, loss_r=0.1423, loss=0.0763, norm_factor=144.4269, grad_norm=1.9266\n",
      "Epoch 3: 71/256 - loss_mc=0.0467, loss_t=0.1390, loss_r=0.1386, loss=0.0744, norm_factor=145.8589, grad_norm=2.1413\n",
      "Epoch 3: 72/256 - loss_mc=0.0473, loss_t=0.1193, loss_r=0.1279, loss=0.0720, norm_factor=147.2803, grad_norm=1.6977\n",
      "Epoch 3: 73/256 - loss_mc=0.0490, loss_t=0.1197, loss_r=0.1507, loss=0.0760, norm_factor=148.6926, grad_norm=1.3449\n",
      "Epoch 3: 74/256 - loss_mc=0.0439, loss_t=0.1178, loss_r=0.1062, loss=0.0663, norm_factor=150.0756, grad_norm=1.0910\n",
      "Epoch 3: 75/256 - loss_mc=0.0429, loss_t=0.1183, loss_r=0.1141, loss=0.0662, norm_factor=151.4507, grad_norm=1.0701\n",
      "Epoch 3: 76/256 - loss_mc=0.0438, loss_t=0.1065, loss_r=0.1157, loss=0.0660, norm_factor=152.8059, grad_norm=0.8098\n",
      "Epoch 3: 77/256 - loss_mc=0.0414, loss_t=0.1332, loss_r=0.1086, loss=0.0655, norm_factor=154.1188, grad_norm=1.5859\n",
      "Epoch 3: 78/256 - loss_mc=0.0418, loss_t=0.1672, loss_r=0.1194, loss=0.0705, norm_factor=155.4036, grad_norm=2.5167\n",
      "Epoch 3: 79/256 - loss_mc=0.0385, loss_t=0.1460, loss_r=0.1108, loss=0.0642, norm_factor=156.6544, grad_norm=1.5810\n",
      "Epoch 3: 80/256 - loss_mc=0.0380, loss_t=0.1132, loss_r=0.1154, loss=0.0608, norm_factor=157.8820, grad_norm=1.6576\n",
      "Epoch 3: 81/256 - loss_mc=0.0380, loss_t=0.1301, loss_r=0.1001, loss=0.0610, norm_factor=159.0990, grad_norm=2.3145\n",
      "Epoch 3: 82/256 - loss_mc=0.0357, loss_t=0.0970, loss_r=0.1036, loss=0.0557, norm_factor=160.2935, grad_norm=1.6412\n",
      "Epoch 3: 83/256 - loss_mc=0.0357, loss_t=0.0939, loss_r=0.1071, loss=0.0558, norm_factor=161.4648, grad_norm=1.6974\n",
      "Epoch 3: 84/256 - loss_mc=0.0366, loss_t=0.1231, loss_r=0.0968, loss=0.0586, norm_factor=162.6145, grad_norm=1.1035\n",
      "Epoch 3: 85/256 - loss_mc=0.0342, loss_t=0.1313, loss_r=0.1096, loss=0.0583, norm_factor=163.7418, grad_norm=1.5154\n",
      "Epoch 3: 86/256 - loss_mc=0.0355, loss_t=0.1558, loss_r=0.1096, loss=0.0621, norm_factor=164.8418, grad_norm=2.6714\n",
      "Epoch 3: 87/256 - loss_mc=0.0363, loss_t=0.1130, loss_r=0.0912, loss=0.0567, norm_factor=165.9180, grad_norm=1.6963\n",
      "Epoch 3: 88/256 - loss_mc=0.0325, loss_t=0.1049, loss_r=0.0994, loss=0.0529, norm_factor=166.9587, grad_norm=1.9054\n",
      "Epoch 3: 89/256 - loss_mc=0.0330, loss_t=0.0989, loss_r=0.0840, loss=0.0513, norm_factor=167.9957, grad_norm=1.1945\n",
      "Epoch 3: 90/256 - loss_mc=0.0365, loss_t=0.1182, loss_r=0.1016, loss=0.0585, norm_factor=169.0016, grad_norm=1.1884\n",
      "Epoch 3: 91/256 - loss_mc=0.0386, loss_t=0.1174, loss_r=0.1085, loss=0.0612, norm_factor=169.9684, grad_norm=1.9546\n",
      "Epoch 3: 92/256 - loss_mc=0.0322, loss_t=0.1331, loss_r=0.0951, loss=0.0550, norm_factor=170.8679, grad_norm=1.9495\n",
      "Epoch 3: 93/256 - loss_mc=0.0308, loss_t=0.1210, loss_r=0.0867, loss=0.0515, norm_factor=171.7432, grad_norm=1.9373\n",
      "Epoch 3: 94/256 - loss_mc=0.0300, loss_t=0.1032, loss_r=0.0850, loss=0.0488, norm_factor=172.5934, grad_norm=1.4958\n",
      "Epoch 3: 95/256 - loss_mc=0.0273, loss_t=0.1058, loss_r=0.0794, loss=0.0459, norm_factor=173.4144, grad_norm=1.5693\n",
      "Epoch 3: 96/256 - loss_mc=0.0287, loss_t=0.1185, loss_r=0.0808, loss=0.0487, norm_factor=174.2328, grad_norm=1.6497\n",
      "Epoch 3: 97/256 - loss_mc=0.0285, loss_t=0.1172, loss_r=0.0793, loss=0.0481, norm_factor=175.0387, grad_norm=1.9167\n",
      "Epoch 3: 98/256 - loss_mc=0.0264, loss_t=0.0894, loss_r=0.0808, loss=0.0434, norm_factor=175.8274, grad_norm=1.5301\n",
      "Epoch 3: 99/256 - loss_mc=0.0268, loss_t=0.0854, loss_r=0.0750, loss=0.0428, norm_factor=176.6031, grad_norm=2.2563\n",
      "Epoch 3: 100/256 - loss_mc=0.0267, loss_t=0.1073, loss_r=0.0737, loss=0.0448, norm_factor=177.3703, grad_norm=1.8715\n",
      "Epoch 3: 101/256 - loss_mc=0.0267, loss_t=0.0939, loss_r=0.0710, loss=0.0432, norm_factor=178.1102, grad_norm=1.5281\n",
      "Epoch 3: 102/256 - loss_mc=0.0259, loss_t=0.0941, loss_r=0.0747, loss=0.0428, norm_factor=178.8354, grad_norm=1.9137\n",
      "Epoch 3: 103/256 - loss_mc=0.0309, loss_t=0.1062, loss_r=0.0937, loss=0.0509, norm_factor=179.5592, grad_norm=2.0059\n",
      "Epoch 3: 104/256 - loss_mc=0.0286, loss_t=0.1074, loss_r=0.0699, loss=0.0463, norm_factor=180.2343, grad_norm=1.5785\n",
      "Epoch 3: 105/256 - loss_mc=0.0277, loss_t=0.0991, loss_r=0.0660, loss=0.0442, norm_factor=180.8808, grad_norm=1.1503\n",
      "Epoch 3: 106/256 - loss_mc=0.0264, loss_t=0.1033, loss_r=0.0782, loss=0.0446, norm_factor=181.5029, grad_norm=1.6724\n",
      "Epoch 3: 107/256 - loss_mc=0.0248, loss_t=0.0929, loss_r=0.0675, loss=0.0409, norm_factor=182.1015, grad_norm=1.1781\n",
      "Epoch 3: 108/256 - loss_mc=0.0277, loss_t=0.1141, loss_r=0.0650, loss=0.0456, norm_factor=182.6859, grad_norm=2.0035\n",
      "Epoch 3: 109/256 - loss_mc=0.0254, loss_t=0.0885, loss_r=0.0751, loss=0.0418, norm_factor=183.2368, grad_norm=1.6011\n",
      "Epoch 3: 110/256 - loss_mc=0.0239, loss_t=0.1205, loss_r=0.0659, loss=0.0426, norm_factor=183.7722, grad_norm=1.1413\n",
      "Epoch 3: 111/256 - loss_mc=0.0266, loss_t=0.1273, loss_r=0.0727, loss=0.0466, norm_factor=184.3062, grad_norm=1.7232\n",
      "Epoch 3: 112/256 - loss_mc=0.0230, loss_t=0.1072, loss_r=0.0609, loss=0.0398, norm_factor=184.8161, grad_norm=1.9284\n",
      "Epoch 3: 113/256 - loss_mc=0.0234, loss_t=0.0996, loss_r=0.0623, loss=0.0396, norm_factor=185.3334, grad_norm=0.9739\n",
      "Epoch 3: 114/256 - loss_mc=0.0251, loss_t=0.0888, loss_r=0.0608, loss=0.0401, norm_factor=185.8320, grad_norm=1.7965\n",
      "Epoch 3: 115/256 - loss_mc=0.0211, loss_t=0.0894, loss_r=0.0635, loss=0.0364, norm_factor=186.3160, grad_norm=1.6663\n",
      "Epoch 3: 116/256 - loss_mc=0.0230, loss_t=0.0963, loss_r=0.0664, loss=0.0393, norm_factor=186.8114, grad_norm=1.5283\n",
      "Epoch 3: 117/256 - loss_mc=0.0237, loss_t=0.1068, loss_r=0.0603, loss=0.0404, norm_factor=187.3026, grad_norm=1.1709\n",
      "Epoch 3: 118/256 - loss_mc=0.0210, loss_t=0.0717, loss_r=0.0621, loss=0.0343, norm_factor=187.7866, grad_norm=1.0743\n",
      "Epoch 3: 119/256 - loss_mc=0.0227, loss_t=0.0984, loss_r=0.0562, loss=0.0382, norm_factor=188.2761, grad_norm=2.2415\n",
      "Epoch 3: 120/256 - loss_mc=0.0221, loss_t=0.0855, loss_r=0.0587, loss=0.0365, norm_factor=188.7600, grad_norm=0.9832\n",
      "Epoch 3: 121/256 - loss_mc=0.0267, loss_t=0.0981, loss_r=0.0541, loss=0.0419, norm_factor=189.2379, grad_norm=1.3019\n",
      "Epoch 3: 122/256 - loss_mc=0.0210, loss_t=0.0799, loss_r=0.0594, loss=0.0350, norm_factor=189.6855, grad_norm=1.0256\n",
      "Epoch 3: 123/256 - loss_mc=0.0228, loss_t=0.0774, loss_r=0.0570, loss=0.0363, norm_factor=190.1464, grad_norm=1.4597\n",
      "Epoch 3: 124/256 - loss_mc=0.0208, loss_t=0.0862, loss_r=0.0551, loss=0.0349, norm_factor=190.5984, grad_norm=1.5173\n",
      "Epoch 3: 125/256 - loss_mc=0.0196, loss_t=0.0932, loss_r=0.0535, loss=0.0343, norm_factor=191.0471, grad_norm=1.3539\n",
      "Epoch 3: 126/256 - loss_mc=0.0218, loss_t=0.0849, loss_r=0.0606, loss=0.0363, norm_factor=191.5036, grad_norm=1.1951\n",
      "Epoch 3: 127/256 - loss_mc=0.0225, loss_t=0.0898, loss_r=0.0541, loss=0.0369, norm_factor=191.9557, grad_norm=1.3182\n",
      "Epoch 3: 128/256 - loss_mc=0.0223, loss_t=0.0818, loss_r=0.0554, loss=0.0360, norm_factor=192.4023, grad_norm=2.0293\n",
      "Epoch 3: 129/256 - loss_mc=0.0242, loss_t=0.1072, loss_r=0.0590, loss=0.0408, norm_factor=192.8385, grad_norm=1.2104\n",
      "Epoch 3: 130/256 - loss_mc=0.0212, loss_t=0.0872, loss_r=0.0499, loss=0.0349, norm_factor=193.2496, grad_norm=1.6118\n",
      "Epoch 3: 131/256 - loss_mc=0.0202, loss_t=0.0774, loss_r=0.0529, loss=0.0332, norm_factor=193.6528, grad_norm=1.1554\n",
      "Epoch 3: 132/256 - loss_mc=0.0205, loss_t=0.0881, loss_r=0.0628, loss=0.0356, norm_factor=194.0594, grad_norm=1.7541\n",
      "Epoch 3: 133/256 - loss_mc=0.0215, loss_t=0.0912, loss_r=0.0532, loss=0.0360, norm_factor=194.4594, grad_norm=1.6480\n",
      "Epoch 3: 134/256 - loss_mc=0.0180, loss_t=0.0814, loss_r=0.0547, loss=0.0316, norm_factor=194.8435, grad_norm=2.0908\n",
      "Epoch 3: 135/256 - loss_mc=0.0201, loss_t=0.0798, loss_r=0.0527, loss=0.0333, norm_factor=195.2434, grad_norm=1.9439\n",
      "Epoch 3: 136/256 - loss_mc=0.0193, loss_t=0.0887, loss_r=0.0452, loss=0.0327, norm_factor=195.6432, grad_norm=1.2999\n",
      "Epoch 3: 137/256 - loss_mc=0.0176, loss_t=0.0807, loss_r=0.0470, loss=0.0304, norm_factor=196.0380, grad_norm=1.8932\n",
      "Epoch 3: 138/256 - loss_mc=0.0214, loss_t=0.0917, loss_r=0.0500, loss=0.0356, norm_factor=196.4417, grad_norm=2.5519\n",
      "Epoch 3: 139/256 - loss_mc=0.0209, loss_t=0.0858, loss_r=0.0484, loss=0.0343, norm_factor=196.8290, grad_norm=1.1667\n",
      "Epoch 3: 140/256 - loss_mc=0.0216, loss_t=0.0813, loss_r=0.0478, loss=0.0345, norm_factor=197.2016, grad_norm=1.6049\n",
      "Epoch 3: 141/256 - loss_mc=0.0193, loss_t=0.0792, loss_r=0.0526, loss=0.0325, norm_factor=197.5632, grad_norm=1.4180\n",
      "Epoch 3: 142/256 - loss_mc=0.0203, loss_t=0.0839, loss_r=0.0469, loss=0.0334, norm_factor=197.9249, grad_norm=2.0814\n",
      "Epoch 3: 143/256 - loss_mc=0.0191, loss_t=0.0794, loss_r=0.0447, loss=0.0315, norm_factor=198.2786, grad_norm=1.4143\n",
      "Epoch 3: 144/256 - loss_mc=0.0184, loss_t=0.0747, loss_r=0.0452, loss=0.0304, norm_factor=198.6394, grad_norm=1.6624\n",
      "Epoch 3: 145/256 - loss_mc=0.0179, loss_t=0.0749, loss_r=0.0409, loss=0.0295, norm_factor=199.0088, grad_norm=1.1500\n",
      "Epoch 3: 146/256 - loss_mc=0.0187, loss_t=0.0747, loss_r=0.0402, loss=0.0302, norm_factor=199.3811, grad_norm=1.6461\n",
      "Epoch 3: 147/256 - loss_mc=0.0170, loss_t=0.0830, loss_r=0.0446, loss=0.0298, norm_factor=199.7470, grad_norm=1.8428\n",
      "Epoch 3: 148/256 - loss_mc=0.0180, loss_t=0.0770, loss_r=0.0453, loss=0.0303, norm_factor=200.1184, grad_norm=1.3745\n",
      "Epoch 3: 149/256 - loss_mc=0.0170, loss_t=0.0718, loss_r=0.0394, loss=0.0281, norm_factor=200.4868, grad_norm=1.3708\n",
      "Epoch 3: 150/256 - loss_mc=0.0179, loss_t=0.0778, loss_r=0.0446, loss=0.0301, norm_factor=200.8571, grad_norm=1.6900\n",
      "Epoch 3: 151/256 - loss_mc=0.0164, loss_t=0.0675, loss_r=0.0536, loss=0.0285, norm_factor=201.2251, grad_norm=1.5423\n",
      "Epoch 3: 152/256 - loss_mc=0.0209, loss_t=0.0867, loss_r=0.0476, loss=0.0343, norm_factor=201.6048, grad_norm=1.8173\n",
      "Epoch 3: 153/256 - loss_mc=0.0179, loss_t=0.0740, loss_r=0.0458, loss=0.0299, norm_factor=201.9620, grad_norm=1.1955\n",
      "Epoch 3: 154/256 - loss_mc=0.0196, loss_t=0.0687, loss_r=0.0454, loss=0.0310, norm_factor=202.3175, grad_norm=0.8168\n",
      "Epoch 3: 155/256 - loss_mc=0.0180, loss_t=0.0750, loss_r=0.0437, loss=0.0299, norm_factor=202.6682, grad_norm=1.2183\n",
      "Epoch 3: 156/256 - loss_mc=0.0192, loss_t=0.0771, loss_r=0.0510, loss=0.0320, norm_factor=203.0124, grad_norm=2.1355\n",
      "Epoch 3: 157/256 - loss_mc=0.0182, loss_t=0.0639, loss_r=0.0468, loss=0.0293, norm_factor=203.3339, grad_norm=0.9696\n",
      "Epoch 3: 158/256 - loss_mc=0.0166, loss_t=0.0685, loss_r=0.0414, loss=0.0276, norm_factor=203.6484, grad_norm=1.2372\n",
      "Epoch 3: 159/256 - loss_mc=0.0188, loss_t=0.0849, loss_r=0.0467, loss=0.0320, norm_factor=203.9683, grad_norm=2.0289\n",
      "Epoch 3: 160/256 - loss_mc=0.0183, loss_t=0.0835, loss_r=0.0374, loss=0.0303, norm_factor=204.2755, grad_norm=1.5787\n",
      "Epoch 3: 161/256 - loss_mc=0.0169, loss_t=0.0660, loss_r=0.0361, loss=0.0271, norm_factor=204.5764, grad_norm=1.4191\n",
      "Epoch 3: 162/256 - loss_mc=0.0172, loss_t=0.0754, loss_r=0.0375, loss=0.0285, norm_factor=204.8691, grad_norm=1.7058\n",
      "Epoch 3: 163/256 - loss_mc=0.0156, loss_t=0.0757, loss_r=0.0373, loss=0.0269, norm_factor=205.1677, grad_norm=1.4376\n",
      "Epoch 3: 164/256 - loss_mc=0.0158, loss_t=0.0746, loss_r=0.0401, loss=0.0273, norm_factor=205.4799, grad_norm=1.7567\n",
      "Epoch 3: 165/256 - loss_mc=0.0156, loss_t=0.0680, loss_r=0.0383, loss=0.0262, norm_factor=205.7949, grad_norm=2.1257\n",
      "Epoch 3: 166/256 - loss_mc=0.0143, loss_t=0.0581, loss_r=0.0382, loss=0.0239, norm_factor=206.1180, grad_norm=1.7284\n",
      "Epoch 3: 167/256 - loss_mc=0.0174, loss_t=0.0675, loss_r=0.0418, loss=0.0283, norm_factor=206.4634, grad_norm=1.5999\n",
      "Epoch 3: 168/256 - loss_mc=0.0152, loss_t=0.0580, loss_r=0.0372, loss=0.0247, norm_factor=206.7968, grad_norm=1.4481\n",
      "Epoch 3: 169/256 - loss_mc=0.0166, loss_t=0.0821, loss_r=0.0389, loss=0.0287, norm_factor=207.1359, grad_norm=2.8303\n",
      "Epoch 3: 170/256 - loss_mc=0.0168, loss_t=0.0752, loss_r=0.0388, loss=0.0282, norm_factor=207.4639, grad_norm=1.6749\n",
      "Epoch 3: 171/256 - loss_mc=0.0142, loss_t=0.0763, loss_r=0.0397, loss=0.0258, norm_factor=207.7801, grad_norm=1.9624\n",
      "Epoch 3: 172/256 - loss_mc=0.0172, loss_t=0.0712, loss_r=0.0435, loss=0.0286, norm_factor=208.1074, grad_norm=2.0755\n",
      "Epoch 3: 173/256 - loss_mc=0.0141, loss_t=0.0671, loss_r=0.0374, loss=0.0246, norm_factor=208.4255, grad_norm=1.5953\n",
      "Epoch 3: 174/256 - loss_mc=0.0157, loss_t=0.0618, loss_r=0.0361, loss=0.0255, norm_factor=208.7541, grad_norm=1.6097\n",
      "Epoch 3: 175/256 - loss_mc=0.0157, loss_t=0.0773, loss_r=0.0414, loss=0.0276, norm_factor=209.0862, grad_norm=1.7756\n",
      "Epoch 3: 176/256 - loss_mc=0.0157, loss_t=0.0739, loss_r=0.0362, loss=0.0267, norm_factor=209.4177, grad_norm=1.4361\n",
      "Epoch 3: 177/256 - loss_mc=0.0160, loss_t=0.0620, loss_r=0.0373, loss=0.0260, norm_factor=209.7453, grad_norm=1.7702\n",
      "Epoch 3: 178/256 - loss_mc=0.0133, loss_t=0.0695, loss_r=0.0350, loss=0.0237, norm_factor=210.0619, grad_norm=2.3720\n",
      "Epoch 3: 179/256 - loss_mc=0.0193, loss_t=0.0898, loss_r=0.0463, loss=0.0329, norm_factor=210.3907, grad_norm=2.0292\n",
      "Epoch 3: 180/256 - loss_mc=0.0141, loss_t=0.0691, loss_r=0.0363, loss=0.0246, norm_factor=210.6925, grad_norm=1.5581\n",
      "Epoch 3: 181/256 - loss_mc=0.0159, loss_t=0.0774, loss_r=0.0421, loss=0.0278, norm_factor=210.9999, grad_norm=2.4858\n",
      "Epoch 3: 182/256 - loss_mc=0.0135, loss_t=0.0710, loss_r=0.0432, loss=0.0249, norm_factor=211.2969, grad_norm=1.7815\n",
      "Epoch 3: 183/256 - loss_mc=0.0128, loss_t=0.0604, loss_r=0.0317, loss=0.0220, norm_factor=211.6024, grad_norm=1.6406\n",
      "Epoch 3: 184/256 - loss_mc=0.0138, loss_t=0.0614, loss_r=0.0384, loss=0.0238, norm_factor=211.9223, grad_norm=2.0587\n",
      "Epoch 3: 185/256 - loss_mc=0.0155, loss_t=0.0676, loss_r=0.0379, loss=0.0261, norm_factor=212.2509, grad_norm=2.1130\n",
      "Epoch 3: 186/256 - loss_mc=0.0148, loss_t=0.0784, loss_r=0.0378, loss=0.0264, norm_factor=212.5631, grad_norm=1.4137\n",
      "Epoch 3: 187/256 - loss_mc=0.0153, loss_t=0.0708, loss_r=0.0346, loss=0.0258, norm_factor=212.8723, grad_norm=2.1867\n",
      "Epoch 3: 188/256 - loss_mc=0.0141, loss_t=0.0667, loss_r=0.0330, loss=0.0241, norm_factor=213.1727, grad_norm=2.1285\n",
      "Epoch 3: 189/256 - loss_mc=0.0150, loss_t=0.0582, loss_r=0.0364, loss=0.0245, norm_factor=213.4723, grad_norm=1.2798\n",
      "Epoch 3: 190/256 - loss_mc=0.0146, loss_t=0.0883, loss_r=0.0328, loss=0.0267, norm_factor=213.7656, grad_norm=1.8086\n",
      "Epoch 3: 191/256 - loss_mc=0.0159, loss_t=0.0764, loss_r=0.0401, loss=0.0275, norm_factor=214.0644, grad_norm=2.3110\n",
      "Epoch 3: 192/256 - loss_mc=0.0146, loss_t=0.0740, loss_r=0.0354, loss=0.0256, norm_factor=214.3465, grad_norm=2.6265\n",
      "Epoch 3: 193/256 - loss_mc=0.0149, loss_t=0.0717, loss_r=0.0334, loss=0.0254, norm_factor=214.6284, grad_norm=0.8887\n",
      "Epoch 3: 194/256 - loss_mc=0.0162, loss_t=0.0721, loss_r=0.0376, loss=0.0272, norm_factor=214.9108, grad_norm=1.2922\n",
      "Epoch 3: 195/256 - loss_mc=0.0142, loss_t=0.0667, loss_r=0.0333, loss=0.0242, norm_factor=215.1773, grad_norm=2.3232\n",
      "Epoch 3: 196/256 - loss_mc=0.0149, loss_t=0.0605, loss_r=0.0371, loss=0.0246, norm_factor=215.4433, grad_norm=1.4800\n",
      "Epoch 3: 197/256 - loss_mc=0.0115, loss_t=0.0613, loss_r=0.0314, loss=0.0208, norm_factor=215.7003, grad_norm=1.5996\n",
      "Epoch 3: 198/256 - loss_mc=0.0133, loss_t=0.0724, loss_r=0.0353, loss=0.0240, norm_factor=215.9773, grad_norm=1.6263\n",
      "Epoch 3: 199/256 - loss_mc=0.0130, loss_t=0.0665, loss_r=0.0364, loss=0.0233, norm_factor=216.2560, grad_norm=1.3568\n",
      "Epoch 3: 200/256 - loss_mc=0.0142, loss_t=0.0696, loss_r=0.0314, loss=0.0243, norm_factor=216.5399, grad_norm=2.3069\n",
      "Epoch 3: 201/256 - loss_mc=0.0129, loss_t=0.0611, loss_r=0.0318, loss=0.0222, norm_factor=216.8241, grad_norm=2.1037\n",
      "Epoch 3: 202/256 - loss_mc=0.0119, loss_t=0.0690, loss_r=0.0399, loss=0.0228, norm_factor=217.1132, grad_norm=1.0722\n",
      "Epoch 3: 203/256 - loss_mc=0.0115, loss_t=0.0600, loss_r=0.0303, loss=0.0205, norm_factor=217.4072, grad_norm=1.1356\n",
      "Epoch 3: 204/256 - loss_mc=0.0122, loss_t=0.0590, loss_r=0.0306, loss=0.0212, norm_factor=217.7112, grad_norm=1.2095\n",
      "Epoch 3: 205/256 - loss_mc=0.0129, loss_t=0.0632, loss_r=0.0294, loss=0.0222, norm_factor=218.0221, grad_norm=1.2810\n",
      "Epoch 3: 206/256 - loss_mc=0.0126, loss_t=0.0521, loss_r=0.0335, loss=0.0211, norm_factor=218.3301, grad_norm=1.3471\n",
      "Epoch 3: 207/256 - loss_mc=0.0116, loss_t=0.0563, loss_r=0.0328, loss=0.0206, norm_factor=218.6402, grad_norm=1.0610\n",
      "Epoch 3: 208/256 - loss_mc=0.0121, loss_t=0.0545, loss_r=0.0310, loss=0.0207, norm_factor=218.9590, grad_norm=1.3091\n",
      "Epoch 3: 209/256 - loss_mc=0.0122, loss_t=0.0672, loss_r=0.0312, loss=0.0221, norm_factor=219.2846, grad_norm=1.1029\n",
      "Epoch 3: 210/256 - loss_mc=0.0115, loss_t=0.0603, loss_r=0.0322, loss=0.0207, norm_factor=219.6130, grad_norm=1.1608\n",
      "Epoch 3: 211/256 - loss_mc=0.0141, loss_t=0.0647, loss_r=0.0311, loss=0.0236, norm_factor=219.9430, grad_norm=1.3743\n",
      "Epoch 3: 212/256 - loss_mc=0.0120, loss_t=0.0580, loss_r=0.0304, loss=0.0209, norm_factor=220.2587, grad_norm=1.5934\n",
      "Epoch 3: 213/256 - loss_mc=0.0121, loss_t=0.0691, loss_r=0.0283, loss=0.0218, norm_factor=220.5827, grad_norm=1.7771\n",
      "Epoch 3: 214/256 - loss_mc=0.0129, loss_t=0.0625, loss_r=0.0307, loss=0.0222, norm_factor=220.9008, grad_norm=1.3031\n",
      "Epoch 3: 215/256 - loss_mc=0.0114, loss_t=0.0667, loss_r=0.0319, loss=0.0213, norm_factor=221.2075, grad_norm=2.1600\n",
      "Epoch 3: 216/256 - loss_mc=0.0124, loss_t=0.0654, loss_r=0.0378, loss=0.0227, norm_factor=221.5170, grad_norm=1.6745\n",
      "Epoch 3: 217/256 - loss_mc=0.0091, loss_t=0.0463, loss_r=0.0272, loss=0.0165, norm_factor=221.8174, grad_norm=1.0436\n",
      "Epoch 3: 218/256 - loss_mc=0.0128, loss_t=0.0610, loss_r=0.0281, loss=0.0217, norm_factor=222.1442, grad_norm=1.6235\n",
      "Epoch 3: 219/256 - loss_mc=0.0111, loss_t=0.0641, loss_r=0.0256, loss=0.0201, norm_factor=222.4609, grad_norm=2.0047\n",
      "Epoch 3: 220/256 - loss_mc=0.0113, loss_t=0.0637, loss_r=0.0290, loss=0.0206, norm_factor=222.7833, grad_norm=1.2609\n",
      "Epoch 3: 221/256 - loss_mc=0.0125, loss_t=0.0612, loss_r=0.0292, loss=0.0215, norm_factor=223.1061, grad_norm=1.6053\n",
      "Epoch 3: 222/256 - loss_mc=0.0111, loss_t=0.0484, loss_r=0.0270, loss=0.0187, norm_factor=223.4198, grad_norm=2.0984\n",
      "Epoch 3: 223/256 - loss_mc=0.0128, loss_t=0.0642, loss_r=0.0261, loss=0.0218, norm_factor=223.7433, grad_norm=1.3538\n",
      "Epoch 3: 224/256 - loss_mc=0.0114, loss_t=0.0564, loss_r=0.0244, loss=0.0195, norm_factor=224.0522, grad_norm=1.5426\n",
      "Epoch 3: 225/256 - loss_mc=0.0103, loss_t=0.0585, loss_r=0.0292, loss=0.0191, norm_factor=224.3655, grad_norm=1.4805\n",
      "Epoch 3: 226/256 - loss_mc=0.0111, loss_t=0.0705, loss_r=0.0327, loss=0.0214, norm_factor=224.6866, grad_norm=1.3136\n",
      "Epoch 3: 227/256 - loss_mc=0.0112, loss_t=0.0593, loss_r=0.0275, loss=0.0199, norm_factor=225.0079, grad_norm=1.6149\n",
      "Epoch 3: 228/256 - loss_mc=0.0119, loss_t=0.0512, loss_r=0.0255, loss=0.0196, norm_factor=225.3235, grad_norm=1.3626\n",
      "Epoch 3: 229/256 - loss_mc=0.0124, loss_t=0.0556, loss_r=0.0257, loss=0.0206, norm_factor=225.6316, grad_norm=1.3452\n",
      "Epoch 3: 230/256 - loss_mc=0.0114, loss_t=0.0517, loss_r=0.0305, loss=0.0196, norm_factor=225.9349, grad_norm=1.3856\n",
      "Epoch 3: 231/256 - loss_mc=0.0095, loss_t=0.0482, loss_r=0.0271, loss=0.0170, norm_factor=226.2377, grad_norm=1.3950\n",
      "Epoch 3: 232/256 - loss_mc=0.0098, loss_t=0.0616, loss_r=0.0270, loss=0.0187, norm_factor=226.5547, grad_norm=1.3572\n",
      "Epoch 3: 233/256 - loss_mc=0.0109, loss_t=0.0502, loss_r=0.0260, loss=0.0185, norm_factor=226.8810, grad_norm=1.6397\n",
      "Epoch 3: 234/256 - loss_mc=0.0116, loss_t=0.0672, loss_r=0.0266, loss=0.0210, norm_factor=227.2062, grad_norm=2.1507\n",
      "Epoch 3: 235/256 - loss_mc=0.0100, loss_t=0.0507, loss_r=0.0267, loss=0.0177, norm_factor=227.5218, grad_norm=1.0019\n",
      "Epoch 3: 236/256 - loss_mc=0.0121, loss_t=0.0566, loss_r=0.0260, loss=0.0204, norm_factor=227.8413, grad_norm=1.3494\n",
      "Epoch 3: 237/256 - loss_mc=0.0136, loss_t=0.0588, loss_r=0.0251, loss=0.0220, norm_factor=228.1429, grad_norm=2.1119\n",
      "Epoch 3: 238/256 - loss_mc=0.0115, loss_t=0.0483, loss_r=0.0289, loss=0.0193, norm_factor=228.4213, grad_norm=1.0071\n",
      "Epoch 3: 239/256 - loss_mc=0.0122, loss_t=0.0536, loss_r=0.0250, loss=0.0201, norm_factor=228.6915, grad_norm=1.0265\n",
      "Epoch 3: 240/256 - loss_mc=0.0093, loss_t=0.0484, loss_r=0.0270, loss=0.0168, norm_factor=228.9493, grad_norm=1.6223\n",
      "Epoch 3: 241/256 - loss_mc=0.0110, loss_t=0.0559, loss_r=0.0236, loss=0.0190, norm_factor=229.2233, grad_norm=2.1734\n",
      "Epoch 3: 242/256 - loss_mc=0.0108, loss_t=0.0493, loss_r=0.0254, loss=0.0182, norm_factor=229.4995, grad_norm=1.2003\n",
      "Epoch 3: 243/256 - loss_mc=0.0104, loss_t=0.0631, loss_r=0.0265, loss=0.0194, norm_factor=229.7775, grad_norm=1.7222\n",
      "Epoch 3: 244/256 - loss_mc=0.0124, loss_t=0.0524, loss_r=0.0236, loss=0.0200, norm_factor=230.0451, grad_norm=2.0830\n",
      "Epoch 3: 245/256 - loss_mc=0.0091, loss_t=0.0611, loss_r=0.0226, loss=0.0175, norm_factor=230.2940, grad_norm=1.1708\n",
      "Epoch 3: 246/256 - loss_mc=0.0098, loss_t=0.0661, loss_r=0.0230, loss=0.0187, norm_factor=230.5548, grad_norm=2.8506\n",
      "Epoch 3: 247/256 - loss_mc=0.0097, loss_t=0.0452, loss_r=0.0233, loss=0.0165, norm_factor=230.8306, grad_norm=0.9351\n",
      "Epoch 3: 248/256 - loss_mc=0.0089, loss_t=0.0469, loss_r=0.0269, loss=0.0163, norm_factor=231.1111, grad_norm=1.3470\n",
      "Epoch 3: 249/256 - loss_mc=0.0086, loss_t=0.0544, loss_r=0.0225, loss=0.0163, norm_factor=231.4036, grad_norm=1.3682\n",
      "Epoch 3: 250/256 - loss_mc=0.0082, loss_t=0.0506, loss_r=0.0247, loss=0.0157, norm_factor=231.7013, grad_norm=2.0824\n",
      "Epoch 3: 251/256 - loss_mc=0.0092, loss_t=0.0600, loss_r=0.0257, loss=0.0177, norm_factor=232.0158, grad_norm=1.5113\n",
      "Epoch 3: 252/256 - loss_mc=0.0094, loss_t=0.0530, loss_r=0.0260, loss=0.0173, norm_factor=232.3381, grad_norm=1.6189\n",
      "Epoch 3: 253/256 - loss_mc=0.0083, loss_t=0.0651, loss_r=0.0217, loss=0.0170, norm_factor=232.6607, grad_norm=2.0899\n",
      "Epoch 3: 254/256 - loss_mc=0.0093, loss_t=0.0490, loss_r=0.0251, loss=0.0167, norm_factor=232.9939, grad_norm=1.6157\n",
      "Epoch 3: 255/256 - loss_mc=0.0087, loss_t=0.0449, loss_r=0.0227, loss=0.0155, norm_factor=233.3300, grad_norm=1.0088\n",
      "Epoch 3: 256/256 - loss_mc=0.0093, loss_t=0.0551, loss_r=0.0222, loss=0.0170, norm_factor=233.6697, grad_norm=1.7717\n",
      "Epoch 4: 1/256 - loss_mc=0.0103, loss_t=0.0667, loss_r=0.0245, loss=0.0194, norm_factor=234.0084, grad_norm=1.8887\n",
      "Epoch 4: 2/256 - loss_mc=0.0097, loss_t=0.0495, loss_r=0.0254, loss=0.0172, norm_factor=234.3355, grad_norm=1.0480\n",
      "Epoch 4: 3/256 - loss_mc=0.0097, loss_t=0.0499, loss_r=0.0224, loss=0.0169, norm_factor=234.6610, grad_norm=2.1625\n",
      "Epoch 4: 4/256 - loss_mc=0.0090, loss_t=0.0510, loss_r=0.0248, loss=0.0166, norm_factor=234.9873, grad_norm=0.9769\n",
      "Epoch 4: 5/256 - loss_mc=0.0101, loss_t=0.0563, loss_r=0.0249, loss=0.0182, norm_factor=235.3136, grad_norm=2.0368\n",
      "Epoch 4: 6/256 - loss_mc=0.0097, loss_t=0.0487, loss_r=0.0222, loss=0.0168, norm_factor=235.6296, grad_norm=2.0089\n",
      "Epoch 4: 7/256 - loss_mc=0.0084, loss_t=0.0432, loss_r=0.0228, loss=0.0150, norm_factor=235.9428, grad_norm=1.1446\n",
      "Epoch 4: 8/256 - loss_mc=0.0083, loss_t=0.0600, loss_r=0.0204, loss=0.0163, norm_factor=236.2635, grad_norm=2.2384\n",
      "Epoch 4: 9/256 - loss_mc=0.0090, loss_t=0.0543, loss_r=0.0263, loss=0.0170, norm_factor=236.5904, grad_norm=0.8108\n",
      "Epoch 4: 10/256 - loss_mc=0.0100, loss_t=0.0596, loss_r=0.0229, loss=0.0183, norm_factor=236.9161, grad_norm=2.2436\n",
      "Epoch 4: 11/256 - loss_mc=0.0092, loss_t=0.0536, loss_r=0.0244, loss=0.0170, norm_factor=237.2318, grad_norm=1.5598\n",
      "Epoch 4: 12/256 - loss_mc=0.0083, loss_t=0.0510, loss_r=0.0236, loss=0.0158, norm_factor=237.5426, grad_norm=1.2637\n",
      "Epoch 4: 13/256 - loss_mc=0.0071, loss_t=0.0495, loss_r=0.0202, loss=0.0141, norm_factor=237.8548, grad_norm=0.9561\n",
      "Epoch 4: 14/256 - loss_mc=0.0092, loss_t=0.0459, loss_r=0.0237, loss=0.0162, norm_factor=238.1754, grad_norm=1.1977\n",
      "Epoch 4: 15/256 - loss_mc=0.0082, loss_t=0.0533, loss_r=0.0221, loss=0.0157, norm_factor=238.4958, grad_norm=1.7215\n",
      "Epoch 4: 16/256 - loss_mc=0.0097, loss_t=0.0581, loss_r=0.0237, loss=0.0179, norm_factor=238.8221, grad_norm=1.5301\n",
      "Epoch 4: 17/256 - loss_mc=0.0086, loss_t=0.0499, loss_r=0.0201, loss=0.0156, norm_factor=239.1317, grad_norm=1.2649\n",
      "Epoch 4: 18/256 - loss_mc=0.0091, loss_t=0.0557, loss_r=0.0219, loss=0.0168, norm_factor=239.4372, grad_norm=1.6899\n",
      "Epoch 4: 19/256 - loss_mc=0.0100, loss_t=0.0567, loss_r=0.0268, loss=0.0184, norm_factor=239.7356, grad_norm=1.7317\n",
      "Epoch 4: 20/256 - loss_mc=0.0078, loss_t=0.0459, loss_r=0.0190, loss=0.0143, norm_factor=240.0151, grad_norm=1.3572\n",
      "Epoch 4: 21/256 - loss_mc=0.0085, loss_t=0.0504, loss_r=0.0195, loss=0.0154, norm_factor=240.2986, grad_norm=1.4767\n",
      "Epoch 4: 22/256 - loss_mc=0.0084, loss_t=0.0463, loss_r=0.0232, loss=0.0153, norm_factor=240.5835, grad_norm=1.5981\n",
      "Epoch 4: 23/256 - loss_mc=0.0078, loss_t=0.0483, loss_r=0.0216, loss=0.0148, norm_factor=240.8715, grad_norm=1.6516\n",
      "Epoch 4: 24/256 - loss_mc=0.0074, loss_t=0.0534, loss_r=0.0216, loss=0.0149, norm_factor=241.1668, grad_norm=1.7688\n",
      "Epoch 4: 25/256 - loss_mc=0.0075, loss_t=0.0523, loss_r=0.0205, loss=0.0148, norm_factor=241.4701, grad_norm=2.1650\n",
      "Epoch 4: 26/256 - loss_mc=0.0076, loss_t=0.0434, loss_r=0.0205, loss=0.0140, norm_factor=241.7797, grad_norm=1.2639\n",
      "Epoch 4: 27/256 - loss_mc=0.0079, loss_t=0.0403, loss_r=0.0239, loss=0.0143, norm_factor=242.0864, grad_norm=1.2855\n",
      "Epoch 4: 28/256 - loss_mc=0.0116, loss_t=0.0582, loss_r=0.0276, loss=0.0202, norm_factor=242.3992, grad_norm=2.1335\n",
      "Epoch 4: 29/256 - loss_mc=0.0074, loss_t=0.0489, loss_r=0.0206, loss=0.0144, norm_factor=242.6804, grad_norm=2.0157\n",
      "Epoch 4: 30/256 - loss_mc=0.0063, loss_t=0.0456, loss_r=0.0186, loss=0.0127, norm_factor=242.9723, grad_norm=0.9815\n",
      "Epoch 4: 31/256 - loss_mc=0.0081, loss_t=0.0483, loss_r=0.0222, loss=0.0151, norm_factor=243.2786, grad_norm=2.1597\n",
      "Epoch 4: 32/256 - loss_mc=0.0066, loss_t=0.0451, loss_r=0.0238, loss=0.0135, norm_factor=243.5825, grad_norm=2.2036\n",
      "Epoch 4: 33/256 - loss_mc=0.0075, loss_t=0.0497, loss_r=0.0216, loss=0.0147, norm_factor=243.8979, grad_norm=1.1090\n",
      "Epoch 4: 34/256 - loss_mc=0.0077, loss_t=0.0549, loss_r=0.0228, loss=0.0155, norm_factor=244.2115, grad_norm=1.4786\n",
      "Epoch 4: 35/256 - loss_mc=0.0051, loss_t=0.0450, loss_r=0.0189, loss=0.0115, norm_factor=244.5197, grad_norm=1.6466\n",
      "Epoch 4: 36/256 - loss_mc=0.0064, loss_t=0.0464, loss_r=0.0202, loss=0.0131, norm_factor=244.8499, grad_norm=1.1830\n",
      "Epoch 4: 37/256 - loss_mc=0.0105, loss_t=0.0559, loss_r=0.0189, loss=0.0180, norm_factor=245.1853, grad_norm=2.1876\n",
      "Epoch 4: 38/256 - loss_mc=0.0077, loss_t=0.0547, loss_r=0.0248, loss=0.0156, norm_factor=245.4908, grad_norm=2.0473\n",
      "Epoch 4: 39/256 - loss_mc=0.0069, loss_t=0.0492, loss_r=0.0192, loss=0.0137, norm_factor=245.7936, grad_norm=0.7300\n",
      "Epoch 4: 40/256 - loss_mc=0.0085, loss_t=0.0558, loss_r=0.0202, loss=0.0161, norm_factor=246.1040, grad_norm=1.2168\n",
      "Epoch 4: 41/256 - loss_mc=0.0064, loss_t=0.0446, loss_r=0.0210, loss=0.0129, norm_factor=246.4003, grad_norm=1.4284\n",
      "Epoch 4: 42/256 - loss_mc=0.0056, loss_t=0.0438, loss_r=0.0184, loss=0.0118, norm_factor=246.7061, grad_norm=1.6204\n",
      "Epoch 4: 43/256 - loss_mc=0.0058, loss_t=0.0533, loss_r=0.0188, loss=0.0130, norm_factor=247.0251, grad_norm=1.5020\n",
      "Epoch 4: 44/256 - loss_mc=0.0053, loss_t=0.0414, loss_r=0.0209, loss=0.0116, norm_factor=247.3545, grad_norm=0.8908\n",
      "Epoch 4: 45/256 - loss_mc=0.0071, loss_t=0.0469, loss_r=0.0185, loss=0.0136, norm_factor=247.6970, grad_norm=1.5776\n",
      "Epoch 4: 46/256 - loss_mc=0.0081, loss_t=0.0436, loss_r=0.0188, loss=0.0144, norm_factor=248.0359, grad_norm=1.2157\n",
      "Epoch 4: 47/256 - loss_mc=0.0064, loss_t=0.0483, loss_r=0.0208, loss=0.0133, norm_factor=248.3629, grad_norm=0.8522\n",
      "Epoch 4: 48/256 - loss_mc=0.0093, loss_t=0.0492, loss_r=0.0215, loss=0.0164, norm_factor=248.6902, grad_norm=1.1460\n",
      "Epoch 4: 49/256 - loss_mc=0.0055, loss_t=0.0464, loss_r=0.0196, loss=0.0121, norm_factor=248.9893, grad_norm=0.5501\n",
      "Epoch 4: 50/256 - loss_mc=0.0089, loss_t=0.0407, loss_r=0.0204, loss=0.0150, norm_factor=249.3008, grad_norm=1.2888\n",
      "Epoch 4: 51/256 - loss_mc=0.0048, loss_t=0.0417, loss_r=0.0184, loss=0.0108, norm_factor=249.5946, grad_norm=1.6388\n",
      "Epoch 4: 52/256 - loss_mc=0.0064, loss_t=0.0471, loss_r=0.0210, loss=0.0132, norm_factor=249.9137, grad_norm=1.1591\n",
      "Epoch 4: 53/256 - loss_mc=0.0082, loss_t=0.0561, loss_r=0.0208, loss=0.0159, norm_factor=250.2319, grad_norm=1.2750\n",
      "Epoch 4: 54/256 - loss_mc=0.0065, loss_t=0.0437, loss_r=0.0212, loss=0.0130, norm_factor=250.5363, grad_norm=1.0934\n",
      "Epoch 4: 55/256 - loss_mc=0.0054, loss_t=0.0447, loss_r=0.0183, loss=0.0117, norm_factor=250.8389, grad_norm=1.5781\n",
      "Epoch 4: 56/256 - loss_mc=0.0048, loss_t=0.0453, loss_r=0.0186, loss=0.0112, norm_factor=251.1538, grad_norm=1.4411\n",
      "Epoch 4: 57/256 - loss_mc=0.0049, loss_t=0.0484, loss_r=0.0190, loss=0.0117, norm_factor=251.4908, grad_norm=0.9979\n",
      "Epoch 4: 58/256 - loss_mc=0.0066, loss_t=0.0395, loss_r=0.0192, loss=0.0124, norm_factor=251.8429, grad_norm=0.9318\n",
      "Epoch 4: 59/256 - loss_mc=0.0060, loss_t=0.0491, loss_r=0.0196, loss=0.0129, norm_factor=252.1931, grad_norm=1.4681\n",
      "Epoch 4: 60/256 - loss_mc=0.0087, loss_t=0.0486, loss_r=0.0231, loss=0.0159, norm_factor=252.5403, grad_norm=0.9887\n",
      "Epoch 4: 61/256 - loss_mc=0.0073, loss_t=0.0569, loss_r=0.0251, loss=0.0155, norm_factor=252.8614, grad_norm=1.3290\n",
      "Epoch 4: 62/256 - loss_mc=0.0046, loss_t=0.0481, loss_r=0.0208, loss=0.0115, norm_factor=253.1742, grad_norm=1.7575\n",
      "Epoch 4: 63/256 - loss_mc=0.0065, loss_t=0.0503, loss_r=0.0202, loss=0.0136, norm_factor=253.5049, grad_norm=1.3988\n",
      "Epoch 4: 64/256 - loss_mc=0.0049, loss_t=0.0396, loss_r=0.0189, loss=0.0108, norm_factor=253.8336, grad_norm=1.2201\n",
      "Epoch 4: 65/256 - loss_mc=0.0046, loss_t=0.0414, loss_r=0.0221, loss=0.0110, norm_factor=254.1746, grad_norm=1.2750\n",
      "Epoch 4: 66/256 - loss_mc=0.0063, loss_t=0.0486, loss_r=0.0193, loss=0.0131, norm_factor=254.5222, grad_norm=1.3994\n",
      "Epoch 4: 67/256 - loss_mc=0.0052, loss_t=0.0496, loss_r=0.0193, loss=0.0121, norm_factor=254.8624, grad_norm=0.9287\n",
      "Epoch 4: 68/256 - loss_mc=0.0050, loss_t=0.0389, loss_r=0.0173, loss=0.0106, norm_factor=255.2029, grad_norm=1.1756\n",
      "Epoch 4: 69/256 - loss_mc=0.0055, loss_t=0.0481, loss_r=0.0193, loss=0.0122, norm_factor=255.5498, grad_norm=0.9985\n",
      "Epoch 4: 70/256 - loss_mc=0.0050, loss_t=0.0370, loss_r=0.0183, loss=0.0105, norm_factor=255.9021, grad_norm=1.3642\n",
      "Epoch 4: 71/256 - loss_mc=0.0058, loss_t=0.0462, loss_r=0.0173, loss=0.0122, norm_factor=256.2619, grad_norm=1.4041\n",
      "Epoch 4: 72/256 - loss_mc=0.0057, loss_t=0.0479, loss_r=0.0193, loss=0.0124, norm_factor=256.6160, grad_norm=1.1564\n",
      "Epoch 4: 73/256 - loss_mc=0.0050, loss_t=0.0418, loss_r=0.0159, loss=0.0108, norm_factor=256.9657, grad_norm=0.9989\n",
      "Epoch 4: 74/256 - loss_mc=0.0058, loss_t=0.0506, loss_r=0.0196, loss=0.0129, norm_factor=257.3144, grad_norm=1.6021\n",
      "Epoch 4: 75/256 - loss_mc=0.0048, loss_t=0.0386, loss_r=0.0182, loss=0.0105, norm_factor=257.6590, grad_norm=1.7573\n",
      "Epoch 4: 76/256 - loss_mc=0.0045, loss_t=0.0396, loss_r=0.0174, loss=0.0102, norm_factor=258.0117, grad_norm=1.2020\n",
      "Epoch 4: 77/256 - loss_mc=0.0055, loss_t=0.0381, loss_r=0.0185, loss=0.0112, norm_factor=258.3692, grad_norm=1.5257\n",
      "Epoch 4: 78/256 - loss_mc=0.0062, loss_t=0.0482, loss_r=0.0209, loss=0.0131, norm_factor=258.7229, grad_norm=1.1513\n",
      "Epoch 4: 79/256 - loss_mc=0.0034, loss_t=0.0432, loss_r=0.0151, loss=0.0092, norm_factor=259.0662, grad_norm=1.1121\n",
      "Epoch 4: 80/256 - loss_mc=0.0056, loss_t=0.0451, loss_r=0.0163, loss=0.0118, norm_factor=259.4292, grad_norm=1.3482\n",
      "Epoch 4: 81/256 - loss_mc=0.0051, loss_t=0.0458, loss_r=0.0195, loss=0.0116, norm_factor=259.7859, grad_norm=1.5951\n",
      "Epoch 4: 82/256 - loss_mc=0.0058, loss_t=0.0479, loss_r=0.0189, loss=0.0125, norm_factor=260.1448, grad_norm=2.1552\n",
      "Epoch 4: 83/256 - loss_mc=0.0033, loss_t=0.0394, loss_r=0.0183, loss=0.0091, norm_factor=260.4937, grad_norm=1.9250\n",
      "Epoch 4: 84/256 - loss_mc=0.0041, loss_t=0.0425, loss_r=0.0179, loss=0.0102, norm_factor=260.8625, grad_norm=1.9433\n",
      "Epoch 4: 85/256 - loss_mc=0.0051, loss_t=0.0479, loss_r=0.0195, loss=0.0119, norm_factor=261.2416, grad_norm=2.0275\n",
      "Epoch 4: 86/256 - loss_mc=0.0050, loss_t=0.0512, loss_r=0.0195, loss=0.0120, norm_factor=261.6167, grad_norm=1.8742\n",
      "Epoch 4: 87/256 - loss_mc=0.0065, loss_t=0.0464, loss_r=0.0201, loss=0.0132, norm_factor=261.9852, grad_norm=1.5152\n",
      "Epoch 4: 88/256 - loss_mc=0.0047, loss_t=0.0525, loss_r=0.0184, loss=0.0118, norm_factor=262.3308, grad_norm=2.6379\n",
      "Epoch 4: 89/256 - loss_mc=0.0047, loss_t=0.0412, loss_r=0.0169, loss=0.0105, norm_factor=262.6775, grad_norm=1.5600\n",
      "Epoch 4: 90/256 - loss_mc=0.0059, loss_t=0.0383, loss_r=0.0177, loss=0.0115, norm_factor=263.0249, grad_norm=1.6138\n",
      "Epoch 4: 91/256 - loss_mc=0.0042, loss_t=0.0320, loss_r=0.0158, loss=0.0090, norm_factor=263.3568, grad_norm=1.7823\n",
      "Epoch 4: 92/256 - loss_mc=0.0055, loss_t=0.0417, loss_r=0.0179, loss=0.0115, norm_factor=263.6983, grad_norm=1.1398\n",
      "Epoch 4: 93/256 - loss_mc=0.0040, loss_t=0.0413, loss_r=0.0187, loss=0.0100, norm_factor=264.0296, grad_norm=1.1984\n",
      "Epoch 4: 94/256 - loss_mc=0.0055, loss_t=0.0448, loss_r=0.0189, loss=0.0118, norm_factor=264.3657, grad_norm=1.8363\n",
      "Epoch 4: 95/256 - loss_mc=0.0086, loss_t=0.0474, loss_r=0.0185, loss=0.0152, norm_factor=264.6927, grad_norm=1.4021\n",
      "Epoch 4: 96/256 - loss_mc=0.0053, loss_t=0.0452, loss_r=0.0150, loss=0.0113, norm_factor=264.9727, grad_norm=1.2748\n",
      "Epoch 4: 97/256 - loss_mc=0.0030, loss_t=0.0376, loss_r=0.0155, loss=0.0084, norm_factor=265.2491, grad_norm=1.0142\n",
      "Epoch 4: 98/256 - loss_mc=0.0039, loss_t=0.0396, loss_r=0.0154, loss=0.0094, norm_factor=265.5484, grad_norm=1.4824\n",
      "Epoch 4: 99/256 - loss_mc=0.0043, loss_t=0.0438, loss_r=0.0203, loss=0.0107, norm_factor=265.8586, grad_norm=1.1034\n",
      "Epoch 4: 100/256 - loss_mc=0.0065, loss_t=0.0497, loss_r=0.0203, loss=0.0135, norm_factor=266.1724, grad_norm=1.5239\n",
      "Epoch 4: 101/256 - loss_mc=0.0041, loss_t=0.0385, loss_r=0.0147, loss=0.0094, norm_factor=266.4679, grad_norm=1.1678\n",
      "Epoch 4: 102/256 - loss_mc=0.0056, loss_t=0.0418, loss_r=0.0163, loss=0.0114, norm_factor=266.7719, grad_norm=1.4709\n",
      "Epoch 4: 103/256 - loss_mc=0.0047, loss_t=0.0413, loss_r=0.0168, loss=0.0105, norm_factor=267.0635, grad_norm=1.5954\n",
      "Epoch 4: 104/256 - loss_mc=0.0021, loss_t=0.0397, loss_r=0.0164, loss=0.0077, norm_factor=267.3558, grad_norm=1.4116\n",
      "Epoch 4: 105/256 - loss_mc=0.0057, loss_t=0.0489, loss_r=0.0211, loss=0.0127, norm_factor=267.6785, grad_norm=2.1000\n",
      "Epoch 4: 106/256 - loss_mc=0.0038, loss_t=0.0343, loss_r=0.0150, loss=0.0087, norm_factor=267.9846, grad_norm=1.2287\n",
      "Epoch 4: 107/256 - loss_mc=0.0044, loss_t=0.0459, loss_r=0.0171, loss=0.0107, norm_factor=268.2996, grad_norm=1.3930\n",
      "Epoch 4: 108/256 - loss_mc=0.0037, loss_t=0.0396, loss_r=0.0195, loss=0.0096, norm_factor=268.6147, grad_norm=1.4885\n",
      "Epoch 4: 109/256 - loss_mc=0.0053, loss_t=0.0422, loss_r=0.0181, loss=0.0113, norm_factor=268.9380, grad_norm=1.5988\n",
      "Epoch 4: 110/256 - loss_mc=0.0051, loss_t=0.0450, loss_r=0.0181, loss=0.0114, norm_factor=269.2553, grad_norm=1.6354\n",
      "Epoch 4: 111/256 - loss_mc=0.0026, loss_t=0.0409, loss_r=0.0163, loss=0.0084, norm_factor=269.5699, grad_norm=1.2304\n",
      "Epoch 4: 112/256 - loss_mc=0.0027, loss_t=0.0374, loss_r=0.0167, loss=0.0081, norm_factor=269.9057, grad_norm=1.1892\n",
      "Epoch 4: 113/256 - loss_mc=0.0035, loss_t=0.0376, loss_r=0.0158, loss=0.0089, norm_factor=270.2568, grad_norm=1.3261\n",
      "Epoch 4: 114/256 - loss_mc=0.0023, loss_t=0.0334, loss_r=0.0160, loss=0.0072, norm_factor=270.6137, grad_norm=0.9068\n",
      "Epoch 4: 115/256 - loss_mc=0.0018, loss_t=0.0365, loss_r=0.0154, loss=0.0069, norm_factor=270.9902, grad_norm=1.6373\n",
      "Epoch 4: 116/256 - loss_mc=0.0043, loss_t=0.0389, loss_r=0.0158, loss=0.0098, norm_factor=271.3849, grad_norm=1.0957\n",
      "Epoch 4: 117/256 - loss_mc=0.0047, loss_t=0.0449, loss_r=0.0167, loss=0.0109, norm_factor=271.7687, grad_norm=1.1602\n",
      "Epoch 4: 118/256 - loss_mc=0.0042, loss_t=0.0379, loss_r=0.0165, loss=0.0096, norm_factor=272.1423, grad_norm=1.1572\n",
      "Epoch 4: 119/256 - loss_mc=0.0026, loss_t=0.0361, loss_r=0.0148, loss=0.0076, norm_factor=272.5088, grad_norm=1.4198\n",
      "Epoch 4: 120/256 - loss_mc=0.0028, loss_t=0.0321, loss_r=0.0160, loss=0.0076, norm_factor=272.8892, grad_norm=1.1687\n",
      "Epoch 4: 121/256 - loss_mc=0.0029, loss_t=0.0419, loss_r=0.0186, loss=0.0090, norm_factor=273.2772, grad_norm=1.4726\n",
      "Epoch 4: 122/256 - loss_mc=0.0013, loss_t=0.0317, loss_r=0.0149, loss=0.0060, norm_factor=273.6705, grad_norm=0.7017\n",
      "Epoch 4: 123/256 - loss_mc=0.0029, loss_t=0.0414, loss_r=0.0152, loss=0.0085, norm_factor=274.0826, grad_norm=1.9261\n",
      "Epoch 4: 124/256 - loss_mc=0.0023, loss_t=0.0373, loss_r=0.0167, loss=0.0077, norm_factor=274.4930, grad_norm=1.5302\n",
      "Epoch 4: 125/256 - loss_mc=0.0012, loss_t=0.0361, loss_r=0.0175, loss=0.0066, norm_factor=274.9082, grad_norm=1.1849\n",
      "Epoch 4: 126/256 - loss_mc=0.0025, loss_t=0.0414, loss_r=0.0150, loss=0.0081, norm_factor=275.3383, grad_norm=1.7256\n",
      "Epoch 4: 127/256 - loss_mc=0.0045, loss_t=0.0406, loss_r=0.0169, loss=0.0102, norm_factor=275.7706, grad_norm=1.2606\n",
      "Epoch 4: 128/256 - loss_mc=0.0052, loss_t=0.0431, loss_r=0.0172, loss=0.0113, norm_factor=276.1801, grad_norm=1.0974\n",
      "Epoch 4: 129/256 - loss_mc=0.0039, loss_t=0.0443, loss_r=0.0191, loss=0.0102, norm_factor=276.5636, grad_norm=2.2429\n",
      "Epoch 4: 130/256 - loss_mc=0.0017, loss_t=0.0369, loss_r=0.0137, loss=0.0067, norm_factor=276.9368, grad_norm=1.3312\n",
      "Epoch 4: 131/256 - loss_mc=0.0040, loss_t=0.0357, loss_r=0.0197, loss=0.0095, norm_factor=277.3231, grad_norm=0.9610\n",
      "Epoch 4: 132/256 - loss_mc=0.0038, loss_t=0.0446, loss_r=0.0181, loss=0.0101, norm_factor=277.6965, grad_norm=1.5639\n",
      "Epoch 4: 133/256 - loss_mc=0.0021, loss_t=0.0376, loss_r=0.0133, loss=0.0071, norm_factor=278.0639, grad_norm=1.4284\n",
      "Epoch 4: 134/256 - loss_mc=0.0028, loss_t=0.0426, loss_r=0.0136, loss=0.0085, norm_factor=278.4447, grad_norm=1.0397\n",
      "Epoch 4: 135/256 - loss_mc=0.0028, loss_t=0.0422, loss_r=0.0163, loss=0.0086, norm_factor=278.8237, grad_norm=1.4795\n",
      "Epoch 4: 136/256 - loss_mc=0.0024, loss_t=0.0488, loss_r=0.0162, loss=0.0089, norm_factor=279.1978, grad_norm=1.0322\n",
      "Epoch 4: 137/256 - loss_mc=0.0023, loss_t=0.0396, loss_r=0.0153, loss=0.0078, norm_factor=279.5754, grad_norm=1.2962\n",
      "Epoch 4: 138/256 - loss_mc=0.0020, loss_t=0.0370, loss_r=0.0150, loss=0.0072, norm_factor=279.9582, grad_norm=1.1945\n",
      "Epoch 4: 139/256 - loss_mc=0.0025, loss_t=0.0329, loss_r=0.0155, loss=0.0074, norm_factor=280.3509, grad_norm=0.7229\n",
      "Epoch 4: 140/256 - loss_mc=0.0020, loss_t=0.0323, loss_r=0.0139, loss=0.0067, norm_factor=280.7456, grad_norm=1.1337\n",
      "Epoch 4: 141/256 - loss_mc=0.0019, loss_t=0.0356, loss_r=0.0169, loss=0.0072, norm_factor=281.1439, grad_norm=0.9849\n",
      "Epoch 4: 142/256 - loss_mc=0.0027, loss_t=0.0406, loss_r=0.0157, loss=0.0083, norm_factor=281.5498, grad_norm=1.6822\n",
      "Epoch 4: 143/256 - loss_mc=0.0019, loss_t=0.0355, loss_r=0.0152, loss=0.0070, norm_factor=281.9450, grad_norm=0.9207\n",
      "Epoch 4: 144/256 - loss_mc=0.0012, loss_t=0.0416, loss_r=0.0143, loss=0.0068, norm_factor=282.3417, grad_norm=1.5035\n",
      "Epoch 4: 145/256 - loss_mc=0.0024, loss_t=0.0412, loss_r=0.0132, loss=0.0078, norm_factor=282.7502, grad_norm=1.4318\n",
      "Epoch 4: 146/256 - loss_mc=0.0023, loss_t=0.0376, loss_r=0.0132, loss=0.0073, norm_factor=283.1517, grad_norm=1.2875\n",
      "Epoch 4: 147/256 - loss_mc=0.0012, loss_t=0.0386, loss_r=0.0150, loss=0.0066, norm_factor=283.5484, grad_norm=1.4164\n",
      "Epoch 4: 148/256 - loss_mc=0.0028, loss_t=0.0368, loss_r=0.0153, loss=0.0080, norm_factor=283.9583, grad_norm=1.5670\n",
      "Epoch 4: 149/256 - loss_mc=0.0027, loss_t=0.0390, loss_r=0.0139, loss=0.0080, norm_factor=284.3600, grad_norm=1.7203\n",
      "Epoch 4: 150/256 - loss_mc=0.0025, loss_t=0.0335, loss_r=0.0195, loss=0.0078, norm_factor=284.7571, grad_norm=1.8129\n",
      "Epoch 4: 151/256 - loss_mc=0.0020, loss_t=0.0323, loss_r=0.0139, loss=0.0066, norm_factor=285.1448, grad_norm=1.6495\n",
      "Epoch 4: 152/256 - loss_mc=0.0028, loss_t=0.0368, loss_r=0.0152, loss=0.0080, norm_factor=285.5338, grad_norm=1.5817\n",
      "Epoch 4: 153/256 - loss_mc=0.0018, loss_t=0.0416, loss_r=0.0130, loss=0.0073, norm_factor=285.9106, grad_norm=1.6766\n",
      "Epoch 4: 154/256 - loss_mc=0.0012, loss_t=0.0304, loss_r=0.0141, loss=0.0057, norm_factor=286.2867, grad_norm=1.4103\n",
      "Epoch 4: 155/256 - loss_mc=0.0011, loss_t=0.0318, loss_r=0.0129, loss=0.0056, norm_factor=286.6712, grad_norm=0.7994\n",
      "Epoch 4: 156/256 - loss_mc=0.0023, loss_t=0.0341, loss_r=0.0129, loss=0.0071, norm_factor=287.0634, grad_norm=1.3427\n",
      "Epoch 4: 157/256 - loss_mc=0.0032, loss_t=0.0402, loss_r=0.0155, loss=0.0088, norm_factor=287.4490, grad_norm=1.7242\n",
      "Epoch 4: 158/256 - loss_mc=0.0011, loss_t=0.0385, loss_r=0.0173, loss=0.0067, norm_factor=287.8198, grad_norm=1.7093\n",
      "Epoch 4: 159/256 - loss_mc=0.0008, loss_t=0.0294, loss_r=0.0122, loss=0.0050, norm_factor=288.2062, grad_norm=1.3907\n",
      "Epoch 4: 160/256 - loss_mc=0.0033, loss_t=0.0443, loss_r=0.0197, loss=0.0097, norm_factor=288.6096, grad_norm=2.2210\n",
      "Epoch 4: 161/256 - loss_mc=0.0010, loss_t=0.0330, loss_r=0.0121, loss=0.0055, norm_factor=288.9960, grad_norm=1.6015\n",
      "Epoch 4: 162/256 - loss_mc=0.0030, loss_t=0.0473, loss_r=0.0151, loss=0.0092, norm_factor=289.3911, grad_norm=1.6935\n",
      "Epoch 4: 163/256 - loss_mc=0.0024, loss_t=0.0439, loss_r=0.0129, loss=0.0081, norm_factor=289.7715, grad_norm=1.9584\n",
      "Epoch 4: 164/256 - loss_mc=0.0021, loss_t=0.0331, loss_r=0.0148, loss=0.0069, norm_factor=290.1407, grad_norm=1.7380\n",
      "Epoch 4: 165/256 - loss_mc=0.0002, loss_t=0.0346, loss_r=0.0129, loss=0.0049, norm_factor=290.5056, grad_norm=1.2170\n",
      "Epoch 4: 166/256 - loss_mc=0.0027, loss_t=0.0325, loss_r=0.0137, loss=0.0073, norm_factor=290.8923, grad_norm=1.3469\n",
      "Epoch 4: 167/256 - loss_mc=0.0028, loss_t=0.0336, loss_r=0.0139, loss=0.0076, norm_factor=291.2676, grad_norm=1.2121\n",
      "Epoch 4: 168/256 - loss_mc=0.0015, loss_t=0.0349, loss_r=0.0133, loss=0.0064, norm_factor=291.6265, grad_norm=1.6243\n",
      "Epoch 4: 169/256 - loss_mc=0.0023, loss_t=0.0368, loss_r=0.0150, loss=0.0075, norm_factor=291.9901, grad_norm=1.3014\n",
      "Epoch 4: 170/256 - loss_mc=0.0030, loss_t=0.0405, loss_r=0.0141, loss=0.0084, norm_factor=292.3425, grad_norm=1.5012\n",
      "Epoch 4: 171/256 - loss_mc=0.0026, loss_t=0.0433, loss_r=0.0174, loss=0.0087, norm_factor=292.6771, grad_norm=1.5922\n",
      "Epoch 4: 172/256 - loss_mc=0.0017, loss_t=0.0390, loss_r=0.0139, loss=0.0070, norm_factor=293.0027, grad_norm=1.9481\n",
      "Epoch 4: 173/256 - loss_mc=0.0013, loss_t=0.0315, loss_r=0.0133, loss=0.0057, norm_factor=293.3387, grad_norm=0.9419\n",
      "Epoch 4: 174/256 - loss_mc=0.0014, loss_t=0.0340, loss_r=0.0144, loss=0.0063, norm_factor=293.6790, grad_norm=1.9558\n",
      "Epoch 4: 175/256 - loss_mc=0.0033, loss_t=0.0430, loss_r=0.0153, loss=0.0091, norm_factor=294.0212, grad_norm=2.8965\n",
      "Epoch 4: 176/256 - loss_mc=0.0006, loss_t=0.0331, loss_r=0.0129, loss=0.0052, norm_factor=294.3420, grad_norm=1.2289\n",
      "Epoch 4: 177/256 - loss_mc=0.0017, loss_t=0.0374, loss_r=0.0148, loss=0.0069, norm_factor=294.6762, grad_norm=1.5168\n",
      "Epoch 4: 178/256 - loss_mc=0.0022, loss_t=0.0376, loss_r=0.0149, loss=0.0074, norm_factor=295.0111, grad_norm=2.7217\n",
      "Epoch 4: 179/256 - loss_mc=-0.0004, loss_t=0.0281, loss_r=0.0124, loss=0.0036, norm_factor=295.3344, grad_norm=0.9173\n",
      "Epoch 4: 180/256 - loss_mc=0.0025, loss_t=0.0456, loss_r=0.0150, loss=0.0086, norm_factor=295.6859, grad_norm=1.5946\n",
      "Epoch 4: 181/256 - loss_mc=0.0010, loss_t=0.0346, loss_r=0.0161, loss=0.0061, norm_factor=296.0242, grad_norm=1.7300\n",
      "Epoch 4: 182/256 - loss_mc=0.0004, loss_t=0.0315, loss_r=0.0129, loss=0.0049, norm_factor=296.3662, grad_norm=1.6414\n",
      "Epoch 4: 183/256 - loss_mc=0.0008, loss_t=0.0364, loss_r=0.0132, loss=0.0057, norm_factor=296.7229, grad_norm=1.8144\n",
      "Epoch 4: 184/256 - loss_mc=0.0007, loss_t=0.0360, loss_r=0.0135, loss=0.0057, norm_factor=297.0886, grad_norm=1.5997\n",
      "Epoch 4: 185/256 - loss_mc=0.0023, loss_t=0.0344, loss_r=0.0141, loss=0.0071, norm_factor=297.4644, grad_norm=1.9641\n",
      "Epoch 4: 186/256 - loss_mc=-0.0003, loss_t=0.0280, loss_r=0.0124, loss=0.0037, norm_factor=297.8293, grad_norm=1.6434\n",
      "Epoch 4: 187/256 - loss_mc=0.0010, loss_t=0.0335, loss_r=0.0142, loss=0.0058, norm_factor=298.2172, grad_norm=1.6726\n",
      "Epoch 4: 188/256 - loss_mc=-0.0004, loss_t=0.0368, loss_r=0.0115, loss=0.0045, norm_factor=298.6086, grad_norm=1.5733\n",
      "Epoch 4: 189/256 - loss_mc=0.0007, loss_t=0.0338, loss_r=0.0127, loss=0.0054, norm_factor=299.0145, grad_norm=1.8264\n",
      "Epoch 4: 190/256 - loss_mc=-0.0007, loss_t=0.0306, loss_r=0.0103, loss=0.0033, norm_factor=299.4238, grad_norm=1.0103\n",
      "Epoch 4: 191/256 - loss_mc=0.0017, loss_t=0.0348, loss_r=0.0133, loss=0.0066, norm_factor=299.8499, grad_norm=1.0787\n",
      "Epoch 4: 192/256 - loss_mc=-0.0005, loss_t=0.0360, loss_r=0.0116, loss=0.0042, norm_factor=300.2612, grad_norm=1.7207\n",
      "Epoch 4: 193/256 - loss_mc=-0.0003, loss_t=0.0312, loss_r=0.0126, loss=0.0041, norm_factor=300.6887, grad_norm=1.2549\n",
      "Epoch 4: 194/256 - loss_mc=0.0021, loss_t=0.0377, loss_r=0.0150, loss=0.0074, norm_factor=301.1270, grad_norm=1.1882\n",
      "Epoch 4: 195/256 - loss_mc=0.0005, loss_t=0.0302, loss_r=0.0140, loss=0.0049, norm_factor=301.5420, grad_norm=1.8552\n",
      "Epoch 4: 196/256 - loss_mc=0.0013, loss_t=0.0349, loss_r=0.0157, loss=0.0063, norm_factor=301.9612, grad_norm=1.2991\n",
      "Epoch 4: 197/256 - loss_mc=0.0020, loss_t=0.0341, loss_r=0.0128, loss=0.0067, norm_factor=302.3767, grad_norm=0.9686\n",
      "Epoch 4: 198/256 - loss_mc=0.0006, loss_t=0.0489, loss_r=0.0181, loss=0.0073, norm_factor=302.7728, grad_norm=1.8371\n",
      "Epoch 4: 199/256 - loss_mc=0.0005, loss_t=0.0377, loss_r=0.0129, loss=0.0055, norm_factor=303.1685, grad_norm=1.6663\n",
      "Epoch 4: 200/256 - loss_mc=-0.0004, loss_t=0.0418, loss_r=0.0124, loss=0.0050, norm_factor=303.5632, grad_norm=1.0556\n",
      "Epoch 4: 201/256 - loss_mc=0.0001, loss_t=0.0327, loss_r=0.0130, loss=0.0047, norm_factor=303.9662, grad_norm=1.6028\n",
      "Epoch 4: 202/256 - loss_mc=0.0002, loss_t=0.0320, loss_r=0.0138, loss=0.0047, norm_factor=304.3730, grad_norm=2.3098\n",
      "Epoch 4: 203/256 - loss_mc=0.0006, loss_t=0.0308, loss_r=0.0130, loss=0.0049, norm_factor=304.7850, grad_norm=1.2463\n",
      "Epoch 4: 204/256 - loss_mc=0.0008, loss_t=0.0398, loss_r=0.0145, loss=0.0062, norm_factor=305.1927, grad_norm=2.1596\n",
      "Epoch 4: 205/256 - loss_mc=-0.0001, loss_t=0.0285, loss_r=0.0121, loss=0.0039, norm_factor=305.5942, grad_norm=1.5975\n",
      "Epoch 4: 206/256 - loss_mc=0.0002, loss_t=0.0350, loss_r=0.0139, loss=0.0051, norm_factor=306.0025, grad_norm=1.8468\n",
      "Epoch 4: 207/256 - loss_mc=-0.0003, loss_t=0.0313, loss_r=0.0117, loss=0.0040, norm_factor=306.4155, grad_norm=1.5368\n",
      "Epoch 4: 208/256 - loss_mc=0.0007, loss_t=0.0310, loss_r=0.0142, loss=0.0052, norm_factor=306.8392, grad_norm=1.4308\n",
      "Epoch 4: 209/256 - loss_mc=-0.0002, loss_t=0.0309, loss_r=0.0136, loss=0.0043, norm_factor=307.2592, grad_norm=1.2432\n",
      "Epoch 4: 210/256 - loss_mc=0.0009, loss_t=0.0370, loss_r=0.0157, loss=0.0062, norm_factor=307.6832, grad_norm=1.0500\n",
      "Epoch 4: 211/256 - loss_mc=0.0022, loss_t=0.0376, loss_r=0.0148, loss=0.0074, norm_factor=308.0909, grad_norm=1.1525\n",
      "Epoch 4: 212/256 - loss_mc=0.0004, loss_t=0.0318, loss_r=0.0123, loss=0.0048, norm_factor=308.4678, grad_norm=1.7741\n",
      "Epoch 4: 213/256 - loss_mc=-0.0003, loss_t=0.0286, loss_r=0.0122, loss=0.0038, norm_factor=308.8439, grad_norm=0.9770\n",
      "Epoch 4: 214/256 - loss_mc=0.0000, loss_t=0.0368, loss_r=0.0114, loss=0.0048, norm_factor=309.2313, grad_norm=1.3370\n",
      "Epoch 4: 215/256 - loss_mc=0.0011, loss_t=0.0339, loss_r=0.0138, loss=0.0059, norm_factor=309.6238, grad_norm=1.6837\n",
      "Epoch 4: 216/256 - loss_mc=-0.0007, loss_t=0.0318, loss_r=0.0120, loss=0.0037, norm_factor=310.0079, grad_norm=1.2271\n",
      "Epoch 4: 217/256 - loss_mc=-0.0007, loss_t=0.0305, loss_r=0.0121, loss=0.0035, norm_factor=310.4088, grad_norm=1.2517\n",
      "Epoch 4: 218/256 - loss_mc=0.0008, loss_t=0.0377, loss_r=0.0129, loss=0.0059, norm_factor=310.8178, grad_norm=1.7894\n",
      "Epoch 4: 219/256 - loss_mc=0.0082, loss_t=0.0390, loss_r=0.0128, loss=0.0134, norm_factor=311.2165, grad_norm=1.7524\n",
      "Epoch 4: 220/256 - loss_mc=0.0002, loss_t=0.0323, loss_r=0.0127, loss=0.0047, norm_factor=311.4944, grad_norm=1.4732\n",
      "Epoch 4: 221/256 - loss_mc=0.0004, loss_t=0.0326, loss_r=0.0112, loss=0.0047, norm_factor=311.7782, grad_norm=1.5224\n",
      "Epoch 4: 222/256 - loss_mc=-0.0001, loss_t=0.0298, loss_r=0.0128, loss=0.0041, norm_factor=312.0695, grad_norm=1.5551\n",
      "Epoch 4: 223/256 - loss_mc=-0.0002, loss_t=0.0292, loss_r=0.0144, loss=0.0041, norm_factor=312.3767, grad_norm=1.5249\n",
      "Epoch 4: 224/256 - loss_mc=-0.0000, loss_t=0.0286, loss_r=0.0133, loss=0.0042, norm_factor=312.7020, grad_norm=2.3515\n",
      "Epoch 4: 225/256 - loss_mc=0.0008, loss_t=0.0404, loss_r=0.0125, loss=0.0061, norm_factor=313.0368, grad_norm=1.8262\n",
      "Epoch 4: 226/256 - loss_mc=-0.0011, loss_t=0.0268, loss_r=0.0106, loss=0.0027, norm_factor=313.3633, grad_norm=0.9734\n",
      "Epoch 4: 227/256 - loss_mc=0.0004, loss_t=0.0280, loss_r=0.0127, loss=0.0044, norm_factor=313.7139, grad_norm=2.0645\n",
      "Epoch 4: 228/256 - loss_mc=-0.0003, loss_t=0.0399, loss_r=0.0170, loss=0.0054, norm_factor=314.0628, grad_norm=1.5645\n",
      "Epoch 4: 229/256 - loss_mc=0.0001, loss_t=0.0384, loss_r=0.0117, loss=0.0051, norm_factor=314.4202, grad_norm=1.7768\n",
      "Epoch 4: 230/256 - loss_mc=-0.0006, loss_t=0.0338, loss_r=0.0132, loss=0.0041, norm_factor=314.7783, grad_norm=1.4324\n",
      "Epoch 4: 231/256 - loss_mc=0.0004, loss_t=0.0363, loss_r=0.0150, loss=0.0056, norm_factor=315.1491, grad_norm=1.3530\n",
      "Epoch 4: 232/256 - loss_mc=0.0004, loss_t=0.0425, loss_r=0.0122, loss=0.0059, norm_factor=315.5186, grad_norm=1.5628\n",
      "Epoch 4: 233/256 - loss_mc=0.0009, loss_t=0.0275, loss_r=0.0147, loss=0.0051, norm_factor=315.8869, grad_norm=1.2441\n",
      "Epoch 4: 234/256 - loss_mc=-0.0002, loss_t=0.0315, loss_r=0.0121, loss=0.0042, norm_factor=316.2429, grad_norm=1.1184\n",
      "Epoch 4: 235/256 - loss_mc=-0.0007, loss_t=0.0305, loss_r=0.0134, loss=0.0037, norm_factor=316.6047, grad_norm=1.0399\n",
      "Epoch 4: 236/256 - loss_mc=-0.0010, loss_t=0.0298, loss_r=0.0103, loss=0.0030, norm_factor=316.9742, grad_norm=0.9279\n",
      "Epoch 4: 237/256 - loss_mc=-0.0003, loss_t=0.0318, loss_r=0.0118, loss=0.0040, norm_factor=317.3555, grad_norm=1.5162\n",
      "Epoch 4: 238/256 - loss_mc=-0.0001, loss_t=0.0342, loss_r=0.0157, loss=0.0049, norm_factor=317.7418, grad_norm=0.9327\n",
      "Epoch 4: 239/256 - loss_mc=0.0003, loss_t=0.0331, loss_r=0.0126, loss=0.0049, norm_factor=318.1230, grad_norm=1.2449\n",
      "Epoch 4: 240/256 - loss_mc=0.0018, loss_t=0.0259, loss_r=0.0121, loss=0.0056, norm_factor=318.4936, grad_norm=1.1438\n",
      "Epoch 4: 241/256 - loss_mc=-0.0012, loss_t=0.0216, loss_r=0.0137, loss=0.0024, norm_factor=318.8359, grad_norm=0.8695\n",
      "Epoch 4: 242/256 - loss_mc=-0.0007, loss_t=0.0278, loss_r=0.0112, loss=0.0032, norm_factor=319.1973, grad_norm=0.7029\n",
      "Epoch 4: 243/256 - loss_mc=0.0008, loss_t=0.0337, loss_r=0.0129, loss=0.0054, norm_factor=319.5686, grad_norm=1.5055\n",
      "Epoch 4: 244/256 - loss_mc=-0.0014, loss_t=0.0288, loss_r=0.0112, loss=0.0026, norm_factor=319.9211, grad_norm=1.2040\n",
      "Epoch 4: 245/256 - loss_mc=-0.0002, loss_t=0.0346, loss_r=0.0112, loss=0.0044, norm_factor=320.2896, grad_norm=1.4611\n",
      "Epoch 4: 246/256 - loss_mc=-0.0015, loss_t=0.0299, loss_r=0.0121, loss=0.0028, norm_factor=320.6628, grad_norm=1.0595\n",
      "Epoch 4: 247/256 - loss_mc=-0.0020, loss_t=0.0322, loss_r=0.0098, loss=0.0022, norm_factor=321.0541, grad_norm=1.1047\n",
      "Epoch 4: 248/256 - loss_mc=-0.0013, loss_t=0.0305, loss_r=0.0113, loss=0.0029, norm_factor=321.4691, grad_norm=1.0368\n",
      "Epoch 4: 249/256 - loss_mc=-0.0002, loss_t=0.0297, loss_r=0.0144, loss=0.0042, norm_factor=321.8980, grad_norm=1.1393\n",
      "Epoch 4: 250/256 - loss_mc=-0.0019, loss_t=0.0298, loss_r=0.0122, loss=0.0023, norm_factor=322.3132, grad_norm=1.2725\n",
      "Epoch 4: 251/256 - loss_mc=-0.0004, loss_t=0.0281, loss_r=0.0113, loss=0.0035, norm_factor=322.7470, grad_norm=1.1753\n",
      "Epoch 4: 252/256 - loss_mc=-0.0019, loss_t=0.0297, loss_r=0.0109, loss=0.0022, norm_factor=323.1733, grad_norm=1.0694\n",
      "Epoch 4: 253/256 - loss_mc=-0.0016, loss_t=0.0280, loss_r=0.0114, loss=0.0024, norm_factor=323.6196, grad_norm=1.4308\n",
      "Epoch 4: 254/256 - loss_mc=-0.0023, loss_t=0.0276, loss_r=0.0116, loss=0.0016, norm_factor=324.0740, grad_norm=1.7447\n",
      "Epoch 4: 255/256 - loss_mc=-0.0005, loss_t=0.0291, loss_r=0.0126, loss=0.0037, norm_factor=324.5493, grad_norm=0.9002\n",
      "Epoch 4: 256/256 - loss_mc=-0.0005, loss_t=0.0325, loss_r=0.0148, loss=0.0042, norm_factor=325.0134, grad_norm=1.3014\n",
      "Epoch 5: 1/256 - loss_mc=-0.0010, loss_t=0.0341, loss_r=0.0116, loss=0.0036, norm_factor=325.4664, grad_norm=1.7817\n",
      "Epoch 5: 2/256 - loss_mc=-0.0011, loss_t=0.0278, loss_r=0.0126, loss=0.0029, norm_factor=325.9168, grad_norm=1.5779\n",
      "Epoch 5: 3/256 - loss_mc=-0.0017, loss_t=0.0258, loss_r=0.0112, loss=0.0020, norm_factor=326.3663, grad_norm=0.9061\n",
      "Epoch 5: 4/256 - loss_mc=-0.0010, loss_t=0.0331, loss_r=0.0125, loss=0.0036, norm_factor=326.8248, grad_norm=1.6413\n",
      "Epoch 5: 5/256 - loss_mc=-0.0015, loss_t=0.0298, loss_r=0.0115, loss=0.0027, norm_factor=327.2817, grad_norm=1.8185\n",
      "Epoch 5: 6/256 - loss_mc=-0.0011, loss_t=0.0294, loss_r=0.0129, loss=0.0032, norm_factor=327.7409, grad_norm=1.0375\n",
      "Epoch 5: 7/256 - loss_mc=-0.0021, loss_t=0.0275, loss_r=0.0090, loss=0.0015, norm_factor=328.1987, grad_norm=1.3998\n",
      "Epoch 5: 8/256 - loss_mc=-0.0011, loss_t=0.0309, loss_r=0.0140, loss=0.0034, norm_factor=328.6736, grad_norm=1.1640\n",
      "Epoch 5: 9/256 - loss_mc=0.0001, loss_t=0.0278, loss_r=0.0127, loss=0.0041, norm_factor=329.1462, grad_norm=1.0292\n",
      "Epoch 5: 10/256 - loss_mc=-0.0026, loss_t=0.0279, loss_r=0.0108, loss=0.0012, norm_factor=329.5918, grad_norm=1.3322\n",
      "Epoch 5: 11/256 - loss_mc=-0.0018, loss_t=0.0262, loss_r=0.0108, loss=0.0019, norm_factor=330.0593, grad_norm=1.4204\n",
      "Epoch 5: 12/256 - loss_mc=-0.0011, loss_t=0.0275, loss_r=0.0124, loss=0.0029, norm_factor=330.5341, grad_norm=1.3740\n",
      "Epoch 5: 13/256 - loss_mc=-0.0014, loss_t=0.0302, loss_r=0.0111, loss=0.0027, norm_factor=331.0043, grad_norm=1.2827\n",
      "Epoch 5: 14/256 - loss_mc=-0.0012, loss_t=0.0270, loss_r=0.0114, loss=0.0026, norm_factor=331.4710, grad_norm=1.6427\n",
      "Epoch 5: 15/256 - loss_mc=-0.0017, loss_t=0.0240, loss_r=0.0118, loss=0.0019, norm_factor=331.9346, grad_norm=1.1950\n",
      "Epoch 5: 16/256 - loss_mc=-0.0017, loss_t=0.0277, loss_r=0.0128, loss=0.0023, norm_factor=332.3993, grad_norm=1.1716\n",
      "Epoch 5: 17/256 - loss_mc=-0.0024, loss_t=0.0230, loss_r=0.0105, loss=0.0010, norm_factor=332.8674, grad_norm=1.3829\n",
      "Epoch 5: 18/256 - loss_mc=-0.0016, loss_t=0.0245, loss_r=0.0105, loss=0.0019, norm_factor=333.3525, grad_norm=1.4420\n",
      "Epoch 5: 19/256 - loss_mc=-0.0004, loss_t=0.0304, loss_r=0.0141, loss=0.0040, norm_factor=333.8408, grad_norm=1.3402\n",
      "Epoch 5: 20/256 - loss_mc=-0.0007, loss_t=0.0373, loss_r=0.0173, loss=0.0048, norm_factor=334.3080, grad_norm=1.0176\n",
      "Epoch 5: 21/256 - loss_mc=-0.0021, loss_t=0.0270, loss_r=0.0106, loss=0.0017, norm_factor=334.7636, grad_norm=1.7660\n",
      "Epoch 5: 22/256 - loss_mc=-0.0013, loss_t=0.0323, loss_r=0.0108, loss=0.0030, norm_factor=335.2273, grad_norm=0.9181\n",
      "Epoch 5: 23/256 - loss_mc=-0.0014, loss_t=0.0276, loss_r=0.0109, loss=0.0024, norm_factor=335.6853, grad_norm=1.5853\n",
      "Epoch 5: 24/256 - loss_mc=-0.0010, loss_t=0.0286, loss_r=0.0106, loss=0.0029, norm_factor=336.1394, grad_norm=1.1457\n",
      "Epoch 5: 25/256 - loss_mc=-0.0017, loss_t=0.0248, loss_r=0.0112, loss=0.0019, norm_factor=336.5825, grad_norm=1.3263\n",
      "Epoch 5: 26/256 - loss_mc=-0.0022, loss_t=0.0221, loss_r=0.0127, loss=0.0013, norm_factor=337.0334, grad_norm=1.5484\n",
      "Epoch 5: 27/256 - loss_mc=-0.0022, loss_t=0.0255, loss_r=0.0106, loss=0.0014, norm_factor=337.4967, grad_norm=1.1897\n",
      "Epoch 5: 28/256 - loss_mc=-0.0009, loss_t=0.0284, loss_r=0.0127, loss=0.0032, norm_factor=337.9727, grad_norm=1.1887\n",
      "Epoch 5: 29/256 - loss_mc=-0.0030, loss_t=0.0233, loss_r=0.0114, loss=0.0005, norm_factor=338.4404, grad_norm=1.3376\n",
      "Epoch 5: 30/256 - loss_mc=-0.0024, loss_t=0.0277, loss_r=0.0113, loss=0.0015, norm_factor=338.9288, grad_norm=1.5250\n",
      "Epoch 5: 31/256 - loss_mc=0.0022, loss_t=0.0310, loss_r=0.0130, loss=0.0066, norm_factor=339.4280, grad_norm=1.0065\n",
      "Epoch 5: 32/256 - loss_mc=-0.0014, loss_t=0.0259, loss_r=0.0112, loss=0.0023, norm_factor=339.8565, grad_norm=1.0881\n",
      "Epoch 5: 33/256 - loss_mc=-0.0017, loss_t=0.0250, loss_r=0.0115, loss=0.0020, norm_factor=340.2856, grad_norm=1.1462\n",
      "Epoch 5: 34/256 - loss_mc=-0.0027, loss_t=0.0265, loss_r=0.0103, loss=0.0010, norm_factor=340.7153, grad_norm=1.1991\n",
      "Epoch 5: 35/256 - loss_mc=-0.0024, loss_t=0.0221, loss_r=0.0106, loss=0.0009, norm_factor=341.1617, grad_norm=1.0807\n",
      "Epoch 5: 36/256 - loss_mc=-0.0026, loss_t=0.0223, loss_r=0.0116, loss=0.0008, norm_factor=341.6241, grad_norm=0.8895\n",
      "Epoch 5: 37/256 - loss_mc=-0.0022, loss_t=0.0294, loss_r=0.0103, loss=0.0018, norm_factor=342.1008, grad_norm=1.2973\n",
      "Epoch 5: 38/256 - loss_mc=-0.0002, loss_t=0.0351, loss_r=0.0096, loss=0.0043, norm_factor=342.5815, grad_norm=1.6988\n",
      "Epoch 5: 39/256 - loss_mc=-0.0015, loss_t=0.0325, loss_r=0.0138, loss=0.0031, norm_factor=343.0327, grad_norm=2.0180\n",
      "Epoch 5: 40/256 - loss_mc=-0.0026, loss_t=0.0268, loss_r=0.0115, loss=0.0012, norm_factor=343.4742, grad_norm=1.7913\n",
      "Epoch 5: 41/256 - loss_mc=-0.0026, loss_t=0.0302, loss_r=0.0112, loss=0.0015, norm_factor=343.9301, grad_norm=1.4579\n",
      "Epoch 5: 42/256 - loss_mc=0.0000, loss_t=0.0318, loss_r=0.0147, loss=0.0047, norm_factor=344.3995, grad_norm=2.2002\n",
      "Epoch 5: 43/256 - loss_mc=-0.0021, loss_t=0.0249, loss_r=0.0115, loss=0.0015, norm_factor=344.8350, grad_norm=1.3214\n",
      "Epoch 5: 44/256 - loss_mc=-0.0024, loss_t=0.0254, loss_r=0.0114, loss=0.0013, norm_factor=345.2729, grad_norm=0.9790\n",
      "Epoch 5: 45/256 - loss_mc=-0.0021, loss_t=0.0323, loss_r=0.0118, loss=0.0023, norm_factor=345.7207, grad_norm=2.4616\n",
      "Epoch 5: 46/256 - loss_mc=0.0052, loss_t=0.0328, loss_r=0.0120, loss=0.0096, norm_factor=346.1736, grad_norm=1.5110\n",
      "Epoch 5: 47/256 - loss_mc=-0.0028, loss_t=0.0366, loss_r=0.0137, loss=0.0023, norm_factor=346.4982, grad_norm=1.9369\n",
      "Epoch 5: 48/256 - loss_mc=-0.0022, loss_t=0.0355, loss_r=0.0094, loss=0.0022, norm_factor=346.8434, grad_norm=1.5535\n",
      "Epoch 5: 49/256 - loss_mc=-0.0028, loss_t=0.0245, loss_r=0.0105, loss=0.0007, norm_factor=347.2020, grad_norm=0.9565\n",
      "Epoch 5: 50/256 - loss_mc=-0.0024, loss_t=0.0320, loss_r=0.0109, loss=0.0019, norm_factor=347.5876, grad_norm=1.8415\n",
      "Epoch 5: 51/256 - loss_mc=-0.0025, loss_t=0.0273, loss_r=0.0107, loss=0.0013, norm_factor=347.9894, grad_norm=1.2131\n",
      "Epoch 5: 52/256 - loss_mc=-0.0028, loss_t=0.0261, loss_r=0.0100, loss=0.0008, norm_factor=348.4050, grad_norm=1.1619\n",
      "Epoch 5: 53/256 - loss_mc=-0.0028, loss_t=0.0291, loss_r=0.0102, loss=0.0011, norm_factor=348.8343, grad_norm=1.3821\n",
      "Epoch 5: 54/256 - loss_mc=-0.0037, loss_t=0.0222, loss_r=0.0095, loss=-0.0005, norm_factor=349.2727, grad_norm=1.1787\n",
      "Epoch 5: 55/256 - loss_mc=-0.0023, loss_t=0.0277, loss_r=0.0112, loss=0.0016, norm_factor=349.7381, grad_norm=1.0816\n",
      "Epoch 5: 56/256 - loss_mc=-0.0033, loss_t=0.0196, loss_r=0.0105, loss=-0.0003, norm_factor=350.2061, grad_norm=1.3080\n",
      "Epoch 5: 57/256 - loss_mc=-0.0000, loss_t=0.0286, loss_r=0.0123, loss=0.0041, norm_factor=350.6904, grad_norm=1.4558\n",
      "Epoch 5: 58/256 - loss_mc=-0.0025, loss_t=0.0294, loss_r=0.0182, loss=0.0023, norm_factor=351.1353, grad_norm=0.9869\n",
      "Epoch 5: 59/256 - loss_mc=-0.0022, loss_t=0.0306, loss_r=0.0111, loss=0.0020, norm_factor=351.5903, grad_norm=1.1624\n",
      "Epoch 5: 60/256 - loss_mc=-0.0002, loss_t=0.0294, loss_r=0.0123, loss=0.0040, norm_factor=352.0392, grad_norm=1.2637\n",
      "Epoch 5: 61/256 - loss_mc=-0.0034, loss_t=0.0237, loss_r=0.0108, loss=0.0001, norm_factor=352.4557, grad_norm=0.7441\n",
      "Epoch 5: 62/256 - loss_mc=-0.0024, loss_t=0.0232, loss_r=0.0103, loss=0.0009, norm_factor=352.9010, grad_norm=1.1260\n",
      "Epoch 5: 63/256 - loss_mc=-0.0024, loss_t=0.0373, loss_r=0.0127, loss=0.0026, norm_factor=353.3527, grad_norm=1.4275\n",
      "Epoch 5: 64/256 - loss_mc=-0.0026, loss_t=0.0276, loss_r=0.0105, loss=0.0012, norm_factor=353.8079, grad_norm=0.9720\n",
      "Epoch 5: 65/256 - loss_mc=-0.0022, loss_t=0.0234, loss_r=0.0123, loss=0.0014, norm_factor=354.2673, grad_norm=1.3064\n",
      "Epoch 5: 66/256 - loss_mc=-0.0031, loss_t=0.0295, loss_r=0.0091, loss=0.0008, norm_factor=354.7294, grad_norm=1.6363\n",
      "Epoch 5: 67/256 - loss_mc=-0.0031, loss_t=0.0264, loss_r=0.0098, loss=0.0005, norm_factor=355.2003, grad_norm=1.3505\n",
      "Epoch 5: 68/256 - loss_mc=-0.0032, loss_t=0.0219, loss_r=0.0090, loss=-0.0001, norm_factor=355.6835, grad_norm=0.9712\n",
      "Epoch 5: 69/256 - loss_mc=-0.0024, loss_t=0.0263, loss_r=0.0100, loss=0.0013, norm_factor=356.1749, grad_norm=1.5077\n",
      "Epoch 5: 70/256 - loss_mc=-0.0028, loss_t=0.0235, loss_r=0.0109, loss=0.0007, norm_factor=356.6597, grad_norm=0.9951\n",
      "Epoch 5: 71/256 - loss_mc=-0.0021, loss_t=0.0306, loss_r=0.0133, loss=0.0023, norm_factor=357.1472, grad_norm=1.7502\n",
      "Epoch 5: 72/256 - loss_mc=-0.0023, loss_t=0.0239, loss_r=0.0088, loss=0.0010, norm_factor=357.6238, grad_norm=1.2326\n",
      "Epoch 5: 73/256 - loss_mc=-0.0030, loss_t=0.0235, loss_r=0.0101, loss=0.0004, norm_factor=358.0952, grad_norm=1.4981\n",
      "Epoch 5: 74/256 - loss_mc=-0.0036, loss_t=0.0210, loss_r=0.0102, loss=-0.0005, norm_factor=358.5768, grad_norm=0.8473\n",
      "Epoch 5: 75/256 - loss_mc=-0.0027, loss_t=0.0203, loss_r=0.0102, loss=0.0003, norm_factor=359.0744, grad_norm=0.8638\n",
      "Epoch 5: 76/256 - loss_mc=-0.0035, loss_t=0.0202, loss_r=0.0093, loss=-0.0006, norm_factor=359.5702, grad_norm=1.3301\n",
      "Epoch 5: 77/256 - loss_mc=-0.0034, loss_t=0.0241, loss_r=0.0096, loss=-0.0000, norm_factor=360.0783, grad_norm=1.0493\n",
      "Epoch 5: 78/256 - loss_mc=-0.0033, loss_t=0.0312, loss_r=0.0092, loss=0.0007, norm_factor=360.5935, grad_norm=1.4815\n",
      "Epoch 5: 79/256 - loss_mc=-0.0031, loss_t=0.0284, loss_r=0.0092, loss=0.0007, norm_factor=361.1167, grad_norm=1.8539\n",
      "Epoch 5: 80/256 - loss_mc=-0.0019, loss_t=0.0242, loss_r=0.0103, loss=0.0016, norm_factor=361.6437, grad_norm=1.0364\n",
      "Epoch 5: 81/256 - loss_mc=-0.0006, loss_t=0.0353, loss_r=0.0108, loss=0.0040, norm_factor=362.1536, grad_norm=1.9193\n",
      "Epoch 5: 82/256 - loss_mc=-0.0027, loss_t=0.0292, loss_r=0.0098, loss=0.0012, norm_factor=362.6229, grad_norm=1.0455\n",
      "Epoch 5: 83/256 - loss_mc=-0.0031, loss_t=0.0294, loss_r=0.0093, loss=0.0007, norm_factor=363.0936, grad_norm=1.7479\n",
      "Epoch 5: 84/256 - loss_mc=-0.0032, loss_t=0.0296, loss_r=0.0098, loss=0.0008, norm_factor=363.5730, grad_norm=1.6371\n",
      "Epoch 5: 85/256 - loss_mc=-0.0027, loss_t=0.0237, loss_r=0.0119, loss=0.0008, norm_factor=364.0594, grad_norm=1.4067\n",
      "Epoch 5: 86/256 - loss_mc=-0.0030, loss_t=0.0254, loss_r=0.0121, loss=0.0008, norm_factor=364.5464, grad_norm=1.3486\n",
      "Epoch 5: 87/256 - loss_mc=-0.0019, loss_t=0.0288, loss_r=0.0100, loss=0.0020, norm_factor=365.0406, grad_norm=1.6487\n",
      "Epoch 5: 88/256 - loss_mc=-0.0027, loss_t=0.0219, loss_r=0.0108, loss=0.0006, norm_factor=365.5192, grad_norm=1.0169\n",
      "Epoch 5: 89/256 - loss_mc=-0.0010, loss_t=0.0295, loss_r=0.0097, loss=0.0029, norm_factor=365.9946, grad_norm=1.2970\n",
      "Epoch 5: 90/256 - loss_mc=-0.0035, loss_t=0.0185, loss_r=0.0100, loss=-0.0006, norm_factor=366.4319, grad_norm=1.1356\n",
      "Epoch 5: 91/256 - loss_mc=-0.0033, loss_t=0.0333, loss_r=0.0101, loss=0.0010, norm_factor=366.8831, grad_norm=1.6258\n",
      "Epoch 5: 92/256 - loss_mc=-0.0043, loss_t=0.0219, loss_r=0.0095, loss=-0.0011, norm_factor=367.3420, grad_norm=1.1971\n",
      "Epoch 5: 93/256 - loss_mc=-0.0038, loss_t=0.0207, loss_r=0.0092, loss=-0.0009, norm_factor=367.8271, grad_norm=1.7248\n",
      "Epoch 5: 94/256 - loss_mc=-0.0015, loss_t=0.0251, loss_r=0.0138, loss=0.0024, norm_factor=368.3304, grad_norm=0.8702\n",
      "Epoch 5: 95/256 - loss_mc=-0.0035, loss_t=0.0283, loss_r=0.0107, loss=0.0004, norm_factor=368.8056, grad_norm=2.1804\n",
      "Epoch 5: 96/256 - loss_mc=-0.0032, loss_t=0.0188, loss_r=0.0088, loss=-0.0005, norm_factor=369.2958, grad_norm=1.0527\n",
      "Epoch 5: 97/256 - loss_mc=-0.0039, loss_t=0.0228, loss_r=0.0095, loss=-0.0007, norm_factor=369.7902, grad_norm=1.2189\n",
      "Epoch 5: 98/256 - loss_mc=-0.0034, loss_t=0.0254, loss_r=0.0091, loss=0.0000, norm_factor=370.2954, grad_norm=1.9967\n",
      "Epoch 5: 99/256 - loss_mc=-0.0033, loss_t=0.0236, loss_r=0.0095, loss=-0.0000, norm_factor=370.8030, grad_norm=1.0128\n",
      "Epoch 5: 100/256 - loss_mc=-0.0031, loss_t=0.0273, loss_r=0.0097, loss=0.0006, norm_factor=371.3174, grad_norm=1.9475\n",
      "Epoch 5: 101/256 - loss_mc=-0.0032, loss_t=0.0288, loss_r=0.0092, loss=0.0006, norm_factor=371.8287, grad_norm=1.6011\n",
      "Epoch 5: 102/256 - loss_mc=-0.0009, loss_t=0.0322, loss_r=0.0116, loss=0.0035, norm_factor=372.3370, grad_norm=1.6318\n",
      "Epoch 5: 103/256 - loss_mc=-0.0029, loss_t=0.0259, loss_r=0.0109, loss=0.0008, norm_factor=372.7980, grad_norm=1.8411\n",
      "Epoch 5: 104/256 - loss_mc=-0.0035, loss_t=0.0231, loss_r=0.0098, loss=-0.0002, norm_factor=373.2589, grad_norm=1.3603\n",
      "Epoch 5: 105/256 - loss_mc=-0.0041, loss_t=0.0207, loss_r=0.0094, loss=-0.0011, norm_factor=373.7294, grad_norm=1.7340\n",
      "Epoch 5: 106/256 - loss_mc=-0.0031, loss_t=0.0251, loss_r=0.0080, loss=0.0002, norm_factor=374.2192, grad_norm=2.2695\n",
      "Epoch 5: 107/256 - loss_mc=-0.0037, loss_t=0.0243, loss_r=0.0087, loss=-0.0004, norm_factor=374.7103, grad_norm=1.0196\n",
      "Epoch 5: 108/256 - loss_mc=-0.0019, loss_t=0.0268, loss_r=0.0123, loss=0.0020, norm_factor=375.2094, grad_norm=1.6922\n",
      "Epoch 5: 109/256 - loss_mc=-0.0037, loss_t=0.0239, loss_r=0.0085, loss=-0.0005, norm_factor=375.6724, grad_norm=1.8112\n",
      "Epoch 5: 110/256 - loss_mc=-0.0036, loss_t=0.0203, loss_r=0.0099, loss=-0.0006, norm_factor=376.1474, grad_norm=1.2230\n",
      "Epoch 5: 111/256 - loss_mc=-0.0036, loss_t=0.0198, loss_r=0.0094, loss=-0.0007, norm_factor=376.6360, grad_norm=1.8510\n",
      "Epoch 5: 112/256 - loss_mc=-0.0037, loss_t=0.0220, loss_r=0.0107, loss=-0.0004, norm_factor=377.1344, grad_norm=1.5456\n",
      "Epoch 5: 113/256 - loss_mc=-0.0037, loss_t=0.0317, loss_r=0.0124, loss=0.0007, norm_factor=377.6342, grad_norm=1.4924\n",
      "Epoch 5: 114/256 - loss_mc=-0.0035, loss_t=0.0242, loss_r=0.0093, loss=-0.0001, norm_factor=378.1395, grad_norm=1.5860\n",
      "Epoch 5: 115/256 - loss_mc=-0.0037, loss_t=0.0219, loss_r=0.0098, loss=-0.0006, norm_factor=378.6461, grad_norm=1.8141\n",
      "Epoch 5: 116/256 - loss_mc=-0.0036, loss_t=0.0383, loss_r=0.0120, loss=0.0014, norm_factor=379.1565, grad_norm=1.5805\n",
      "Epoch 5: 117/256 - loss_mc=-0.0021, loss_t=0.0205, loss_r=0.0126, loss=0.0012, norm_factor=379.6724, grad_norm=1.4742\n",
      "Epoch 5: 118/256 - loss_mc=-0.0035, loss_t=0.0341, loss_r=0.0097, loss=0.0008, norm_factor=380.1591, grad_norm=1.6172\n",
      "Epoch 5: 119/256 - loss_mc=-0.0045, loss_t=0.0234, loss_r=0.0093, loss=-0.0013, norm_factor=380.6479, grad_norm=1.4532\n",
      "Epoch 5: 120/256 - loss_mc=-0.0050, loss_t=0.0166, loss_r=0.0078, loss=-0.0026, norm_factor=381.1581, grad_norm=1.4446\n",
      "Epoch 5: 121/256 - loss_mc=-0.0043, loss_t=0.0207, loss_r=0.0086, loss=-0.0014, norm_factor=381.6949, grad_norm=1.6307\n",
      "Epoch 5: 122/256 - loss_mc=-0.0030, loss_t=0.0330, loss_r=0.0100, loss=0.0013, norm_factor=382.2428, grad_norm=1.3378\n",
      "Epoch 5: 123/256 - loss_mc=-0.0032, loss_t=0.0178, loss_r=0.0130, loss=-0.0001, norm_factor=382.7731, grad_norm=1.3311\n",
      "Epoch 5: 124/256 - loss_mc=-0.0036, loss_t=0.0206, loss_r=0.0093, loss=-0.0006, norm_factor=383.2936, grad_norm=2.0991\n",
      "Epoch 5: 125/256 - loss_mc=-0.0041, loss_t=0.0215, loss_r=0.0090, loss=-0.0010, norm_factor=383.8179, grad_norm=0.9134\n",
      "Epoch 5: 126/256 - loss_mc=-0.0037, loss_t=0.0232, loss_r=0.0088, loss=-0.0005, norm_factor=384.3489, grad_norm=1.3490\n",
      "Epoch 5: 127/256 - loss_mc=-0.0044, loss_t=0.0235, loss_r=0.0089, loss=-0.0012, norm_factor=384.8813, grad_norm=2.0258\n",
      "Epoch 5: 128/256 - loss_mc=-0.0048, loss_t=0.0220, loss_r=0.0074, loss=-0.0018, norm_factor=385.4278, grad_norm=0.9821\n",
      "Epoch 5: 129/256 - loss_mc=-0.0040, loss_t=0.0225, loss_r=0.0085, loss=-0.0009, norm_factor=385.9973, grad_norm=1.5224\n",
      "Epoch 5: 130/256 - loss_mc=-0.0035, loss_t=0.0214, loss_r=0.0094, loss=-0.0004, norm_factor=386.5677, grad_norm=1.6871\n",
      "Epoch 5: 131/256 - loss_mc=-0.0037, loss_t=0.0264, loss_r=0.0112, loss=0.0001, norm_factor=387.1284, grad_norm=1.2207\n",
      "Epoch 5: 132/256 - loss_mc=-0.0038, loss_t=0.0245, loss_r=0.0093, loss=-0.0004, norm_factor=387.6893, grad_norm=1.3898\n",
      "Epoch 5: 133/256 - loss_mc=-0.0044, loss_t=0.0200, loss_r=0.0089, loss=-0.0015, norm_factor=388.2517, grad_norm=1.6135\n",
      "Epoch 5: 134/256 - loss_mc=-0.0036, loss_t=0.0301, loss_r=0.0101, loss=0.0004, norm_factor=388.8190, grad_norm=1.4054\n",
      "Epoch 5: 135/256 - loss_mc=-0.0037, loss_t=0.0238, loss_r=0.0094, loss=-0.0004, norm_factor=389.3764, grad_norm=1.2739\n",
      "Epoch 5: 136/256 - loss_mc=-0.0046, loss_t=0.0243, loss_r=0.0084, loss=-0.0014, norm_factor=389.9293, grad_norm=1.6286\n",
      "Epoch 5: 137/256 - loss_mc=-0.0029, loss_t=0.0286, loss_r=0.0101, loss=0.0010, norm_factor=390.4987, grad_norm=1.4139\n",
      "Epoch 5: 138/256 - loss_mc=-0.0049, loss_t=0.0269, loss_r=0.0081, loss=-0.0014, norm_factor=391.0406, grad_norm=1.1775\n",
      "Epoch 5: 139/256 - loss_mc=-0.0035, loss_t=0.0217, loss_r=0.0088, loss=-0.0005, norm_factor=391.6001, grad_norm=1.3018\n",
      "Epoch 5: 140/256 - loss_mc=-0.0049, loss_t=0.0164, loss_r=0.0078, loss=-0.0025, norm_factor=392.1497, grad_norm=1.1379\n",
      "Epoch 5: 141/256 - loss_mc=-0.0045, loss_t=0.0208, loss_r=0.0090, loss=-0.0015, norm_factor=392.7159, grad_norm=1.1812\n",
      "Epoch 5: 142/256 - loss_mc=-0.0039, loss_t=0.0228, loss_r=0.0088, loss=-0.0007, norm_factor=393.2878, grad_norm=1.5388\n",
      "Epoch 5: 143/256 - loss_mc=-0.0048, loss_t=0.0212, loss_r=0.0082, loss=-0.0019, norm_factor=393.8509, grad_norm=1.0962\n",
      "Epoch 5: 144/256 - loss_mc=-0.0043, loss_t=0.0212, loss_r=0.0097, loss=-0.0012, norm_factor=394.4247, grad_norm=1.3353\n",
      "Epoch 5: 145/256 - loss_mc=-0.0045, loss_t=0.0183, loss_r=0.0082, loss=-0.0019, norm_factor=394.9991, grad_norm=1.4186\n",
      "Epoch 5: 146/256 - loss_mc=-0.0050, loss_t=0.0186, loss_r=0.0084, loss=-0.0023, norm_factor=395.5809, grad_norm=1.1828\n",
      "Epoch 5: 147/256 - loss_mc=-0.0042, loss_t=0.0206, loss_r=0.0098, loss=-0.0011, norm_factor=396.1768, grad_norm=1.0482\n",
      "Epoch 5: 148/256 - loss_mc=-0.0043, loss_t=0.0250, loss_r=0.0093, loss=-0.0009, norm_factor=396.7695, grad_norm=1.7017\n",
      "Epoch 5: 149/256 - loss_mc=-0.0036, loss_t=0.0228, loss_r=0.0140, loss=0.0000, norm_factor=397.3588, grad_norm=1.0562\n",
      "Epoch 5: 150/256 - loss_mc=-0.0048, loss_t=0.0214, loss_r=0.0079, loss=-0.0018, norm_factor=397.9294, grad_norm=1.1258\n",
      "Epoch 5: 151/256 - loss_mc=-0.0047, loss_t=0.0203, loss_r=0.0083, loss=-0.0019, norm_factor=398.5108, grad_norm=1.1794\n",
      "Epoch 5: 152/256 - loss_mc=-0.0051, loss_t=0.0179, loss_r=0.0073, loss=-0.0026, norm_factor=399.0989, grad_norm=0.7632\n",
      "Epoch 5: 153/256 - loss_mc=-0.0047, loss_t=0.0223, loss_r=0.0077, loss=-0.0017, norm_factor=399.6979, grad_norm=0.9707\n",
      "Epoch 5: 154/256 - loss_mc=-0.0045, loss_t=0.0207, loss_r=0.0074, loss=-0.0017, norm_factor=400.3012, grad_norm=1.6509\n",
      "Epoch 5: 155/256 - loss_mc=-0.0050, loss_t=0.0198, loss_r=0.0083, loss=-0.0022, norm_factor=400.9043, grad_norm=1.6341\n",
      "Epoch 5: 156/256 - loss_mc=-0.0034, loss_t=0.3472, loss_r=0.0165, loss=0.0329, norm_factor=401.5159, grad_norm=4.9832\n",
      "Epoch 5: 157/256 - loss_mc=-0.0034, loss_t=0.0276, loss_r=0.0092, loss=0.0003, norm_factor=401.9072, grad_norm=2.0246\n",
      "Epoch 5: 158/256 - loss_mc=-0.0018, loss_t=0.0282, loss_r=0.0140, loss=0.0025, norm_factor=402.2982, grad_norm=1.4704\n",
      "Epoch 5: 159/256 - loss_mc=0.0015, loss_t=0.0350, loss_r=0.0191, loss=0.0069, norm_factor=402.6566, grad_norm=1.7164\n",
      "Epoch 5: 160/256 - loss_mc=0.0015, loss_t=0.0465, loss_r=0.0266, loss=0.0088, norm_factor=402.9137, grad_norm=2.1316\n",
      "Epoch 5: 161/256 - loss_mc=0.0013, loss_t=0.0510, loss_r=0.0198, loss=0.0083, norm_factor=403.0705, grad_norm=1.2407\n",
      "Epoch 5: 162/256 - loss_mc=-0.0004, loss_t=0.0433, loss_r=0.0169, loss=0.0056, norm_factor=403.1397, grad_norm=2.5794\n",
      "Epoch 5: 163/256 - loss_mc=-0.0013, loss_t=0.0427, loss_r=0.0184, loss=0.0048, norm_factor=403.1615, grad_norm=1.6592\n",
      "Epoch 5: 164/256 - loss_mc=0.0013, loss_t=0.0422, loss_r=0.0197, loss=0.0075, norm_factor=403.1638, grad_norm=1.5321\n",
      "Epoch 5: 165/256 - loss_mc=0.0023, loss_t=0.0516, loss_r=0.0338, loss=0.0108, norm_factor=403.0908, grad_norm=1.8260\n",
      "Epoch 5: 166/256 - loss_mc=0.0013, loss_t=0.0430, loss_r=0.0231, loss=0.0079, norm_factor=402.9307, grad_norm=1.6631\n",
      "Epoch 5: 167/256 - loss_mc=0.0013, loss_t=0.0489, loss_r=0.0215, loss=0.0083, norm_factor=402.7112, grad_norm=1.7623\n",
      "Epoch 5: 168/256 - loss_mc=-0.0010, loss_t=0.0491, loss_r=0.0168, loss=0.0056, norm_factor=402.4376, grad_norm=2.2158\n",
      "Epoch 5: 169/256 - loss_mc=0.0005, loss_t=0.0467, loss_r=0.0194, loss=0.0071, norm_factor=402.1729, grad_norm=1.8358\n",
      "Epoch 5: 170/256 - loss_mc=-0.0009, loss_t=0.0408, loss_r=0.0144, loss=0.0046, norm_factor=401.8797, grad_norm=2.3360\n",
      "Epoch 5: 171/256 - loss_mc=-0.0016, loss_t=0.0440, loss_r=0.0137, loss=0.0042, norm_factor=401.5898, grad_norm=2.1312\n",
      "Epoch 5: 172/256 - loss_mc=-0.0016, loss_t=0.0339, loss_r=0.0144, loss=0.0032, norm_factor=401.3207, grad_norm=1.6327\n",
      "Epoch 5: 173/256 - loss_mc=-0.0001, loss_t=0.0395, loss_r=0.0169, loss=0.0056, norm_factor=401.0637, grad_norm=3.0333\n",
      "Epoch 5: 174/256 - loss_mc=-0.0002, loss_t=0.0425, loss_r=0.0145, loss=0.0055, norm_factor=400.7943, grad_norm=1.6472\n",
      "Epoch 5: 175/256 - loss_mc=0.0002, loss_t=0.0417, loss_r=0.0178, loss=0.0062, norm_factor=400.5103, grad_norm=2.2392\n",
      "Epoch 5: 176/256 - loss_mc=-0.0014, loss_t=0.0322, loss_r=0.0208, loss=0.0039, norm_factor=400.2073, grad_norm=1.5943\n",
      "Epoch 5: 177/256 - loss_mc=-0.0017, loss_t=0.0284, loss_r=0.0123, loss=0.0024, norm_factor=399.9157, grad_norm=1.6413\n",
      "Epoch 5: 178/256 - loss_mc=-0.0015, loss_t=0.0322, loss_r=0.0192, loss=0.0036, norm_factor=399.6422, grad_norm=1.5850\n",
      "Epoch 5: 179/256 - loss_mc=-0.0003, loss_t=0.0305, loss_r=0.0184, loss=0.0046, norm_factor=399.3804, grad_norm=2.0316\n",
      "Epoch 5: 180/256 - loss_mc=-0.0021, loss_t=0.0332, loss_r=0.0123, loss=0.0024, norm_factor=399.1075, grad_norm=1.4202\n",
      "Epoch 5: 181/256 - loss_mc=-0.0017, loss_t=0.0279, loss_r=0.0164, loss=0.0028, norm_factor=398.8672, grad_norm=1.3178\n",
      "Epoch 5: 182/256 - loss_mc=-0.0013, loss_t=0.0341, loss_r=0.0136, loss=0.0034, norm_factor=398.6422, grad_norm=1.7215\n",
      "Epoch 5: 183/256 - loss_mc=-0.0028, loss_t=0.0318, loss_r=0.0127, loss=0.0016, norm_factor=398.4242, grad_norm=1.8308\n",
      "Epoch 5: 184/256 - loss_mc=-0.0022, loss_t=0.0270, loss_r=0.0122, loss=0.0017, norm_factor=398.2450, grad_norm=1.5892\n",
      "Epoch 5: 185/256 - loss_mc=-0.0020, loss_t=0.0333, loss_r=0.0141, loss=0.0028, norm_factor=398.0873, grad_norm=2.0731\n",
      "Epoch 5: 186/256 - loss_mc=-0.0029, loss_t=0.0290, loss_r=0.0121, loss=0.0012, norm_factor=397.9421, grad_norm=1.4235\n",
      "Epoch 5: 187/256 - loss_mc=-0.0027, loss_t=0.0260, loss_r=0.0120, loss=0.0011, norm_factor=397.8279, grad_norm=2.0080\n",
      "Epoch 5: 188/256 - loss_mc=-0.0030, loss_t=0.0349, loss_r=0.0102, loss=0.0015, norm_factor=397.7371, grad_norm=1.8761\n",
      "Epoch 5: 189/256 - loss_mc=-0.0017, loss_t=0.0300, loss_r=0.0127, loss=0.0026, norm_factor=397.6714, grad_norm=1.5851\n",
      "Epoch 5: 190/256 - loss_mc=-0.0029, loss_t=0.0281, loss_r=0.0128, loss=0.0012, norm_factor=397.6068, grad_norm=2.0233\n",
      "Epoch 5: 191/256 - loss_mc=-0.0036, loss_t=0.0224, loss_r=0.0104, loss=-0.0003, norm_factor=397.5677, grad_norm=1.6623\n",
      "Epoch 5: 192/256 - loss_mc=-0.0030, loss_t=0.0234, loss_r=0.0099, loss=0.0004, norm_factor=397.5613, grad_norm=2.2023\n",
      "Epoch 5: 193/256 - loss_mc=-0.0037, loss_t=0.0237, loss_r=0.0091, loss=-0.0005, norm_factor=397.5764, grad_norm=1.9003\n",
      "Epoch 5: 194/256 - loss_mc=-0.0041, loss_t=0.0252, loss_r=0.0090, loss=-0.0007, norm_factor=397.6284, grad_norm=1.6692\n",
      "Epoch 5: 195/256 - loss_mc=-0.0013, loss_t=0.0285, loss_r=0.0148, loss=0.0031, norm_factor=397.7178, grad_norm=1.8257\n",
      "Epoch 5: 196/256 - loss_mc=-0.0020, loss_t=0.0285, loss_r=0.0124, loss=0.0021, norm_factor=397.7766, grad_norm=1.8155\n",
      "Epoch 5: 197/256 - loss_mc=-0.0034, loss_t=0.0240, loss_r=0.0110, loss=0.0001, norm_factor=397.8314, grad_norm=2.0858\n",
      "Epoch 5: 198/256 - loss_mc=-0.0025, loss_t=0.0442, loss_r=0.0098, loss=0.0029, norm_factor=397.9070, grad_norm=1.9117\n",
      "Epoch 5: 199/256 - loss_mc=-0.0039, loss_t=0.0223, loss_r=0.0095, loss=-0.0007, norm_factor=397.9864, grad_norm=2.1320\n",
      "Epoch 5: 200/256 - loss_mc=-0.0039, loss_t=0.0266, loss_r=0.0104, loss=-0.0002, norm_factor=398.0974, grad_norm=1.4600\n",
      "Epoch 5: 201/256 - loss_mc=-0.0040, loss_t=0.0244, loss_r=0.0106, loss=-0.0005, norm_factor=398.2346, grad_norm=2.1391\n",
      "Epoch 5: 202/256 - loss_mc=-0.0043, loss_t=0.0243, loss_r=0.0096, loss=-0.0009, norm_factor=398.4044, grad_norm=1.4757\n",
      "Epoch 5: 203/256 - loss_mc=-0.0037, loss_t=0.0203, loss_r=0.0092, loss=-0.0008, norm_factor=398.6084, grad_norm=1.7778\n",
      "Epoch 5: 204/256 - loss_mc=-0.0036, loss_t=0.0265, loss_r=0.0102, loss=0.0001, norm_factor=398.8319, grad_norm=2.4546\n",
      "Epoch 5: 205/256 - loss_mc=-0.0038, loss_t=0.0230, loss_r=0.0099, loss=-0.0005, norm_factor=399.0683, grad_norm=1.7343\n",
      "Epoch 5: 206/256 - loss_mc=-0.0026, loss_t=0.0259, loss_r=0.0090, loss=0.0009, norm_factor=399.3202, grad_norm=2.0208\n",
      "Epoch 5: 207/256 - loss_mc=-0.0041, loss_t=0.0211, loss_r=0.0102, loss=-0.0009, norm_factor=399.5657, grad_norm=1.2059\n",
      "Epoch 5: 208/256 - loss_mc=-0.0050, loss_t=0.0180, loss_r=0.0083, loss=-0.0024, norm_factor=399.8317, grad_norm=1.4219\n",
      "Epoch 5: 209/256 - loss_mc=-0.0043, loss_t=0.0199, loss_r=0.0094, loss=-0.0014, norm_factor=400.1387, grad_norm=1.2472\n",
      "Epoch 5: 210/256 - loss_mc=-0.0047, loss_t=0.0188, loss_r=0.0082, loss=-0.0020, norm_factor=400.4656, grad_norm=1.6018\n",
      "Epoch 5: 211/256 - loss_mc=-0.0047, loss_t=0.0223, loss_r=0.0088, loss=-0.0016, norm_factor=400.8174, grad_norm=0.9735\n",
      "Epoch 5: 212/256 - loss_mc=-0.0049, loss_t=0.0208, loss_r=0.0077, loss=-0.0020, norm_factor=401.1872, grad_norm=1.4822\n",
      "Epoch 5: 213/256 - loss_mc=-0.0044, loss_t=0.0226, loss_r=0.0112, loss=-0.0010, norm_factor=401.5821, grad_norm=1.0444\n",
      "Epoch 5: 214/256 - loss_mc=-0.0023, loss_t=0.0265, loss_r=0.0107, loss=0.0015, norm_factor=401.9878, grad_norm=1.1246\n",
      "Epoch 5: 215/256 - loss_mc=-0.0055, loss_t=0.0223, loss_r=0.0067, loss=-0.0026, norm_factor=402.3591, grad_norm=1.4962\n",
      "Epoch 5: 216/256 - loss_mc=-0.0046, loss_t=0.0270, loss_r=0.0077, loss=-0.0011, norm_factor=402.7779, grad_norm=1.3962\n",
      "Epoch 5: 217/256 - loss_mc=-0.0049, loss_t=0.0198, loss_r=0.0090, loss=-0.0020, norm_factor=403.2066, grad_norm=1.3744\n",
      "Epoch 5: 218/256 - loss_mc=-0.0046, loss_t=0.0218, loss_r=0.0093, loss=-0.0014, norm_factor=403.6562, grad_norm=1.9704\n",
      "Epoch 5: 219/256 - loss_mc=-0.0045, loss_t=0.0206, loss_r=0.0081, loss=-0.0016, norm_factor=404.1190, grad_norm=1.0948\n",
      "Epoch 5: 220/256 - loss_mc=-0.0033, loss_t=0.0191, loss_r=0.0100, loss=-0.0004, norm_factor=404.5865, grad_norm=1.2987\n",
      "Epoch 5: 221/256 - loss_mc=-0.0049, loss_t=0.0202, loss_r=0.0084, loss=-0.0020, norm_factor=405.0380, grad_norm=1.5298\n",
      "Epoch 5: 222/256 - loss_mc=-0.0033, loss_t=0.0235, loss_r=0.0098, loss=0.0000, norm_factor=405.5113, grad_norm=1.3539\n",
      "Epoch 5: 223/256 - loss_mc=-0.0050, loss_t=0.0187, loss_r=0.0087, loss=-0.0023, norm_factor=405.9669, grad_norm=0.8272\n",
      "Epoch 5: 224/256 - loss_mc=-0.0044, loss_t=0.0215, loss_r=0.0086, loss=-0.0013, norm_factor=406.4434, grad_norm=1.5417\n",
      "Epoch 5: 225/256 - loss_mc=-0.0049, loss_t=0.0233, loss_r=0.0087, loss=-0.0017, norm_factor=406.9227, grad_norm=1.3562\n",
      "Epoch 5: 226/256 - loss_mc=-0.0052, loss_t=0.0180, loss_r=0.0086, loss=-0.0025, norm_factor=407.4168, grad_norm=0.7224\n",
      "Epoch 5: 227/256 - loss_mc=-0.0046, loss_t=0.0196, loss_r=0.0078, loss=-0.0019, norm_factor=407.9366, grad_norm=1.5617\n",
      "Epoch 5: 228/256 - loss_mc=-0.0043, loss_t=0.0214, loss_r=0.0099, loss=-0.0012, norm_factor=408.4579, grad_norm=1.1808\n",
      "Epoch 5: 229/256 - loss_mc=-0.0044, loss_t=0.0185, loss_r=0.0076, loss=-0.0018, norm_factor=408.9708, grad_norm=0.8268\n",
      "Epoch 5: 230/256 - loss_mc=-0.0032, loss_t=0.0316, loss_r=0.0086, loss=0.0008, norm_factor=409.4825, grad_norm=2.4887\n",
      "Epoch 5: 231/256 - loss_mc=-0.0031, loss_t=0.0260, loss_r=0.0087, loss=0.0004, norm_factor=409.9597, grad_norm=1.5888\n",
      "Epoch 5: 232/256 - loss_mc=-0.0040, loss_t=0.0275, loss_r=0.0087, loss=-0.0004, norm_factor=410.4095, grad_norm=1.8312\n",
      "Epoch 5: 233/256 - loss_mc=-0.0047, loss_t=0.0256, loss_r=0.0078, loss=-0.0013, norm_factor=410.8573, grad_norm=1.5415\n",
      "Epoch 5: 234/256 - loss_mc=-0.0041, loss_t=0.0275, loss_r=0.0096, loss=-0.0004, norm_factor=411.3173, grad_norm=1.2192\n",
      "Epoch 5: 235/256 - loss_mc=-0.0034, loss_t=0.0201, loss_r=0.0122, loss=-0.0001, norm_factor=411.7784, grad_norm=1.1650\n",
      "Epoch 5: 236/256 - loss_mc=-0.0037, loss_t=0.0333, loss_r=0.0083, loss=0.0004, norm_factor=412.2184, grad_norm=1.7067\n",
      "Epoch 5: 237/256 - loss_mc=-0.0059, loss_t=0.0168, loss_r=0.0072, loss=-0.0035, norm_factor=412.6479, grad_norm=1.0322\n",
      "Epoch 5: 238/256 - loss_mc=-0.0016, loss_t=0.0238, loss_r=0.0080, loss=0.0016, norm_factor=413.1122, grad_norm=1.7804\n",
      "Epoch 5: 239/256 - loss_mc=-0.0044, loss_t=0.0210, loss_r=0.0076, loss=-0.0016, norm_factor=413.5063, grad_norm=1.8038\n",
      "Epoch 5: 240/256 - loss_mc=-0.0052, loss_t=0.0184, loss_r=0.0092, loss=-0.0025, norm_factor=413.9080, grad_norm=0.7388\n",
      "Epoch 5: 241/256 - loss_mc=-0.0038, loss_t=0.0245, loss_r=0.0083, loss=-0.0006, norm_factor=414.3384, grad_norm=1.7763\n",
      "Epoch 5: 242/256 - loss_mc=-0.0052, loss_t=0.0207, loss_r=0.0086, loss=-0.0023, norm_factor=414.7610, grad_norm=1.5414\n",
      "Epoch 5: 243/256 - loss_mc=-0.0041, loss_t=0.0219, loss_r=0.0102, loss=-0.0009, norm_factor=415.2057, grad_norm=1.2521\n",
      "Epoch 5: 244/256 - loss_mc=-0.0040, loss_t=0.0174, loss_r=0.0096, loss=-0.0013, norm_factor=415.6435, grad_norm=1.9195\n",
      "Epoch 5: 245/256 - loss_mc=-0.0043, loss_t=0.0268, loss_r=0.0101, loss=-0.0006, norm_factor=416.0747, grad_norm=1.9486\n",
      "Epoch 5: 246/256 - loss_mc=-0.0057, loss_t=0.0209, loss_r=0.0069, loss=-0.0030, norm_factor=416.5018, grad_norm=1.0330\n",
      "Epoch 5: 247/256 - loss_mc=-0.0039, loss_t=0.0185, loss_r=0.0097, loss=-0.0011, norm_factor=416.9597, grad_norm=0.8310\n",
      "Epoch 5: 248/256 - loss_mc=-0.0048, loss_t=0.0212, loss_r=0.0083, loss=-0.0018, norm_factor=417.4045, grad_norm=1.4981\n",
      "Epoch 5: 249/256 - loss_mc=-0.0043, loss_t=0.0202, loss_r=0.0098, loss=-0.0013, norm_factor=417.8589, grad_norm=1.1254\n",
      "Epoch 5: 250/256 - loss_mc=-0.0047, loss_t=0.0217, loss_r=0.0083, loss=-0.0017, norm_factor=418.3096, grad_norm=0.7664\n",
      "Epoch 5: 251/256 - loss_mc=-0.0042, loss_t=0.0215, loss_r=0.0081, loss=-0.0013, norm_factor=418.7708, grad_norm=1.3013\n",
      "Epoch 5: 252/256 - loss_mc=-0.0048, loss_t=0.0230, loss_r=0.0084, loss=-0.0017, norm_factor=419.2285, grad_norm=1.8150\n",
      "Epoch 5: 253/256 - loss_mc=-0.0047, loss_t=0.0196, loss_r=0.0080, loss=-0.0019, norm_factor=419.7039, grad_norm=1.5055\n",
      "Epoch 5: 254/256 - loss_mc=-0.0040, loss_t=0.0194, loss_r=0.0107, loss=-0.0010, norm_factor=420.1823, grad_norm=1.7943\n",
      "Epoch 5: 255/256 - loss_mc=-0.0044, loss_t=0.0209, loss_r=0.0084, loss=-0.0015, norm_factor=420.6456, grad_norm=1.4922\n",
      "Epoch 5: 256/256 - loss_mc=-0.0051, loss_t=0.0201, loss_r=0.0082, loss=-0.0023, norm_factor=421.1108, grad_norm=1.0034\n",
      "Epoch 6: 1/256 - loss_mc=-0.0052, loss_t=0.0201, loss_r=0.0091, loss=-0.0023, norm_factor=421.5834, grad_norm=1.3002\n",
      "Epoch 6: 2/256 - loss_mc=-0.0048, loss_t=0.1670, loss_r=0.0127, loss=0.0131, norm_factor=422.0696, grad_norm=3.5371\n",
      "Epoch 6: 3/256 - loss_mc=-0.0044, loss_t=0.0177, loss_r=0.0077, loss=-0.0019, norm_factor=422.6857, grad_norm=1.6101\n",
      "Epoch 6: 4/256 - loss_mc=-0.0036, loss_t=0.0336, loss_r=0.0106, loss=0.0009, norm_factor=423.2935, grad_norm=3.0404\n",
      "Epoch 6: 5/256 - loss_mc=-0.0013, loss_t=0.0263, loss_r=0.0160, loss=0.0029, norm_factor=423.8745, grad_norm=2.0678\n",
      "Epoch 6: 6/256 - loss_mc=-0.0024, loss_t=0.0315, loss_r=0.0121, loss=0.0020, norm_factor=424.3733, grad_norm=3.5741\n",
      "Epoch 6: 7/256 - loss_mc=-0.0030, loss_t=0.0282, loss_r=0.0146, loss=0.0013, norm_factor=424.8193, grad_norm=1.1830\n",
      "Epoch 6: 8/256 - loss_mc=-0.0036, loss_t=0.0241, loss_r=0.0129, loss=0.0001, norm_factor=425.2241, grad_norm=2.3884\n",
      "Epoch 6: 9/256 - loss_mc=-0.0030, loss_t=0.0348, loss_r=0.0112, loss=0.0016, norm_factor=425.6036, grad_norm=1.5201\n",
      "Epoch 6: 10/256 - loss_mc=-0.0025, loss_t=0.0298, loss_r=0.0138, loss=0.0019, norm_factor=425.9482, grad_norm=1.3386\n",
      "Epoch 6: 11/256 - loss_mc=-0.0022, loss_t=0.0234, loss_r=0.0165, loss=0.0018, norm_factor=426.2520, grad_norm=1.7933\n",
      "Epoch 6: 12/256 - loss_mc=-0.0035, loss_t=0.0291, loss_r=0.0099, loss=0.0004, norm_factor=426.5108, grad_norm=1.7866\n",
      "Epoch 6: 13/256 - loss_mc=-0.0039, loss_t=0.0272, loss_r=0.0119, loss=0.0001, norm_factor=426.7650, grad_norm=1.5488\n",
      "Epoch 6: 14/256 - loss_mc=-0.0029, loss_t=0.0277, loss_r=0.0157, loss=0.0015, norm_factor=427.0264, grad_norm=1.8193\n",
      "Epoch 6: 15/256 - loss_mc=-0.0038, loss_t=0.0237, loss_r=0.0108, loss=-0.0004, norm_factor=427.2752, grad_norm=1.9165\n",
      "Epoch 6: 16/256 - loss_mc=-0.0043, loss_t=0.0222, loss_r=0.0109, loss=-0.0010, norm_factor=427.5239, grad_norm=1.3329\n",
      "Epoch 6: 17/256 - loss_mc=-0.0040, loss_t=0.0226, loss_r=0.0090, loss=-0.0009, norm_factor=427.7885, grad_norm=2.4190\n",
      "Epoch 6: 18/256 - loss_mc=-0.0013, loss_t=0.0291, loss_r=0.0121, loss=0.0028, norm_factor=428.0527, grad_norm=1.7523\n",
      "Epoch 6: 19/256 - loss_mc=-0.0048, loss_t=0.0246, loss_r=0.0083, loss=-0.0015, norm_factor=428.2515, grad_norm=1.8844\n",
      "Epoch 6: 20/256 - loss_mc=-0.0046, loss_t=0.0238, loss_r=0.0092, loss=-0.0013, norm_factor=428.4777, grad_norm=2.0370\n",
      "Epoch 6: 21/256 - loss_mc=-0.0030, loss_t=0.0265, loss_r=0.0116, loss=0.0009, norm_factor=428.7126, grad_norm=1.5834\n",
      "Epoch 6: 22/256 - loss_mc=-0.0047, loss_t=0.0182, loss_r=0.0084, loss=-0.0021, norm_factor=428.9326, grad_norm=1.4836\n",
      "Epoch 6: 23/256 - loss_mc=-0.0043, loss_t=0.0216, loss_r=0.0116, loss=-0.0010, norm_factor=429.1815, grad_norm=2.0425\n",
      "Epoch 6: 24/256 - loss_mc=-0.0032, loss_t=0.0232, loss_r=0.0118, loss=0.0003, norm_factor=429.4469, grad_norm=1.4153\n",
      "Epoch 6: 25/256 - loss_mc=-0.0027, loss_t=0.0238, loss_r=0.0147, loss=0.0011, norm_factor=429.6975, grad_norm=1.4572\n",
      "Epoch 6: 26/256 - loss_mc=-0.0047, loss_t=0.0239, loss_r=0.0084, loss=-0.0015, norm_factor=429.9251, grad_norm=1.7750\n",
      "Epoch 6: 27/256 - loss_mc=-0.0038, loss_t=0.0334, loss_r=0.0079, loss=0.0003, norm_factor=430.1682, grad_norm=1.3675\n",
      "Epoch 6: 28/256 - loss_mc=-0.0049, loss_t=0.0272, loss_r=0.0080, loss=-0.0014, norm_factor=430.4023, grad_norm=1.5289\n",
      "Epoch 6: 29/256 - loss_mc=-0.0017, loss_t=0.0262, loss_r=0.0100, loss=0.0019, norm_factor=430.6617, grad_norm=1.7730\n",
      "Epoch 6: 30/256 - loss_mc=-0.0050, loss_t=0.0266, loss_r=0.0080, loss=-0.0015, norm_factor=430.8631, grad_norm=1.5962\n",
      "Epoch 6: 31/256 - loss_mc=-0.0053, loss_t=0.0190, loss_r=0.0084, loss=-0.0025, norm_factor=431.0990, grad_norm=0.9993\n",
      "Epoch 6: 32/256 - loss_mc=-0.0037, loss_t=0.0307, loss_r=0.0097, loss=0.0004, norm_factor=431.3754, grad_norm=1.6539\n",
      "Epoch 6: 33/256 - loss_mc=-0.0036, loss_t=0.0261, loss_r=0.0095, loss=-0.0001, norm_factor=431.6450, grad_norm=1.8491\n",
      "Epoch 6: 34/256 - loss_mc=-0.0055, loss_t=0.0180, loss_r=0.0083, loss=-0.0029, norm_factor=431.9080, grad_norm=1.9303\n",
      "Epoch 6: 35/256 - loss_mc=-0.0043, loss_t=0.0236, loss_r=0.0093, loss=-0.0010, norm_factor=432.2112, grad_norm=1.5095\n",
      "Epoch 6: 36/256 - loss_mc=-0.0055, loss_t=0.0196, loss_r=0.0068, loss=-0.0029, norm_factor=432.5212, grad_norm=1.3431\n",
      "Epoch 6: 37/256 - loss_mc=-0.0054, loss_t=0.0217, loss_r=0.0068, loss=-0.0025, norm_factor=432.8645, grad_norm=2.1088\n",
      "Epoch 6: 38/256 - loss_mc=-0.0057, loss_t=0.0170, loss_r=0.0075, loss=-0.0032, norm_factor=433.2358, grad_norm=1.0356\n",
      "Epoch 6: 39/256 - loss_mc=-0.0052, loss_t=0.0219, loss_r=0.0074, loss=-0.0023, norm_factor=433.6367, grad_norm=1.3394\n",
      "Epoch 6: 40/256 - loss_mc=-0.0053, loss_t=0.0201, loss_r=0.0097, loss=-0.0023, norm_factor=434.0590, grad_norm=1.1590\n",
      "Epoch 6: 41/256 - loss_mc=-0.0057, loss_t=0.0207, loss_r=0.0073, loss=-0.0029, norm_factor=434.4941, grad_norm=1.3296\n",
      "Epoch 6: 42/256 - loss_mc=-0.0049, loss_t=0.0154, loss_r=0.0104, loss=-0.0023, norm_factor=434.9498, grad_norm=0.9712\n",
      "Epoch 6: 43/256 - loss_mc=-0.0053, loss_t=0.0204, loss_r=0.0083, loss=-0.0024, norm_factor=435.4093, grad_norm=1.3247\n",
      "Epoch 6: 44/256 - loss_mc=-0.0054, loss_t=0.0228, loss_r=0.0084, loss=-0.0023, norm_factor=435.8851, grad_norm=1.6069\n",
      "Epoch 6: 45/256 - loss_mc=-0.0054, loss_t=0.0178, loss_r=0.0069, loss=-0.0029, norm_factor=436.3777, grad_norm=1.1985\n",
      "Epoch 6: 46/256 - loss_mc=-0.0056, loss_t=0.0174, loss_r=0.0113, loss=-0.0027, norm_factor=436.8818, grad_norm=1.3403\n",
      "Epoch 6: 47/256 - loss_mc=-0.0055, loss_t=0.0173, loss_r=0.0086, loss=-0.0029, norm_factor=437.4035, grad_norm=1.1617\n",
      "Epoch 6: 48/256 - loss_mc=-0.0053, loss_t=0.0191, loss_r=0.0087, loss=-0.0025, norm_factor=437.9381, grad_norm=1.3695\n",
      "Epoch 6: 49/256 - loss_mc=-0.0052, loss_t=0.0188, loss_r=0.0070, loss=-0.0026, norm_factor=438.4764, grad_norm=0.6372\n",
      "Epoch 6: 50/256 - loss_mc=-0.0053, loss_t=0.0181, loss_r=0.0077, loss=-0.0027, norm_factor=439.0166, grad_norm=1.4488\n",
      "Epoch 6: 51/256 - loss_mc=-0.0059, loss_t=0.0189, loss_r=0.0072, loss=-0.0033, norm_factor=439.5554, grad_norm=1.2051\n",
      "Epoch 6: 52/256 - loss_mc=-0.0055, loss_t=0.0177, loss_r=0.0069, loss=-0.0031, norm_factor=440.1121, grad_norm=0.8955\n",
      "Epoch 6: 53/256 - loss_mc=-0.0060, loss_t=0.0156, loss_r=0.0077, loss=-0.0037, norm_factor=440.6758, grad_norm=0.9832\n",
      "Epoch 6: 54/256 - loss_mc=-0.0049, loss_t=0.0208, loss_r=0.0093, loss=-0.0019, norm_factor=441.2602, grad_norm=1.8069\n",
      "Epoch 6: 55/256 - loss_mc=-0.0053, loss_t=0.0170, loss_r=0.0087, loss=-0.0027, norm_factor=441.8404, grad_norm=0.8630\n",
      "Epoch 6: 56/256 - loss_mc=-0.0045, loss_t=0.0177, loss_r=0.0077, loss=-0.0019, norm_factor=442.4212, grad_norm=1.1212\n",
      "Epoch 6: 57/256 - loss_mc=-0.0059, loss_t=0.0187, loss_r=0.0071, loss=-0.0033, norm_factor=442.9752, grad_norm=1.1716\n",
      "Epoch 6: 58/256 - loss_mc=-0.0055, loss_t=0.0210, loss_r=0.0073, loss=-0.0026, norm_factor=443.5459, grad_norm=1.8748\n",
      "Epoch 6: 59/256 - loss_mc=-0.0054, loss_t=0.0233, loss_r=0.0075, loss=-0.0023, norm_factor=444.1236, grad_norm=1.2148\n",
      "Epoch 6: 60/256 - loss_mc=-0.0053, loss_t=0.0218, loss_r=0.0078, loss=-0.0023, norm_factor=444.6988, grad_norm=1.5848\n",
      "Epoch 6: 61/256 - loss_mc=-0.0043, loss_t=0.0252, loss_r=0.0119, loss=-0.0006, norm_factor=445.2626, grad_norm=1.6651\n",
      "Epoch 6: 62/256 - loss_mc=-0.0052, loss_t=0.0217, loss_r=0.0075, loss=-0.0022, norm_factor=445.7910, grad_norm=1.1330\n",
      "Epoch 6: 63/256 - loss_mc=-0.0054, loss_t=0.0224, loss_r=0.0082, loss=-0.0023, norm_factor=446.3152, grad_norm=1.7683\n",
      "Epoch 6: 64/256 - loss_mc=-0.0053, loss_t=0.0174, loss_r=0.0080, loss=-0.0027, norm_factor=446.8496, grad_norm=1.3858\n",
      "Epoch 6: 65/256 - loss_mc=-0.0061, loss_t=0.0180, loss_r=0.0077, loss=-0.0035, norm_factor=447.3796, grad_norm=1.4863\n",
      "Epoch 6: 66/256 - loss_mc=-0.0054, loss_t=0.0237, loss_r=0.0072, loss=-0.0023, norm_factor=447.9313, grad_norm=2.0691\n",
      "Epoch 6: 67/256 - loss_mc=-0.0056, loss_t=0.0176, loss_r=0.0071, loss=-0.0031, norm_factor=448.4764, grad_norm=0.8874\n",
      "Epoch 6: 68/256 - loss_mc=-0.0056, loss_t=0.0189, loss_r=0.0076, loss=-0.0029, norm_factor=449.0232, grad_norm=1.8805\n",
      "Epoch 6: 69/256 - loss_mc=-0.0063, loss_t=0.0139, loss_r=0.0066, loss=-0.0043, norm_factor=449.5714, grad_norm=1.4918\n",
      "Epoch 6: 70/256 - loss_mc=-0.0048, loss_t=0.0151, loss_r=0.0093, loss=-0.0024, norm_factor=450.1466, grad_norm=0.6952\n",
      "Epoch 6: 71/256 - loss_mc=-0.0052, loss_t=0.0195, loss_r=0.0081, loss=-0.0024, norm_factor=450.7047, grad_norm=1.6945\n",
      "Epoch 6: 72/256 - loss_mc=-0.0057, loss_t=0.0179, loss_r=0.0065, loss=-0.0033, norm_factor=451.2598, grad_norm=1.2015\n",
      "Epoch 6: 73/256 - loss_mc=-0.0058, loss_t=0.0179, loss_r=0.0070, loss=-0.0033, norm_factor=451.8212, grad_norm=1.3439\n",
      "Epoch 6: 74/256 - loss_mc=-0.0062, loss_t=0.0182, loss_r=0.0072, loss=-0.0036, norm_factor=452.3940, grad_norm=1.0133\n",
      "Epoch 6: 75/256 - loss_mc=-0.0047, loss_t=0.0212, loss_r=0.0081, loss=-0.0018, norm_factor=452.9855, grad_norm=1.1899\n",
      "Epoch 6: 76/256 - loss_mc=-0.0055, loss_t=0.0195, loss_r=0.0073, loss=-0.0028, norm_factor=453.5592, grad_norm=0.9659\n",
      "Epoch 6: 77/256 - loss_mc=-0.0038, loss_t=0.0167, loss_r=0.0101, loss=-0.0011, norm_factor=454.1270, grad_norm=1.2199\n",
      "Epoch 6: 78/256 - loss_mc=-0.0047, loss_t=0.0219, loss_r=0.0085, loss=-0.0016, norm_factor=454.6460, grad_norm=1.5166\n",
      "Epoch 6: 79/256 - loss_mc=-0.0062, loss_t=0.0155, loss_r=0.0060, loss=-0.0040, norm_factor=455.1521, grad_norm=0.6889\n",
      "Epoch 6: 80/256 - loss_mc=-0.0055, loss_t=0.0161, loss_r=0.0071, loss=-0.0032, norm_factor=455.6783, grad_norm=1.0648\n",
      "Epoch 6: 81/256 - loss_mc=-0.0052, loss_t=0.0181, loss_r=0.0098, loss=-0.0024, norm_factor=456.2056, grad_norm=1.1127\n",
      "Epoch 6: 82/256 - loss_mc=-0.0054, loss_t=0.0225, loss_r=0.0129, loss=-0.0019, norm_factor=456.7281, grad_norm=1.6670\n",
      "Epoch 6: 83/256 - loss_mc=-0.0058, loss_t=0.0175, loss_r=0.0062, loss=-0.0034, norm_factor=457.2476, grad_norm=1.1596\n",
      "Epoch 6: 84/256 - loss_mc=-0.0065, loss_t=0.0130, loss_r=0.0061, loss=-0.0046, norm_factor=457.7776, grad_norm=1.1500\n",
      "Epoch 6: 85/256 - loss_mc=-0.0057, loss_t=0.0169, loss_r=0.0067, loss=-0.0033, norm_factor=458.3402, grad_norm=1.5353\n",
      "Epoch 6: 86/256 - loss_mc=-0.0058, loss_t=0.0187, loss_r=0.0071, loss=-0.0032, norm_factor=458.9073, grad_norm=1.2053\n",
      "Epoch 6: 87/256 - loss_mc=-0.0045, loss_t=0.0218, loss_r=0.0078, loss=-0.0015, norm_factor=459.4767, grad_norm=1.8433\n",
      "Epoch 6: 88/256 - loss_mc=-0.0059, loss_t=0.0192, loss_r=0.0075, loss=-0.0033, norm_factor=460.0137, grad_norm=1.6982\n",
      "Epoch 6: 89/256 - loss_mc=-0.0058, loss_t=0.0185, loss_r=0.0068, loss=-0.0032, norm_factor=460.5637, grad_norm=1.8162\n",
      "Epoch 6: 90/256 - loss_mc=-0.0057, loss_t=0.0206, loss_r=0.0071, loss=-0.0029, norm_factor=461.1202, grad_norm=1.6280\n",
      "Epoch 6: 91/256 - loss_mc=-0.0059, loss_t=0.0159, loss_r=0.0070, loss=-0.0036, norm_factor=461.6762, grad_norm=1.7002\n",
      "Epoch 6: 92/256 - loss_mc=-0.0058, loss_t=0.0154, loss_r=0.0064, loss=-0.0037, norm_factor=462.2453, grad_norm=1.9892\n",
      "Epoch 6: 93/256 - loss_mc=-0.0061, loss_t=0.0131, loss_r=0.0062, loss=-0.0042, norm_factor=462.8267, grad_norm=1.0411\n",
      "Epoch 6: 94/256 - loss_mc=-0.0058, loss_t=0.0177, loss_r=0.0069, loss=-0.0034, norm_factor=463.4246, grad_norm=1.4929\n",
      "Epoch 6: 95/256 - loss_mc=-0.0062, loss_t=0.0158, loss_r=0.0063, loss=-0.0040, norm_factor=464.0236, grad_norm=1.0694\n",
      "Epoch 6: 96/256 - loss_mc=-0.0059, loss_t=0.0200, loss_r=0.0071, loss=-0.0032, norm_factor=464.6353, grad_norm=1.2212\n",
      "Epoch 6: 97/256 - loss_mc=-0.0061, loss_t=0.0182, loss_r=0.0063, loss=-0.0037, norm_factor=465.2455, grad_norm=1.6863\n",
      "Epoch 6: 98/256 - loss_mc=-0.0049, loss_t=0.0242, loss_r=0.0079, loss=-0.0017, norm_factor=465.8659, grad_norm=1.7973\n",
      "Epoch 6: 99/256 - loss_mc=-0.0062, loss_t=0.0185, loss_r=0.0066, loss=-0.0037, norm_factor=466.4611, grad_norm=1.9974\n",
      "Epoch 6: 100/256 - loss_mc=-0.0059, loss_t=0.0208, loss_r=0.0069, loss=-0.0031, norm_factor=467.0706, grad_norm=1.3685\n",
      "Epoch 6: 101/256 - loss_mc=-0.0060, loss_t=0.0160, loss_r=0.0064, loss=-0.0038, norm_factor=467.6823, grad_norm=1.3905\n",
      "Epoch 6: 102/256 - loss_mc=-0.0062, loss_t=0.0170, loss_r=0.0066, loss=-0.0039, norm_factor=468.3048, grad_norm=1.6366\n",
      "Epoch 6: 103/256 - loss_mc=-0.0057, loss_t=0.0156, loss_r=0.0066, loss=-0.0034, norm_factor=468.9387, grad_norm=1.0537\n",
      "Epoch 6: 104/256 - loss_mc=-0.0061, loss_t=0.0143, loss_r=0.0056, loss=-0.0041, norm_factor=469.5670, grad_norm=1.5773\n",
      "Epoch 6: 105/256 - loss_mc=-0.0059, loss_t=0.0167, loss_r=0.0059, loss=-0.0037, norm_factor=470.2079, grad_norm=0.9200\n",
      "Epoch 6: 106/256 - loss_mc=-0.0064, loss_t=0.0225, loss_r=0.0069, loss=-0.0034, norm_factor=470.8490, grad_norm=1.1796\n",
      "Epoch 6: 107/256 - loss_mc=-0.0060, loss_t=0.0179, loss_r=0.0066, loss=-0.0035, norm_factor=471.4995, grad_norm=1.2438\n",
      "Epoch 6: 108/256 - loss_mc=-0.0057, loss_t=0.0201, loss_r=0.0072, loss=-0.0030, norm_factor=472.1498, grad_norm=1.3996\n",
      "Epoch 6: 109/256 - loss_mc=-0.0058, loss_t=0.0160, loss_r=0.0070, loss=-0.0035, norm_factor=472.7929, grad_norm=0.7597\n",
      "Epoch 6: 110/256 - loss_mc=-0.0053, loss_t=0.0135, loss_r=0.0076, loss=-0.0032, norm_factor=473.4289, grad_norm=1.5469\n",
      "Epoch 6: 111/256 - loss_mc=-0.0058, loss_t=0.0188, loss_r=0.0071, loss=-0.0032, norm_factor=474.0422, grad_norm=1.1917\n",
      "Epoch 6: 112/256 - loss_mc=-0.0054, loss_t=0.0146, loss_r=0.0071, loss=-0.0032, norm_factor=474.6527, grad_norm=1.2598\n",
      "Epoch 6: 113/256 - loss_mc=-0.0060, loss_t=0.0184, loss_r=0.0067, loss=-0.0035, norm_factor=475.2493, grad_norm=1.4086\n",
      "Epoch 6: 114/256 - loss_mc=-0.0048, loss_t=0.0169, loss_r=0.0144, loss=-0.0016, norm_factor=475.8515, grad_norm=1.0904\n",
      "Epoch 6: 115/256 - loss_mc=-0.0057, loss_t=0.0163, loss_r=0.0061, loss=-0.0034, norm_factor=476.4217, grad_norm=1.7754\n",
      "Epoch 6: 116/256 - loss_mc=-0.0065, loss_t=0.0162, loss_r=0.0062, loss=-0.0043, norm_factor=476.9879, grad_norm=0.9233\n",
      "Epoch 6: 117/256 - loss_mc=-0.0056, loss_t=0.0198, loss_r=0.0066, loss=-0.0029, norm_factor=477.5790, grad_norm=1.3733\n",
      "Epoch 6: 118/256 - loss_mc=-0.0062, loss_t=0.0151, loss_r=0.0066, loss=-0.0041, norm_factor=478.1661, grad_norm=0.9138\n",
      "Epoch 6: 119/256 - loss_mc=-0.0040, loss_t=0.0213, loss_r=0.0078, loss=-0.0011, norm_factor=478.7625, grad_norm=0.8771\n",
      "Epoch 6: 120/256 - loss_mc=-0.0063, loss_t=0.0164, loss_r=0.0064, loss=-0.0040, norm_factor=479.3031, grad_norm=1.3701\n",
      "Epoch 6: 121/256 - loss_mc=-0.0055, loss_t=0.0163, loss_r=0.0069, loss=-0.0032, norm_factor=479.8586, grad_norm=0.8014\n",
      "Epoch 6: 122/256 - loss_mc=-0.0048, loss_t=0.0200, loss_r=0.0072, loss=-0.0020, norm_factor=480.4112, grad_norm=0.9123\n",
      "Epoch 6: 123/256 - loss_mc=-0.0064, loss_t=0.0163, loss_r=0.0068, loss=-0.0041, norm_factor=480.9334, grad_norm=1.3729\n",
      "Epoch 6: 124/256 - loss_mc=-0.0052, loss_t=0.0175, loss_r=0.0072, loss=-0.0027, norm_factor=481.4770, grad_norm=1.4885\n",
      "Epoch 6: 125/256 - loss_mc=-0.0059, loss_t=0.0158, loss_r=0.0066, loss=-0.0036, norm_factor=482.0054, grad_norm=1.8354\n",
      "Epoch 6: 126/256 - loss_mc=-0.0065, loss_t=0.0120, loss_r=0.0063, loss=-0.0047, norm_factor=482.5371, grad_norm=1.1615\n",
      "Epoch 6: 127/256 - loss_mc=-0.0061, loss_t=0.0181, loss_r=0.0063, loss=-0.0037, norm_factor=483.0927, grad_norm=2.4146\n",
      "Epoch 6: 128/256 - loss_mc=-0.0062, loss_t=0.0195, loss_r=0.0052, loss=-0.0037, norm_factor=483.6588, grad_norm=1.8895\n",
      "Epoch 6: 129/256 - loss_mc=-0.0055, loss_t=0.0189, loss_r=0.0079, loss=-0.0029, norm_factor=484.2288, grad_norm=2.4075\n",
      "Epoch 6: 130/256 - loss_mc=-0.0055, loss_t=0.0183, loss_r=0.0071, loss=-0.0029, norm_factor=484.7883, grad_norm=2.4473\n",
      "Epoch 6: 131/256 - loss_mc=-0.0055, loss_t=0.0197, loss_r=0.0075, loss=-0.0028, norm_factor=485.3276, grad_norm=1.7430\n",
      "Epoch 6: 132/256 - loss_mc=-0.0065, loss_t=0.0158, loss_r=0.0050, loss=-0.0045, norm_factor=485.8564, grad_norm=1.3632\n",
      "Epoch 6: 133/256 - loss_mc=-0.0062, loss_t=0.0141, loss_r=0.0057, loss=-0.0042, norm_factor=486.4131, grad_norm=1.0109\n",
      "Epoch 6: 134/256 - loss_mc=-0.0056, loss_t=0.0162, loss_r=0.0075, loss=-0.0032, norm_factor=486.9836, grad_norm=1.4077\n",
      "Epoch 6: 135/256 - loss_mc=-0.0062, loss_t=0.0157, loss_r=0.0054, loss=-0.0040, norm_factor=487.5502, grad_norm=1.1572\n",
      "Epoch 6: 136/256 - loss_mc=-0.0065, loss_t=0.0199, loss_r=0.0059, loss=-0.0039, norm_factor=488.1271, grad_norm=1.5168\n",
      "Epoch 6: 137/256 - loss_mc=-0.0061, loss_t=0.0186, loss_r=0.0065, loss=-0.0035, norm_factor=488.7192, grad_norm=1.2701\n",
      "Epoch 6: 138/256 - loss_mc=-0.0062, loss_t=0.0160, loss_r=0.0060, loss=-0.0040, norm_factor=489.3068, grad_norm=1.0222\n",
      "Epoch 6: 139/256 - loss_mc=-0.0055, loss_t=0.0160, loss_r=0.0067, loss=-0.0032, norm_factor=489.8979, grad_norm=1.1604\n",
      "Epoch 6: 140/256 - loss_mc=-0.0062, loss_t=0.0161, loss_r=0.0063, loss=-0.0040, norm_factor=490.4711, grad_norm=1.3563\n",
      "Epoch 6: 141/256 - loss_mc=-0.0061, loss_t=0.0182, loss_r=0.0077, loss=-0.0035, norm_factor=491.0539, grad_norm=1.0972\n",
      "Epoch 6: 142/256 - loss_mc=-0.0062, loss_t=0.0141, loss_r=0.0056, loss=-0.0042, norm_factor=491.6438, grad_norm=1.4197\n",
      "Epoch 6: 143/256 - loss_mc=-0.0063, loss_t=0.0157, loss_r=0.0060, loss=-0.0041, norm_factor=492.2419, grad_norm=1.0576\n",
      "Epoch 6: 144/256 - loss_mc=-0.0054, loss_t=0.0178, loss_r=0.0069, loss=-0.0029, norm_factor=492.8425, grad_norm=1.4127\n",
      "Epoch 6: 145/256 - loss_mc=-0.0061, loss_t=0.0146, loss_r=0.0069, loss=-0.0040, norm_factor=493.4250, grad_norm=1.3612\n",
      "Epoch 6: 146/256 - loss_mc=-0.0065, loss_t=0.0131, loss_r=0.0054, loss=-0.0047, norm_factor=494.0105, grad_norm=0.8590\n",
      "Epoch 6: 147/256 - loss_mc=-0.0060, loss_t=0.0224, loss_r=0.0070, loss=-0.0030, norm_factor=494.6132, grad_norm=1.1421\n",
      "Epoch 6: 148/256 - loss_mc=-0.0061, loss_t=0.0138, loss_r=0.0064, loss=-0.0041, norm_factor=495.2159, grad_norm=0.8797\n",
      "Epoch 6: 149/256 - loss_mc=-0.0063, loss_t=0.0179, loss_r=0.0058, loss=-0.0039, norm_factor=495.8203, grad_norm=1.2705\n",
      "Epoch 6: 150/256 - loss_mc=-0.0065, loss_t=0.0162, loss_r=0.0065, loss=-0.0042, norm_factor=496.4277, grad_norm=0.9654\n",
      "Epoch 6: 151/256 - loss_mc=-0.0060, loss_t=0.0162, loss_r=0.0060, loss=-0.0038, norm_factor=497.0455, grad_norm=0.8967\n",
      "Epoch 6: 152/256 - loss_mc=-0.0067, loss_t=0.0129, loss_r=0.0060, loss=-0.0048, norm_factor=497.6598, grad_norm=0.9659\n",
      "Epoch 6: 153/256 - loss_mc=-0.0069, loss_t=0.0119, loss_r=0.0054, loss=-0.0052, norm_factor=498.2869, grad_norm=0.7548\n",
      "Epoch 6: 154/256 - loss_mc=-0.0058, loss_t=0.0158, loss_r=0.0068, loss=-0.0036, norm_factor=498.9346, grad_norm=1.2274\n",
      "Epoch 6: 155/256 - loss_mc=0.0053, loss_t=0.0151, loss_r=0.0117, loss=0.0080, norm_factor=499.5741, grad_norm=1.3817\n",
      "Epoch 6: 156/256 - loss_mc=-0.0056, loss_t=0.0152, loss_r=0.0075, loss=-0.0033, norm_factor=499.8409, grad_norm=1.2057\n",
      "Epoch 6: 157/256 - loss_mc=-0.0066, loss_t=0.0170, loss_r=0.0060, loss=-0.0043, norm_factor=500.1244, grad_norm=1.3064\n",
      "Epoch 6: 158/256 - loss_mc=-0.0060, loss_t=0.0183, loss_r=0.0057, loss=-0.0036, norm_factor=500.4540, grad_norm=1.3732\n",
      "Epoch 6: 159/256 - loss_mc=-0.0064, loss_t=0.0154, loss_r=0.0059, loss=-0.0043, norm_factor=500.8041, grad_norm=0.9925\n",
      "Epoch 6: 160/256 - loss_mc=-0.0064, loss_t=0.0199, loss_r=0.0059, loss=-0.0039, norm_factor=501.1796, grad_norm=1.3485\n",
      "Epoch 6: 161/256 - loss_mc=-0.0061, loss_t=0.0167, loss_r=0.0060, loss=-0.0039, norm_factor=501.5800, grad_norm=1.3781\n",
      "Epoch 6: 162/256 - loss_mc=-0.0064, loss_t=0.0145, loss_r=0.0065, loss=-0.0044, norm_factor=501.9969, grad_norm=1.3332\n",
      "Epoch 6: 163/256 - loss_mc=-0.0058, loss_t=0.0214, loss_r=0.0059, loss=-0.0030, norm_factor=502.4422, grad_norm=2.4771\n",
      "Epoch 6: 164/256 - loss_mc=-0.0063, loss_t=0.0170, loss_r=0.0064, loss=-0.0040, norm_factor=502.8972, grad_norm=2.3998\n",
      "Epoch 6: 165/256 - loss_mc=-0.0053, loss_t=0.0209, loss_r=0.0095, loss=-0.0023, norm_factor=503.3821, grad_norm=2.0288\n",
      "Epoch 6: 166/256 - loss_mc=-0.0062, loss_t=0.0162, loss_r=0.0062, loss=-0.0039, norm_factor=503.8536, grad_norm=1.3563\n",
      "Epoch 6: 167/256 - loss_mc=-0.0060, loss_t=0.0197, loss_r=0.0060, loss=-0.0034, norm_factor=504.3419, grad_norm=1.8587\n",
      "Epoch 6: 168/256 - loss_mc=-0.0063, loss_t=0.0159, loss_r=0.0062, loss=-0.0041, norm_factor=504.8334, grad_norm=1.8142\n",
      "Epoch 6: 169/256 - loss_mc=-0.0058, loss_t=0.0163, loss_r=0.0059, loss=-0.0036, norm_factor=505.3380, grad_norm=1.5905\n",
      "Epoch 6: 170/256 - loss_mc=-0.0057, loss_t=0.0190, loss_r=0.0072, loss=-0.0031, norm_factor=505.8393, grad_norm=1.9198\n",
      "Epoch 6: 171/256 - loss_mc=-0.0062, loss_t=0.0157, loss_r=0.0056, loss=-0.0040, norm_factor=506.3384, grad_norm=1.3423\n",
      "Epoch 6: 172/256 - loss_mc=-0.0054, loss_t=0.0174, loss_r=0.0099, loss=-0.0027, norm_factor=506.8542, grad_norm=1.4120\n",
      "Epoch 6: 173/256 - loss_mc=-0.0056, loss_t=0.0156, loss_r=0.0070, loss=-0.0034, norm_factor=507.3612, grad_norm=1.4621\n",
      "Epoch 6: 174/256 - loss_mc=-0.0062, loss_t=0.0158, loss_r=0.0060, loss=-0.0040, norm_factor=507.8589, grad_norm=1.3305\n",
      "Epoch 6: 175/256 - loss_mc=-0.0061, loss_t=0.0196, loss_r=0.0058, loss=-0.0036, norm_factor=508.3655, grad_norm=1.4267\n",
      "Epoch 6: 176/256 - loss_mc=-0.0066, loss_t=0.0217, loss_r=0.0053, loss=-0.0039, norm_factor=508.8766, grad_norm=2.3601\n",
      "Epoch 6: 177/256 - loss_mc=-0.0050, loss_t=0.0183, loss_r=0.0076, loss=-0.0024, norm_factor=509.4048, grad_norm=1.6136\n",
      "Epoch 6: 178/256 - loss_mc=-0.0053, loss_t=0.0184, loss_r=0.0080, loss=-0.0027, norm_factor=509.8982, grad_norm=2.3107\n",
      "Epoch 6: 179/256 - loss_mc=-0.0063, loss_t=0.0188, loss_r=0.0064, loss=-0.0038, norm_factor=510.3699, grad_norm=0.8315\n",
      "Epoch 6: 180/256 - loss_mc=-0.0062, loss_t=0.0192, loss_r=0.0066, loss=-0.0036, norm_factor=510.8515, grad_norm=1.7773\n",
      "Epoch 6: 181/256 - loss_mc=-0.0061, loss_t=0.0145, loss_r=0.0064, loss=-0.0040, norm_factor=511.3400, grad_norm=1.8046\n",
      "Epoch 6: 182/256 - loss_mc=-0.0061, loss_t=0.0183, loss_r=0.0066, loss=-0.0036, norm_factor=511.8331, grad_norm=2.2000\n",
      "Epoch 6: 183/256 - loss_mc=-0.0055, loss_t=0.0168, loss_r=0.0066, loss=-0.0031, norm_factor=512.3308, grad_norm=2.4411\n",
      "Epoch 6: 184/256 - loss_mc=-0.0064, loss_t=0.0175, loss_r=0.0061, loss=-0.0040, norm_factor=512.8176, grad_norm=2.0002\n",
      "Epoch 6: 185/256 - loss_mc=-0.0062, loss_t=0.0176, loss_r=0.0050, loss=-0.0039, norm_factor=513.3190, grad_norm=1.2185\n",
      "Epoch 6: 186/256 - loss_mc=-0.0066, loss_t=0.0132, loss_r=0.0049, loss=-0.0048, norm_factor=513.8248, grad_norm=1.5074\n",
      "Epoch 6: 187/256 - loss_mc=-0.0063, loss_t=0.0143, loss_r=0.0054, loss=-0.0043, norm_factor=514.3481, grad_norm=1.5583\n",
      "Epoch 6: 188/256 - loss_mc=-0.0070, loss_t=0.0134, loss_r=0.0052, loss=-0.0051, norm_factor=514.8762, grad_norm=0.8236\n",
      "Epoch 6: 189/256 - loss_mc=-0.0064, loss_t=0.0161, loss_r=0.0056, loss=-0.0042, norm_factor=515.4327, grad_norm=1.7527\n",
      "Epoch 6: 190/256 - loss_mc=-0.0060, loss_t=0.0170, loss_r=0.0060, loss=-0.0037, norm_factor=516.0003, grad_norm=1.1237\n",
      "Epoch 6: 191/256 - loss_mc=-0.0060, loss_t=0.0146, loss_r=0.0057, loss=-0.0040, norm_factor=516.5580, grad_norm=1.5942\n",
      "Epoch 6: 192/256 - loss_mc=-0.0063, loss_t=0.0133, loss_r=0.0062, loss=-0.0043, norm_factor=517.1210, grad_norm=1.8224\n",
      "Epoch 6: 193/256 - loss_mc=-0.0068, loss_t=0.0126, loss_r=0.0055, loss=-0.0050, norm_factor=517.6918, grad_norm=1.3678\n",
      "Epoch 6: 194/256 - loss_mc=-0.0058, loss_t=0.0115, loss_r=0.0088, loss=-0.0038, norm_factor=518.2849, grad_norm=1.4583\n",
      "Epoch 6: 195/256 - loss_mc=-0.0055, loss_t=0.0171, loss_r=0.0081, loss=-0.0030, norm_factor=518.8585, grad_norm=1.5058\n",
      "Epoch 6: 196/256 - loss_mc=-0.0058, loss_t=0.0164, loss_r=0.0063, loss=-0.0036, norm_factor=519.4030, grad_norm=0.8090\n",
      "Epoch 6: 197/256 - loss_mc=-0.0060, loss_t=0.0171, loss_r=0.0066, loss=-0.0036, norm_factor=519.9300, grad_norm=1.8722\n",
      "Epoch 6: 198/256 - loss_mc=-0.0057, loss_t=0.0153, loss_r=0.0069, loss=-0.0035, norm_factor=520.4457, grad_norm=1.6323\n",
      "Epoch 6: 199/256 - loss_mc=-0.0066, loss_t=0.0129, loss_r=0.0051, loss=-0.0048, norm_factor=520.9508, grad_norm=0.9308\n",
      "Epoch 6: 200/256 - loss_mc=-0.0060, loss_t=0.0142, loss_r=0.0063, loss=-0.0039, norm_factor=521.4743, grad_norm=1.7804\n",
      "Epoch 6: 201/256 - loss_mc=-0.0066, loss_t=0.0116, loss_r=0.0048, loss=-0.0049, norm_factor=521.9965, grad_norm=1.4558\n",
      "Epoch 6: 202/256 - loss_mc=-0.0057, loss_t=0.0145, loss_r=0.0062, loss=-0.0036, norm_factor=522.5340, grad_norm=1.1831\n",
      "Epoch 6: 203/256 - loss_mc=-0.0064, loss_t=0.0131, loss_r=0.0053, loss=-0.0046, norm_factor=523.0594, grad_norm=1.5687\n",
      "Epoch 6: 204/256 - loss_mc=-0.0064, loss_t=0.0131, loss_r=0.0052, loss=-0.0046, norm_factor=523.5924, grad_norm=0.9338\n",
      "Epoch 6: 205/256 - loss_mc=-0.0061, loss_t=0.0179, loss_r=0.0064, loss=-0.0036, norm_factor=524.1348, grad_norm=1.2548\n",
      "Epoch 6: 206/256 - loss_mc=-0.0068, loss_t=0.0129, loss_r=0.0045, loss=-0.0051, norm_factor=524.6682, grad_norm=1.1565\n",
      "Epoch 6: 207/256 - loss_mc=-0.0059, loss_t=0.0164, loss_r=0.0063, loss=-0.0036, norm_factor=525.2206, grad_norm=1.0845\n",
      "Epoch 6: 208/256 - loss_mc=-0.0067, loss_t=0.0137, loss_r=0.0045, loss=-0.0049, norm_factor=525.7604, grad_norm=0.7047\n",
      "Epoch 6: 209/256 - loss_mc=-0.0066, loss_t=0.0174, loss_r=0.0056, loss=-0.0043, norm_factor=526.3130, grad_norm=1.1517\n",
      "Epoch 6: 210/256 - loss_mc=-0.0042, loss_t=0.0194, loss_r=0.0067, loss=-0.0016, norm_factor=526.8766, grad_norm=1.6383\n",
      "Epoch 6: 211/256 - loss_mc=-0.0059, loss_t=0.0122, loss_r=0.0054, loss=-0.0042, norm_factor=527.3795, grad_norm=1.0705\n",
      "Epoch 6: 212/256 - loss_mc=-0.0061, loss_t=0.0118, loss_r=0.0056, loss=-0.0043, norm_factor=527.8750, grad_norm=1.3778\n",
      "Epoch 6: 213/256 - loss_mc=-0.0060, loss_t=0.0156, loss_r=0.0054, loss=-0.0039, norm_factor=528.3731, grad_norm=1.4016\n",
      "Epoch 6: 214/256 - loss_mc=-0.0065, loss_t=0.0143, loss_r=0.0060, loss=-0.0045, norm_factor=528.8679, grad_norm=1.0045\n",
      "Epoch 6: 215/256 - loss_mc=-0.0062, loss_t=0.0149, loss_r=0.0067, loss=-0.0041, norm_factor=529.3733, grad_norm=1.6889\n",
      "Epoch 6: 216/256 - loss_mc=-0.0071, loss_t=0.0135, loss_r=0.0047, loss=-0.0052, norm_factor=529.8813, grad_norm=1.3447\n",
      "Epoch 6: 217/256 - loss_mc=-0.0069, loss_t=0.0126, loss_r=0.0053, loss=-0.0051, norm_factor=530.4230, grad_norm=1.2799\n",
      "Epoch 6: 218/256 - loss_mc=-0.0058, loss_t=0.0141, loss_r=0.0071, loss=-0.0037, norm_factor=530.9916, grad_norm=2.1272\n",
      "Epoch 6: 219/256 - loss_mc=-0.0066, loss_t=0.0124, loss_r=0.0054, loss=-0.0048, norm_factor=531.5519, grad_norm=0.9266\n",
      "Epoch 6: 220/256 - loss_mc=-0.0064, loss_t=0.0133, loss_r=0.0047, loss=-0.0046, norm_factor=532.1270, grad_norm=1.5379\n",
      "Epoch 6: 221/256 - loss_mc=-0.0069, loss_t=0.0150, loss_r=0.0049, loss=-0.0049, norm_factor=532.7104, grad_norm=1.7656\n",
      "Epoch 6: 222/256 - loss_mc=-0.0058, loss_t=0.0177, loss_r=0.0063, loss=-0.0034, norm_factor=533.3173, grad_norm=1.0724\n",
      "Epoch 6: 223/256 - loss_mc=-0.0060, loss_t=0.0183, loss_r=0.0055, loss=-0.0036, norm_factor=533.8983, grad_norm=1.3985\n",
      "Epoch 6: 224/256 - loss_mc=-0.0068, loss_t=0.0134, loss_r=0.0047, loss=-0.0050, norm_factor=534.4709, grad_norm=1.0718\n",
      "Epoch 6: 225/256 - loss_mc=-0.0065, loss_t=0.0140, loss_r=0.0057, loss=-0.0045, norm_factor=535.0593, grad_norm=1.4743\n",
      "Epoch 6: 226/256 - loss_mc=-0.0070, loss_t=0.0109, loss_r=0.0046, loss=-0.0054, norm_factor=535.6558, grad_norm=1.0567\n",
      "Epoch 6: 227/256 - loss_mc=-0.0069, loss_t=0.0149, loss_r=0.0049, loss=-0.0049, norm_factor=536.2686, grad_norm=0.9944\n",
      "Epoch 6: 228/256 - loss_mc=-0.0065, loss_t=0.0152, loss_r=0.0047, loss=-0.0045, norm_factor=536.8912, grad_norm=1.2545\n",
      "Epoch 6: 229/256 - loss_mc=-0.0061, loss_t=0.0149, loss_r=0.0059, loss=-0.0040, norm_factor=537.5127, grad_norm=1.0307\n",
      "Epoch 6: 230/256 - loss_mc=-0.0048, loss_t=0.0116, loss_r=0.0085, loss=-0.0028, norm_factor=538.1204, grad_norm=1.0876\n",
      "Epoch 6: 231/256 - loss_mc=-0.0065, loss_t=0.0116, loss_r=0.0054, loss=-0.0048, norm_factor=538.6704, grad_norm=1.0347\n",
      "Epoch 6: 232/256 - loss_mc=-0.0057, loss_t=0.0168, loss_r=0.0067, loss=-0.0034, norm_factor=539.2325, grad_norm=1.2218\n",
      "Epoch 6: 233/256 - loss_mc=-0.0064, loss_t=0.0119, loss_r=0.0057, loss=-0.0047, norm_factor=539.7781, grad_norm=0.9660\n",
      "Epoch 6: 234/256 - loss_mc=-0.0060, loss_t=0.0123, loss_r=0.0054, loss=-0.0042, norm_factor=540.3340, grad_norm=0.9368\n",
      "Epoch 6: 235/256 - loss_mc=-0.0064, loss_t=0.0138, loss_r=0.0060, loss=-0.0044, norm_factor=540.8833, grad_norm=1.2978\n",
      "Epoch 6: 236/256 - loss_mc=-0.0054, loss_t=0.0165, loss_r=0.0070, loss=-0.0030, norm_factor=541.4413, grad_norm=1.1876\n",
      "Epoch 6: 237/256 - loss_mc=-0.0067, loss_t=0.0121, loss_r=0.0056, loss=-0.0049, norm_factor=541.9661, grad_norm=0.9395\n",
      "Epoch 6: 238/256 - loss_mc=-0.0066, loss_t=0.0136, loss_r=0.0049, loss=-0.0048, norm_factor=542.5000, grad_norm=1.3777\n",
      "Epoch 6: 239/256 - loss_mc=-0.0067, loss_t=0.0165, loss_r=0.0055, loss=-0.0045, norm_factor=543.0475, grad_norm=1.0171\n",
      "Epoch 6: 240/256 - loss_mc=-0.0064, loss_t=0.0129, loss_r=0.0051, loss=-0.0046, norm_factor=543.6024, grad_norm=0.9512\n",
      "Epoch 6: 241/256 - loss_mc=-0.0069, loss_t=0.0131, loss_r=0.0047, loss=-0.0052, norm_factor=544.1661, grad_norm=0.9438\n",
      "Epoch 6: 242/256 - loss_mc=-0.0062, loss_t=0.0121, loss_r=0.0057, loss=-0.0044, norm_factor=544.7537, grad_norm=1.1432\n",
      "Epoch 6: 243/256 - loss_mc=-0.0066, loss_t=0.0124, loss_r=0.0053, loss=-0.0048, norm_factor=545.3365, grad_norm=1.2002\n",
      "Epoch 6: 244/256 - loss_mc=-0.0066, loss_t=0.0168, loss_r=0.0049, loss=-0.0044, norm_factor=545.9208, grad_norm=1.5464\n",
      "Epoch 6: 245/256 - loss_mc=-0.0066, loss_t=0.0134, loss_r=0.0053, loss=-0.0048, norm_factor=546.5095, grad_norm=1.1621\n",
      "Epoch 6: 246/256 - loss_mc=-0.0066, loss_t=0.0134, loss_r=0.0058, loss=-0.0046, norm_factor=547.1125, grad_norm=1.9328\n",
      "Epoch 6: 247/256 - loss_mc=-0.0069, loss_t=0.0114, loss_r=0.0051, loss=-0.0052, norm_factor=547.7236, grad_norm=0.8838\n",
      "Epoch 6: 248/256 - loss_mc=-0.0061, loss_t=0.0122, loss_r=0.0069, loss=-0.0042, norm_factor=548.3466, grad_norm=1.4069\n",
      "Epoch 6: 249/256 - loss_mc=-0.0068, loss_t=0.0136, loss_r=0.0054, loss=-0.0049, norm_factor=548.9512, grad_norm=1.0616\n",
      "Epoch 6: 250/256 - loss_mc=-0.0063, loss_t=0.0220, loss_r=0.0090, loss=-0.0032, norm_factor=549.5620, grad_norm=1.5654\n",
      "Epoch 6: 251/256 - loss_mc=-0.0033, loss_t=0.0208, loss_r=0.0091, loss=-0.0003, norm_factor=550.1637, grad_norm=0.8980\n",
      "Epoch 6: 252/256 - loss_mc=-0.0062, loss_t=0.0142, loss_r=0.0058, loss=-0.0042, norm_factor=550.6434, grad_norm=1.3642\n",
      "Epoch 6: 253/256 - loss_mc=-0.0065, loss_t=0.0114, loss_r=0.0060, loss=-0.0047, norm_factor=551.1262, grad_norm=1.3516\n",
      "Epoch 6: 254/256 - loss_mc=-0.0062, loss_t=0.0144, loss_r=0.0056, loss=-0.0043, norm_factor=551.6223, grad_norm=1.3011\n",
      "Epoch 6: 255/256 - loss_mc=-0.0063, loss_t=0.0132, loss_r=0.0052, loss=-0.0045, norm_factor=552.1271, grad_norm=0.5544\n",
      "Epoch 6: 256/256 - loss_mc=-0.0056, loss_t=0.0161, loss_r=0.0052, loss=-0.0035, norm_factor=552.6286, grad_norm=1.2078\n",
      "Epoch 7: 1/256 - loss_mc=-0.0072, loss_t=0.0125, loss_r=0.0045, loss=-0.0055, norm_factor=553.1049, grad_norm=1.4229\n",
      "Epoch 7: 2/256 - loss_mc=-0.0036, loss_t=0.0144, loss_r=0.0056, loss=-0.0016, norm_factor=553.6174, grad_norm=0.9537\n",
      "Epoch 7: 3/256 - loss_mc=-0.0049, loss_t=0.0115, loss_r=0.0107, loss=-0.0027, norm_factor=554.0294, grad_norm=0.9620\n",
      "Epoch 7: 4/256 - loss_mc=-0.0068, loss_t=0.0120, loss_r=0.0050, loss=-0.0051, norm_factor=554.3966, grad_norm=0.9691\n",
      "Epoch 7: 5/256 - loss_mc=-0.0067, loss_t=0.0109, loss_r=0.0050, loss=-0.0051, norm_factor=554.7965, grad_norm=0.9906\n",
      "Epoch 7: 6/256 - loss_mc=-0.0071, loss_t=0.0129, loss_r=0.0047, loss=-0.0053, norm_factor=555.2260, grad_norm=1.1210\n",
      "Epoch 7: 7/256 - loss_mc=-0.0062, loss_t=0.0102, loss_r=0.0057, loss=-0.0046, norm_factor=555.6919, grad_norm=1.7264\n",
      "Epoch 7: 8/256 - loss_mc=-0.0065, loss_t=0.0129, loss_r=0.0051, loss=-0.0047, norm_factor=556.1621, grad_norm=1.2337\n",
      "Epoch 7: 9/256 - loss_mc=-0.0066, loss_t=0.0132, loss_r=0.0060, loss=-0.0047, norm_factor=556.6414, grad_norm=1.5761\n",
      "Epoch 7: 10/256 - loss_mc=-0.0062, loss_t=0.0119, loss_r=0.0048, loss=-0.0045, norm_factor=557.1368, grad_norm=1.2490\n",
      "Epoch 7: 11/256 - loss_mc=-0.0068, loss_t=0.0169, loss_r=0.0051, loss=-0.0046, norm_factor=557.6232, grad_norm=1.4464\n",
      "Epoch 7: 12/256 - loss_mc=-0.0056, loss_t=0.0130, loss_r=0.0063, loss=-0.0037, norm_factor=558.1268, grad_norm=1.4214\n",
      "Epoch 7: 13/256 - loss_mc=-0.0068, loss_t=0.0124, loss_r=0.0049, loss=-0.0051, norm_factor=558.6052, grad_norm=1.7245\n",
      "Epoch 7: 14/256 - loss_mc=-0.0069, loss_t=0.0135, loss_r=0.0043, loss=-0.0051, norm_factor=559.1067, grad_norm=1.6248\n",
      "Epoch 7: 15/256 - loss_mc=-0.0063, loss_t=0.0145, loss_r=0.0060, loss=-0.0042, norm_factor=559.6333, grad_norm=1.4590\n",
      "Epoch 7: 16/256 - loss_mc=-0.0066, loss_t=0.0134, loss_r=0.0048, loss=-0.0048, norm_factor=560.1624, grad_norm=1.8303\n",
      "Epoch 7: 17/256 - loss_mc=-0.0067, loss_t=0.0108, loss_r=0.0052, loss=-0.0051, norm_factor=560.7046, grad_norm=0.7650\n",
      "Epoch 7: 18/256 - loss_mc=-0.0069, loss_t=0.0139, loss_r=0.0049, loss=-0.0050, norm_factor=561.2595, grad_norm=1.8855\n",
      "Epoch 7: 19/256 - loss_mc=-0.0060, loss_t=0.0150, loss_r=0.0051, loss=-0.0040, norm_factor=561.8319, grad_norm=1.1913\n",
      "Epoch 7: 20/256 - loss_mc=-0.0046, loss_t=0.0156, loss_r=0.0094, loss=-0.0021, norm_factor=562.3853, grad_norm=0.8272\n",
      "Epoch 7: 21/256 - loss_mc=-0.0061, loss_t=0.0161, loss_r=0.0059, loss=-0.0039, norm_factor=562.8555, grad_norm=1.6549\n",
      "Epoch 7: 22/256 - loss_mc=-0.0061, loss_t=0.0109, loss_r=0.0056, loss=-0.0045, norm_factor=563.3262, grad_norm=0.9147\n",
      "Epoch 7: 23/256 - loss_mc=-0.0066, loss_t=0.0129, loss_r=0.0051, loss=-0.0048, norm_factor=563.7990, grad_norm=1.6120\n",
      "Epoch 7: 24/256 - loss_mc=-0.0071, loss_t=0.0138, loss_r=0.0047, loss=-0.0052, norm_factor=564.2942, grad_norm=1.4358\n",
      "Epoch 7: 25/256 - loss_mc=-0.0065, loss_t=0.0141, loss_r=0.0051, loss=-0.0046, norm_factor=564.8160, grad_norm=1.4345\n",
      "Epoch 7: 26/256 - loss_mc=-0.0061, loss_t=0.0143, loss_r=0.0061, loss=-0.0041, norm_factor=565.3400, grad_norm=1.9789\n",
      "Epoch 7: 27/256 - loss_mc=-0.0062, loss_t=0.0155, loss_r=0.0060, loss=-0.0040, norm_factor=565.8533, grad_norm=0.7710\n",
      "Epoch 7: 28/256 - loss_mc=-0.0060, loss_t=0.0140, loss_r=0.0051, loss=-0.0041, norm_factor=566.3560, grad_norm=1.0376\n",
      "Epoch 7: 29/256 - loss_mc=-0.0060, loss_t=0.0139, loss_r=0.0065, loss=-0.0040, norm_factor=566.8381, grad_norm=1.7062\n",
      "Epoch 7: 30/256 - loss_mc=-0.0065, loss_t=0.0135, loss_r=0.0056, loss=-0.0046, norm_factor=567.3097, grad_norm=1.0158\n",
      "Epoch 7: 31/256 - loss_mc=-0.0064, loss_t=0.0142, loss_r=0.0050, loss=-0.0044, norm_factor=567.7925, grad_norm=1.9722\n",
      "Epoch 7: 32/256 - loss_mc=-0.0074, loss_t=0.0112, loss_r=0.0044, loss=-0.0058, norm_factor=568.2863, grad_norm=0.8818\n",
      "Epoch 7: 33/256 - loss_mc=-0.0062, loss_t=0.0136, loss_r=0.0058, loss=-0.0043, norm_factor=568.8198, grad_norm=1.9478\n",
      "Epoch 7: 34/256 - loss_mc=-0.0064, loss_t=0.0138, loss_r=0.0058, loss=-0.0044, norm_factor=569.3400, grad_norm=1.6990\n",
      "Epoch 7: 35/256 - loss_mc=-0.0068, loss_t=0.0119, loss_r=0.0048, loss=-0.0051, norm_factor=569.8545, grad_norm=1.3209\n",
      "Epoch 7: 36/256 - loss_mc=-0.0064, loss_t=0.0162, loss_r=0.0057, loss=-0.0042, norm_factor=570.3840, grad_norm=2.5621\n",
      "Epoch 7: 37/256 - loss_mc=-0.0067, loss_t=0.0130, loss_r=0.0051, loss=-0.0049, norm_factor=570.9082, grad_norm=1.2208\n",
      "Epoch 7: 38/256 - loss_mc=-0.0064, loss_t=0.0118, loss_r=0.0056, loss=-0.0046, norm_factor=571.4441, grad_norm=2.1890\n",
      "Epoch 7: 39/256 - loss_mc=-0.0066, loss_t=0.0132, loss_r=0.0055, loss=-0.0047, norm_factor=571.9772, grad_norm=1.6985\n",
      "Epoch 7: 40/256 - loss_mc=-0.0068, loss_t=0.0148, loss_r=0.0049, loss=-0.0048, norm_factor=572.5123, grad_norm=1.7411\n",
      "Epoch 7: 41/256 - loss_mc=-0.0065, loss_t=0.0153, loss_r=0.0050, loss=-0.0045, norm_factor=573.0658, grad_norm=1.7672\n",
      "Epoch 7: 42/256 - loss_mc=-0.0067, loss_t=0.0178, loss_r=0.0048, loss=-0.0044, norm_factor=573.6172, grad_norm=1.8560\n",
      "Epoch 7: 43/256 - loss_mc=-0.0070, loss_t=0.0102, loss_r=0.0050, loss=-0.0055, norm_factor=574.1748, grad_norm=1.2536\n",
      "Epoch 7: 44/256 - loss_mc=-0.0065, loss_t=0.0116, loss_r=0.0048, loss=-0.0049, norm_factor=574.7563, grad_norm=2.2803\n",
      "Epoch 7: 45/256 - loss_mc=-0.0068, loss_t=0.0123, loss_r=0.0044, loss=-0.0052, norm_factor=575.3395, grad_norm=1.0889\n",
      "Epoch 7: 46/256 - loss_mc=-0.0064, loss_t=0.0122, loss_r=0.0050, loss=-0.0047, norm_factor=575.9334, grad_norm=1.4006\n",
      "Epoch 7: 47/256 - loss_mc=-0.0063, loss_t=0.0109, loss_r=0.0053, loss=-0.0047, norm_factor=576.5226, grad_norm=1.7684\n",
      "Epoch 7: 48/256 - loss_mc=-0.0054, loss_t=0.0187, loss_r=0.0055, loss=-0.0030, norm_factor=577.0970, grad_norm=1.1824\n",
      "Epoch 7: 49/256 - loss_mc=-0.0056, loss_t=0.0182, loss_r=0.0060, loss=-0.0032, norm_factor=577.6285, grad_norm=2.0061\n",
      "Epoch 7: 50/256 - loss_mc=-0.0066, loss_t=0.0175, loss_r=0.0055, loss=-0.0043, norm_factor=578.1259, grad_norm=1.7082\n",
      "Epoch 7: 51/256 - loss_mc=-0.0069, loss_t=0.0132, loss_r=0.0051, loss=-0.0050, norm_factor=578.6340, grad_norm=1.3878\n",
      "Epoch 7: 52/256 - loss_mc=-0.0050, loss_t=0.0125, loss_r=0.0065, loss=-0.0031, norm_factor=579.1573, grad_norm=1.4543\n",
      "Epoch 7: 53/256 - loss_mc=-0.0069, loss_t=0.0129, loss_r=0.0046, loss=-0.0052, norm_factor=579.6219, grad_norm=1.0171\n",
      "Epoch 7: 54/256 - loss_mc=-0.0064, loss_t=0.0117, loss_r=0.0049, loss=-0.0048, norm_factor=580.1104, grad_norm=1.2437\n",
      "Epoch 7: 55/256 - loss_mc=-0.0065, loss_t=0.0121, loss_r=0.0050, loss=-0.0048, norm_factor=580.6019, grad_norm=0.9403\n",
      "Epoch 7: 56/256 - loss_mc=-0.0061, loss_t=0.0148, loss_r=0.0053, loss=-0.0041, norm_factor=581.1008, grad_norm=1.4224\n",
      "Epoch 7: 57/256 - loss_mc=-0.0067, loss_t=0.0133, loss_r=0.0043, loss=-0.0049, norm_factor=581.5886, grad_norm=1.4327\n",
      "Epoch 7: 58/256 - loss_mc=-0.0061, loss_t=0.0133, loss_r=0.0059, loss=-0.0042, norm_factor=582.0851, grad_norm=0.9061\n",
      "Epoch 7: 59/256 - loss_mc=-0.0067, loss_t=0.0137, loss_r=0.0051, loss=-0.0048, norm_factor=582.5706, grad_norm=1.7202\n",
      "Epoch 7: 60/256 - loss_mc=-0.0057, loss_t=0.0138, loss_r=0.0062, loss=-0.0037, norm_factor=583.0747, grad_norm=1.1543\n",
      "Epoch 7: 61/256 - loss_mc=-0.0066, loss_t=0.0156, loss_r=0.0053, loss=-0.0045, norm_factor=583.5494, grad_norm=1.6210\n",
      "Epoch 7: 62/256 - loss_mc=-0.0059, loss_t=0.0157, loss_r=0.0053, loss=-0.0038, norm_factor=584.0341, grad_norm=1.0557\n",
      "Epoch 7: 63/256 - loss_mc=-0.0066, loss_t=0.0226, loss_r=0.0049, loss=-0.0039, norm_factor=584.5040, grad_norm=1.3731\n",
      "Epoch 7: 64/256 - loss_mc=-0.0066, loss_t=0.0119, loss_r=0.0051, loss=-0.0049, norm_factor=584.9899, grad_norm=1.0658\n",
      "Epoch 7: 65/256 - loss_mc=-0.0065, loss_t=0.0134, loss_r=0.0053, loss=-0.0046, norm_factor=585.4860, grad_norm=1.5244\n",
      "Epoch 7: 66/256 - loss_mc=-0.0071, loss_t=0.0100, loss_r=0.0044, loss=-0.0057, norm_factor=585.9897, grad_norm=1.0532\n",
      "Epoch 7: 67/256 - loss_mc=-0.0066, loss_t=0.0129, loss_r=0.0051, loss=-0.0048, norm_factor=586.5189, grad_norm=1.1258\n",
      "Epoch 7: 68/256 - loss_mc=-0.0068, loss_t=0.0144, loss_r=0.0046, loss=-0.0049, norm_factor=587.0471, grad_norm=1.0259\n",
      "Epoch 7: 69/256 - loss_mc=-0.0054, loss_t=0.0160, loss_r=0.0066, loss=-0.0032, norm_factor=587.5790, grad_norm=1.7827\n",
      "Epoch 7: 70/256 - loss_mc=-0.0066, loss_t=0.0117, loss_r=0.0049, loss=-0.0049, norm_factor=588.0670, grad_norm=1.4981\n",
      "Epoch 7: 71/256 - loss_mc=-0.0067, loss_t=0.0124, loss_r=0.0045, loss=-0.0050, norm_factor=588.5638, grad_norm=1.6705\n",
      "Epoch 7: 72/256 - loss_mc=-0.0066, loss_t=0.0136, loss_r=0.0049, loss=-0.0048, norm_factor=589.0756, grad_norm=1.7224\n",
      "Epoch 7: 73/256 - loss_mc=-0.0068, loss_t=0.0120, loss_r=0.0044, loss=-0.0051, norm_factor=589.5874, grad_norm=1.4404\n",
      "Epoch 7: 74/256 - loss_mc=-0.0070, loss_t=0.0093, loss_r=0.0047, loss=-0.0056, norm_factor=590.1111, grad_norm=1.5447\n",
      "Epoch 7: 75/256 - loss_mc=-0.0068, loss_t=0.0104, loss_r=0.0047, loss=-0.0053, norm_factor=590.6544, grad_norm=1.5178\n",
      "Epoch 7: 76/256 - loss_mc=-0.0069, loss_t=0.0116, loss_r=0.0043, loss=-0.0053, norm_factor=591.2013, grad_norm=1.2430\n",
      "Epoch 7: 77/256 - loss_mc=-0.0063, loss_t=0.0112, loss_r=0.0051, loss=-0.0047, norm_factor=591.7617, grad_norm=2.2927\n",
      "Epoch 7: 78/256 - loss_mc=-0.0060, loss_t=0.0100, loss_r=0.0056, loss=-0.0044, norm_factor=592.3146, grad_norm=1.1242\n",
      "Epoch 7: 79/256 - loss_mc=-0.0065, loss_t=0.0117, loss_r=0.0047, loss=-0.0049, norm_factor=592.8411, grad_norm=1.4263\n",
      "Epoch 7: 80/256 - loss_mc=-0.0066, loss_t=0.0128, loss_r=0.0055, loss=-0.0048, norm_factor=593.3672, grad_norm=1.2042\n",
      "Epoch 7: 81/256 - loss_mc=-0.0063, loss_t=0.0110, loss_r=0.0053, loss=-0.0047, norm_factor=593.8932, grad_norm=1.3728\n",
      "Epoch 7: 82/256 - loss_mc=-0.0061, loss_t=0.0132, loss_r=0.0046, loss=-0.0044, norm_factor=594.4105, grad_norm=1.7360\n",
      "Epoch 7: 83/256 - loss_mc=-0.0070, loss_t=0.0096, loss_r=0.0042, loss=-0.0056, norm_factor=594.9118, grad_norm=1.0960\n",
      "Epoch 7: 84/256 - loss_mc=0.0041, loss_t=0.0156, loss_r=0.0062, loss=0.0063, norm_factor=595.4352, grad_norm=2.0620\n",
      "Epoch 7: 85/256 - loss_mc=-0.0068, loss_t=0.0105, loss_r=0.0050, loss=-0.0053, norm_factor=595.4930, grad_norm=1.1260\n",
      "Epoch 7: 86/256 - loss_mc=-0.0063, loss_t=0.0105, loss_r=0.0052, loss=-0.0048, norm_factor=595.6112, grad_norm=1.4711\n",
      "Epoch 7: 87/256 - loss_mc=-0.0063, loss_t=0.0120, loss_r=0.0051, loss=-0.0046, norm_factor=595.7635, grad_norm=1.2966\n",
      "Epoch 7: 88/256 - loss_mc=-0.0062, loss_t=0.0163, loss_r=0.0048, loss=-0.0041, norm_factor=595.9458, grad_norm=1.2624\n",
      "Epoch 7: 89/256 - loss_mc=-0.0068, loss_t=0.0116, loss_r=0.0048, loss=-0.0052, norm_factor=596.1442, grad_norm=1.2220\n",
      "Epoch 7: 90/256 - loss_mc=-0.0070, loss_t=0.0106, loss_r=0.0041, loss=-0.0055, norm_factor=596.3827, grad_norm=1.0410\n",
      "Epoch 7: 91/256 - loss_mc=-0.0064, loss_t=0.0160, loss_r=0.0054, loss=-0.0043, norm_factor=596.6605, grad_norm=1.6411\n",
      "Epoch 7: 92/256 - loss_mc=-0.0067, loss_t=0.0131, loss_r=0.0044, loss=-0.0050, norm_factor=596.9598, grad_norm=1.0680\n",
      "Epoch 7: 93/256 - loss_mc=-0.0062, loss_t=0.0126, loss_r=0.0048, loss=-0.0045, norm_factor=597.2935, grad_norm=1.3621\n",
      "Epoch 7: 94/256 - loss_mc=-0.0063, loss_t=0.0107, loss_r=0.0053, loss=-0.0046, norm_factor=597.6411, grad_norm=1.2063\n",
      "Epoch 7: 95/256 - loss_mc=-0.0063, loss_t=0.0119, loss_r=0.0049, loss=-0.0046, norm_factor=597.9976, grad_norm=0.9940\n",
      "Epoch 7: 96/256 - loss_mc=-0.0067, loss_t=0.0137, loss_r=0.0047, loss=-0.0048, norm_factor=598.3619, grad_norm=1.2070\n",
      "Epoch 7: 97/256 - loss_mc=-0.0065, loss_t=0.0132, loss_r=0.0051, loss=-0.0047, norm_factor=598.7572, grad_norm=1.4301\n",
      "Epoch 7: 98/256 - loss_mc=-0.0061, loss_t=0.0174, loss_r=0.0054, loss=-0.0038, norm_factor=599.1680, grad_norm=1.7042\n",
      "Epoch 7: 99/256 - loss_mc=-0.0063, loss_t=0.0143, loss_r=0.0055, loss=-0.0044, norm_factor=599.5806, grad_norm=2.0604\n",
      "Epoch 7: 100/256 - loss_mc=-0.0065, loss_t=0.0113, loss_r=0.0052, loss=-0.0048, norm_factor=599.9977, grad_norm=1.6698\n",
      "Epoch 7: 101/256 - loss_mc=-0.0065, loss_t=0.0126, loss_r=0.0043, loss=-0.0048, norm_factor=600.4286, grad_norm=1.6347\n",
      "Epoch 7: 102/256 - loss_mc=-0.0061, loss_t=0.0109, loss_r=0.0055, loss=-0.0045, norm_factor=600.8690, grad_norm=1.7664\n",
      "Epoch 7: 103/256 - loss_mc=-0.0061, loss_t=0.0121, loss_r=0.0050, loss=-0.0044, norm_factor=601.3085, grad_norm=1.5429\n",
      "Epoch 7: 104/256 - loss_mc=-0.0054, loss_t=0.0199, loss_r=0.0059, loss=-0.0028, norm_factor=601.7379, grad_norm=2.5740\n",
      "Epoch 7: 105/256 - loss_mc=-0.0070, loss_t=0.0101, loss_r=0.0049, loss=-0.0055, norm_factor=602.1226, grad_norm=0.7812\n",
      "Epoch 7: 106/256 - loss_mc=-0.0060, loss_t=0.0165, loss_r=0.0043, loss=-0.0039, norm_factor=602.5355, grad_norm=2.4332\n",
      "Epoch 7: 107/256 - loss_mc=-0.0064, loss_t=0.0118, loss_r=0.0045, loss=-0.0048, norm_factor=602.9351, grad_norm=1.1923\n",
      "Epoch 7: 108/256 - loss_mc=-0.0067, loss_t=0.0105, loss_r=0.0049, loss=-0.0052, norm_factor=603.3445, grad_norm=1.7326\n",
      "Epoch 7: 109/256 - loss_mc=-0.0061, loss_t=0.0127, loss_r=0.0055, loss=-0.0042, norm_factor=603.7773, grad_norm=1.9201\n",
      "Epoch 7: 110/256 - loss_mc=-0.0064, loss_t=0.0112, loss_r=0.0052, loss=-0.0047, norm_factor=604.1990, grad_norm=1.0269\n",
      "Epoch 7: 111/256 - loss_mc=-0.0064, loss_t=0.0123, loss_r=0.0048, loss=-0.0047, norm_factor=604.6278, grad_norm=2.0673\n",
      "Epoch 7: 112/256 - loss_mc=-0.0063, loss_t=0.0138, loss_r=0.0052, loss=-0.0044, norm_factor=605.0659, grad_norm=1.4596\n",
      "Epoch 7: 113/256 - loss_mc=-0.0066, loss_t=0.0138, loss_r=0.0048, loss=-0.0047, norm_factor=605.5005, grad_norm=1.4231\n",
      "Epoch 7: 114/256 - loss_mc=-0.0064, loss_t=0.0106, loss_r=0.0050, loss=-0.0048, norm_factor=605.9461, grad_norm=1.2373\n",
      "Epoch 7: 115/256 - loss_mc=-0.0067, loss_t=0.0135, loss_r=0.0049, loss=-0.0049, norm_factor=606.3909, grad_norm=1.4145\n",
      "Epoch 7: 116/256 - loss_mc=-0.0065, loss_t=0.0146, loss_r=0.0050, loss=-0.0045, norm_factor=606.8469, grad_norm=0.9658\n",
      "Epoch 7: 117/256 - loss_mc=-0.0066, loss_t=0.0143, loss_r=0.0053, loss=-0.0046, norm_factor=607.3060, grad_norm=1.7786\n",
      "Epoch 7: 118/256 - loss_mc=-0.0066, loss_t=0.0114, loss_r=0.0044, loss=-0.0050, norm_factor=607.7762, grad_norm=0.5905\n",
      "Epoch 7: 119/256 - loss_mc=-0.0067, loss_t=0.0132, loss_r=0.0046, loss=-0.0049, norm_factor=608.2590, grad_norm=1.5669\n",
      "Epoch 7: 120/256 - loss_mc=-0.0070, loss_t=0.0125, loss_r=0.0044, loss=-0.0053, norm_factor=608.7486, grad_norm=0.6956\n",
      "Epoch 7: 121/256 - loss_mc=-0.0070, loss_t=0.0122, loss_r=0.0038, loss=-0.0054, norm_factor=609.2557, grad_norm=0.8576\n",
      "Epoch 7: 122/256 - loss_mc=-0.0063, loss_t=0.0115, loss_r=0.0046, loss=-0.0047, norm_factor=609.7789, grad_norm=0.8445\n",
      "Epoch 7: 123/256 - loss_mc=-0.0064, loss_t=0.0124, loss_r=0.0050, loss=-0.0047, norm_factor=610.2977, grad_norm=1.4345\n",
      "Epoch 7: 124/256 - loss_mc=-0.0070, loss_t=0.0121, loss_r=0.0040, loss=-0.0054, norm_factor=610.8167, grad_norm=1.4005\n",
      "Epoch 7: 125/256 - loss_mc=-0.0071, loss_t=0.0115, loss_r=0.0038, loss=-0.0056, norm_factor=611.3606, grad_norm=1.3992\n",
      "Epoch 7: 126/256 - loss_mc=-0.0070, loss_t=0.0134, loss_r=0.0040, loss=-0.0053, norm_factor=611.9264, grad_norm=1.0849\n",
      "Epoch 7: 127/256 - loss_mc=-0.0066, loss_t=0.0134, loss_r=0.0050, loss=-0.0048, norm_factor=612.5083, grad_norm=1.5690\n",
      "Epoch 7: 128/256 - loss_mc=-0.0061, loss_t=0.0155, loss_r=0.0052, loss=-0.0041, norm_factor=613.0819, grad_norm=1.3848\n",
      "Epoch 7: 129/256 - loss_mc=-0.0065, loss_t=0.0125, loss_r=0.0051, loss=-0.0047, norm_factor=613.6285, grad_norm=1.1777\n",
      "Epoch 7: 130/256 - loss_mc=-0.0065, loss_t=0.0162, loss_r=0.0048, loss=-0.0044, norm_factor=614.1700, grad_norm=1.9436\n",
      "Epoch 7: 131/256 - loss_mc=-0.0067, loss_t=0.0111, loss_r=0.0041, loss=-0.0052, norm_factor=614.7139, grad_norm=1.1857\n",
      "Epoch 7: 132/256 - loss_mc=-0.0071, loss_t=0.0118, loss_r=0.0037, loss=-0.0056, norm_factor=615.2643, grad_norm=1.3579\n",
      "Epoch 7: 133/256 - loss_mc=-0.0069, loss_t=0.0116, loss_r=0.0048, loss=-0.0052, norm_factor=615.8375, grad_norm=1.7868\n",
      "Epoch 7: 134/256 - loss_mc=-0.0071, loss_t=0.0138, loss_r=0.0037, loss=-0.0054, norm_factor=616.4243, grad_norm=1.1908\n",
      "Epoch 7: 135/256 - loss_mc=-0.0068, loss_t=0.0119, loss_r=0.0047, loss=-0.0051, norm_factor=617.0280, grad_norm=1.7438\n",
      "Epoch 7: 136/256 - loss_mc=-0.0067, loss_t=0.0131, loss_r=0.0047, loss=-0.0049, norm_factor=617.6337, grad_norm=1.5723\n",
      "Epoch 7: 137/256 - loss_mc=-0.0070, loss_t=0.0127, loss_r=0.0045, loss=-0.0052, norm_factor=618.2329, grad_norm=1.1100\n",
      "Epoch 7: 138/256 - loss_mc=-0.0065, loss_t=0.0124, loss_r=0.0051, loss=-0.0048, norm_factor=618.8372, grad_norm=1.2082\n",
      "Epoch 7: 139/256 - loss_mc=-0.0060, loss_t=0.0104, loss_r=0.0052, loss=-0.0044, norm_factor=619.4315, grad_norm=1.6078\n",
      "Epoch 7: 140/256 - loss_mc=-0.0066, loss_t=0.0137, loss_r=0.0053, loss=-0.0047, norm_factor=619.9979, grad_norm=1.3283\n",
      "Epoch 7: 141/256 - loss_mc=-0.0068, loss_t=0.0111, loss_r=0.0046, loss=-0.0052, norm_factor=620.5610, grad_norm=1.2306\n",
      "Epoch 7: 142/256 - loss_mc=-0.0065, loss_t=0.0121, loss_r=0.0049, loss=-0.0048, norm_factor=621.1250, grad_norm=1.7447\n",
      "Epoch 7: 143/256 - loss_mc=-0.0060, loss_t=0.0144, loss_r=0.0054, loss=-0.0040, norm_factor=621.6841, grad_norm=1.7217\n",
      "Epoch 7: 144/256 - loss_mc=-0.0069, loss_t=0.0117, loss_r=0.0042, loss=-0.0053, norm_factor=622.2107, grad_norm=1.3369\n",
      "Epoch 7: 145/256 - loss_mc=-0.0067, loss_t=0.0111, loss_r=0.0048, loss=-0.0051, norm_factor=622.7450, grad_norm=1.4321\n",
      "Epoch 7: 146/256 - loss_mc=-0.0057, loss_t=0.1180, loss_r=0.0053, loss=0.0066, norm_factor=623.2863, grad_norm=2.5699\n",
      "Epoch 7: 147/256 - loss_mc=-0.0064, loss_t=0.0127, loss_r=0.0052, loss=-0.0046, norm_factor=623.8026, grad_norm=1.3039\n",
      "Epoch 7: 148/256 - loss_mc=-0.0064, loss_t=0.0142, loss_r=0.0050, loss=-0.0044, norm_factor=624.3115, grad_norm=1.9388\n",
      "Epoch 7: 149/256 - loss_mc=-0.0067, loss_t=0.0136, loss_r=0.0042, loss=-0.0049, norm_factor=624.8187, grad_norm=0.7567\n",
      "Epoch 7: 150/256 - loss_mc=-0.0062, loss_t=0.0202, loss_r=0.0056, loss=-0.0036, norm_factor=625.3459, grad_norm=1.6204\n",
      "Epoch 7: 151/256 - loss_mc=-0.0062, loss_t=0.0201, loss_r=0.0051, loss=-0.0037, norm_factor=625.8585, grad_norm=1.6408\n",
      "Epoch 7: 152/256 - loss_mc=-0.0061, loss_t=0.0162, loss_r=0.0047, loss=-0.0040, norm_factor=626.3492, grad_norm=1.2405\n",
      "Epoch 7: 153/256 - loss_mc=-0.0059, loss_t=0.0140, loss_r=0.0054, loss=-0.0039, norm_factor=626.8176, grad_norm=1.5275\n",
      "Epoch 7: 154/256 - loss_mc=-0.0047, loss_t=0.0150, loss_r=0.0061, loss=-0.0026, norm_factor=627.2604, grad_norm=1.2464\n",
      "Epoch 7: 155/256 - loss_mc=-0.0062, loss_t=0.0194, loss_r=0.0052, loss=-0.0037, norm_factor=627.6240, grad_norm=1.8233\n",
      "Epoch 7: 156/256 - loss_mc=-0.0052, loss_t=0.0146, loss_r=0.0064, loss=-0.0031, norm_factor=627.9877, grad_norm=1.3387\n",
      "Epoch 7: 157/256 - loss_mc=-0.0060, loss_t=0.0153, loss_r=0.0057, loss=-0.0039, norm_factor=628.3085, grad_norm=1.6299\n",
      "Epoch 7: 158/256 - loss_mc=-0.0064, loss_t=0.0142, loss_r=0.0049, loss=-0.0045, norm_factor=628.6149, grad_norm=1.7180\n",
      "Epoch 7: 159/256 - loss_mc=-0.0057, loss_t=0.0199, loss_r=0.0052, loss=-0.0032, norm_factor=628.9275, grad_norm=1.6757\n",
      "Epoch 7: 160/256 - loss_mc=-0.0063, loss_t=0.0120, loss_r=0.0062, loss=-0.0045, norm_factor=629.2169, grad_norm=1.3655\n",
      "Epoch 7: 161/256 - loss_mc=-0.0062, loss_t=0.0130, loss_r=0.0047, loss=-0.0044, norm_factor=629.5138, grad_norm=1.4182\n",
      "Epoch 7: 162/256 - loss_mc=-0.0062, loss_t=0.0119, loss_r=0.0048, loss=-0.0045, norm_factor=629.8087, grad_norm=1.3025\n",
      "Epoch 7: 163/256 - loss_mc=-0.0050, loss_t=0.0220, loss_r=0.0069, loss=-0.0021, norm_factor=630.1041, grad_norm=1.0734\n",
      "Epoch 7: 164/256 - loss_mc=-0.0065, loss_t=0.0129, loss_r=0.0048, loss=-0.0047, norm_factor=630.3435, grad_norm=1.3612\n",
      "Epoch 7: 165/256 - loss_mc=-0.0065, loss_t=0.0125, loss_r=0.0044, loss=-0.0048, norm_factor=630.6068, grad_norm=1.3068\n",
      "Epoch 7: 166/256 - loss_mc=-0.0069, loss_t=0.0122, loss_r=0.0043, loss=-0.0052, norm_factor=630.8895, grad_norm=1.2838\n",
      "Epoch 7: 167/256 - loss_mc=-0.0070, loss_t=0.0092, loss_r=0.0040, loss=-0.0057, norm_factor=631.1996, grad_norm=1.0469\n",
      "Epoch 7: 168/256 - loss_mc=-0.0063, loss_t=0.0125, loss_r=0.0053, loss=-0.0045, norm_factor=631.5433, grad_norm=1.0608\n",
      "Epoch 7: 169/256 - loss_mc=-0.0055, loss_t=0.0127, loss_r=0.0054, loss=-0.0037, norm_factor=631.8823, grad_norm=1.4106\n",
      "Epoch 7: 170/256 - loss_mc=-0.0065, loss_t=0.0130, loss_r=0.0043, loss=-0.0048, norm_factor=632.1884, grad_norm=0.9798\n",
      "Epoch 7: 171/256 - loss_mc=-0.0067, loss_t=0.0118, loss_r=0.0042, loss=-0.0051, norm_factor=632.5091, grad_norm=1.3466\n",
      "Epoch 7: 172/256 - loss_mc=-0.0064, loss_t=0.0108, loss_r=0.0052, loss=-0.0048, norm_factor=632.8489, grad_norm=0.8970\n",
      "Epoch 7: 173/256 - loss_mc=-0.0065, loss_t=0.0124, loss_r=0.0048, loss=-0.0048, norm_factor=633.1938, grad_norm=1.2135\n",
      "Epoch 7: 174/256 - loss_mc=-0.0053, loss_t=0.0114, loss_r=0.0060, loss=-0.0035, norm_factor=633.5541, grad_norm=0.9643\n",
      "Epoch 7: 175/256 - loss_mc=-0.0074, loss_t=0.0091, loss_r=0.0038, loss=-0.0061, norm_factor=633.8591, grad_norm=0.9890\n",
      "Epoch 7: 176/256 - loss_mc=-0.0065, loss_t=0.0110, loss_r=0.0073, loss=-0.0046, norm_factor=634.2163, grad_norm=1.3512\n",
      "Epoch 7: 177/256 - loss_mc=-0.0069, loss_t=0.0092, loss_r=0.0041, loss=-0.0056, norm_factor=634.5865, grad_norm=0.9769\n",
      "Epoch 7: 178/256 - loss_mc=-0.0064, loss_t=0.0101, loss_r=0.0044, loss=-0.0049, norm_factor=634.9854, grad_norm=1.4547\n",
      "Epoch 7: 179/256 - loss_mc=-0.0066, loss_t=0.0109, loss_r=0.0045, loss=-0.0051, norm_factor=635.3835, grad_norm=0.7890\n",
      "Epoch 7: 180/256 - loss_mc=-0.0061, loss_t=0.0144, loss_r=0.0048, loss=-0.0042, norm_factor=635.7849, grad_norm=1.0486\n",
      "Epoch 7: 181/256 - loss_mc=-0.0064, loss_t=0.0127, loss_r=0.0044, loss=-0.0047, norm_factor=636.1689, grad_norm=1.0075\n",
      "Epoch 7: 182/256 - loss_mc=-0.0066, loss_t=0.0111, loss_r=0.0040, loss=-0.0051, norm_factor=636.5582, grad_norm=1.3041\n",
      "Epoch 7: 183/256 - loss_mc=-0.0060, loss_t=0.0114, loss_r=0.0053, loss=-0.0044, norm_factor=636.9625, grad_norm=1.2185\n",
      "Epoch 7: 184/256 - loss_mc=-0.0062, loss_t=0.0111, loss_r=0.0060, loss=-0.0045, norm_factor=637.3489, grad_norm=1.2395\n",
      "Epoch 7: 185/256 - loss_mc=-0.0063, loss_t=0.0178, loss_r=0.0041, loss=-0.0041, norm_factor=637.7269, grad_norm=1.0724\n",
      "Epoch 7: 186/256 - loss_mc=-0.0068, loss_t=0.0117, loss_r=0.0039, loss=-0.0053, norm_factor=638.1008, grad_norm=1.2143\n",
      "Epoch 7: 187/256 - loss_mc=-0.0067, loss_t=0.0115, loss_r=0.0041, loss=-0.0051, norm_factor=638.4952, grad_norm=1.8173\n",
      "Epoch 7: 188/256 - loss_mc=-0.0070, loss_t=0.0096, loss_r=0.0042, loss=-0.0057, norm_factor=638.9094, grad_norm=1.1441\n",
      "Epoch 7: 189/256 - loss_mc=-0.0061, loss_t=0.0113, loss_r=0.0054, loss=-0.0044, norm_factor=639.3525, grad_norm=1.8628\n",
      "Epoch 7: 190/256 - loss_mc=-0.0063, loss_t=0.0159, loss_r=0.0051, loss=-0.0042, norm_factor=639.7763, grad_norm=1.3897\n",
      "Epoch 7: 191/256 - loss_mc=-0.0066, loss_t=0.0112, loss_r=0.0040, loss=-0.0051, norm_factor=640.1953, grad_norm=1.5044\n",
      "Epoch 7: 192/256 - loss_mc=-0.0063, loss_t=0.0101, loss_r=0.0045, loss=-0.0048, norm_factor=640.6257, grad_norm=1.4793\n",
      "Epoch 7: 193/256 - loss_mc=-0.0068, loss_t=0.0100, loss_r=0.0047, loss=-0.0053, norm_factor=641.0582, grad_norm=1.2406\n",
      "Epoch 7: 194/256 - loss_mc=-0.0065, loss_t=0.0122, loss_r=0.0044, loss=-0.0048, norm_factor=641.4974, grad_norm=2.0044\n",
      "Epoch 7: 195/256 - loss_mc=-0.0067, loss_t=0.0118, loss_r=0.0044, loss=-0.0051, norm_factor=641.9366, grad_norm=1.2828\n",
      "Epoch 7: 196/256 - loss_mc=-0.0070, loss_t=0.0110, loss_r=0.0039, loss=-0.0055, norm_factor=642.3822, grad_norm=2.2238\n",
      "Epoch 7: 197/256 - loss_mc=-0.0067, loss_t=0.0117, loss_r=0.0043, loss=-0.0051, norm_factor=642.8474, grad_norm=1.2049\n",
      "Epoch 7: 198/256 - loss_mc=-0.0068, loss_t=0.0094, loss_r=0.0050, loss=-0.0053, norm_factor=643.3166, grad_norm=1.5181\n",
      "Epoch 7: 199/256 - loss_mc=-0.0062, loss_t=0.0149, loss_r=0.0050, loss=-0.0042, norm_factor=643.7925, grad_norm=1.0796\n",
      "Epoch 7: 200/256 - loss_mc=-0.0064, loss_t=0.0124, loss_r=0.0046, loss=-0.0047, norm_factor=644.2507, grad_norm=1.8383\n",
      "Epoch 7: 201/256 - loss_mc=-0.0068, loss_t=0.0087, loss_r=0.0040, loss=-0.0055, norm_factor=644.7062, grad_norm=0.7453\n",
      "Epoch 7: 202/256 - loss_mc=-0.0065, loss_t=0.0105, loss_r=0.0045, loss=-0.0050, norm_factor=645.1817, grad_norm=1.2815\n",
      "Epoch 7: 203/256 - loss_mc=-0.0068, loss_t=0.0099, loss_r=0.0044, loss=-0.0053, norm_factor=645.6556, grad_norm=1.1558\n",
      "Epoch 7: 204/256 - loss_mc=-0.0071, loss_t=0.0149, loss_r=0.0040, loss=-0.0052, norm_factor=646.1423, grad_norm=1.2952\n",
      "Epoch 7: 205/256 - loss_mc=-0.0071, loss_t=0.0112, loss_r=0.0034, loss=-0.0056, norm_factor=646.6476, grad_norm=1.5616\n",
      "Epoch 7: 206/256 - loss_mc=-0.0066, loss_t=0.0123, loss_r=0.0044, loss=-0.0049, norm_factor=647.1696, grad_norm=1.3112\n",
      "Epoch 7: 207/256 - loss_mc=-0.0071, loss_t=0.0096, loss_r=0.0037, loss=-0.0058, norm_factor=647.6914, grad_norm=1.2650\n",
      "Epoch 7: 208/256 - loss_mc=-0.0069, loss_t=0.0100, loss_r=0.0042, loss=-0.0055, norm_factor=648.2367, grad_norm=1.0955\n",
      "Epoch 7: 209/256 - loss_mc=-0.0065, loss_t=0.0138, loss_r=0.0042, loss=-0.0047, norm_factor=648.7935, grad_norm=1.9304\n",
      "Epoch 7: 210/256 - loss_mc=-0.0070, loss_t=0.0102, loss_r=0.0040, loss=-0.0056, norm_factor=649.3419, grad_norm=1.0719\n",
      "Epoch 7: 211/256 - loss_mc=-0.0061, loss_t=0.0151, loss_r=0.0055, loss=-0.0041, norm_factor=649.9122, grad_norm=1.5460\n",
      "Epoch 7: 212/256 - loss_mc=-0.0069, loss_t=0.0147, loss_r=0.0036, loss=-0.0050, norm_factor=650.4529, grad_norm=1.7496\n",
      "Epoch 7: 213/256 - loss_mc=-0.0068, loss_t=0.0150, loss_r=0.0039, loss=-0.0049, norm_factor=650.9977, grad_norm=1.4804\n",
      "Epoch 7: 214/256 - loss_mc=-0.0070, loss_t=0.0108, loss_r=0.0042, loss=-0.0055, norm_factor=651.5336, grad_norm=1.5488\n",
      "Epoch 7: 215/256 - loss_mc=-0.0070, loss_t=0.0090, loss_r=0.0041, loss=-0.0056, norm_factor=652.0785, grad_norm=0.9291\n",
      "Epoch 7: 216/256 - loss_mc=-0.0057, loss_t=0.0173, loss_r=0.0054, loss=-0.0034, norm_factor=652.6323, grad_norm=2.1344\n",
      "Epoch 7: 217/256 - loss_mc=-0.0052, loss_t=0.0148, loss_r=0.0048, loss=-0.0033, norm_factor=653.1395, grad_norm=1.5910\n",
      "Epoch 7: 218/256 - loss_mc=-0.0070, loss_t=0.0117, loss_r=0.0039, loss=-0.0054, norm_factor=653.5771, grad_norm=1.3964\n",
      "Epoch 7: 219/256 - loss_mc=-0.0069, loss_t=0.0125, loss_r=0.0040, loss=-0.0052, norm_factor=654.0327, grad_norm=1.5152\n",
      "Epoch 7: 220/256 - loss_mc=-0.0066, loss_t=0.0156, loss_r=0.0046, loss=-0.0046, norm_factor=654.4990, grad_norm=1.7203\n",
      "Epoch 7: 221/256 - loss_mc=-0.0053, loss_t=0.0149, loss_r=0.0097, loss=-0.0028, norm_factor=654.9695, grad_norm=1.1677\n",
      "Epoch 7: 222/256 - loss_mc=-0.0069, loss_t=0.0116, loss_r=0.0040, loss=-0.0053, norm_factor=655.3735, grad_norm=1.8072\n",
      "Epoch 7: 223/256 - loss_mc=-0.0067, loss_t=0.0110, loss_r=0.0039, loss=-0.0052, norm_factor=655.7953, grad_norm=1.1429\n",
      "Epoch 7: 224/256 - loss_mc=-0.0064, loss_t=0.0127, loss_r=0.0044, loss=-0.0047, norm_factor=656.2266, grad_norm=1.4200\n",
      "Epoch 7: 225/256 - loss_mc=-0.0062, loss_t=0.0113, loss_r=0.0048, loss=-0.0046, norm_factor=656.6671, grad_norm=0.9565\n",
      "Epoch 7: 226/256 - loss_mc=-0.0067, loss_t=0.0118, loss_r=0.0042, loss=-0.0051, norm_factor=657.0878, grad_norm=1.7088\n",
      "Epoch 7: 227/256 - loss_mc=-0.0070, loss_t=0.0120, loss_r=0.0038, loss=-0.0054, norm_factor=657.5203, grad_norm=1.4084\n",
      "Epoch 7: 228/256 - loss_mc=-0.0064, loss_t=0.0114, loss_r=0.0049, loss=-0.0047, norm_factor=657.9754, grad_norm=1.2474\n",
      "Epoch 7: 229/256 - loss_mc=-0.0074, loss_t=0.0092, loss_r=0.0034, loss=-0.0062, norm_factor=658.4164, grad_norm=0.9010\n",
      "Epoch 7: 230/256 - loss_mc=-0.0069, loss_t=0.0087, loss_r=0.0041, loss=-0.0056, norm_factor=658.9001, grad_norm=1.2707\n",
      "Epoch 7: 231/256 - loss_mc=-0.0069, loss_t=0.0106, loss_r=0.0042, loss=-0.0054, norm_factor=659.3950, grad_norm=1.2222\n",
      "Epoch 7: 232/256 - loss_mc=-0.0068, loss_t=0.0113, loss_r=0.0045, loss=-0.0053, norm_factor=659.8967, grad_norm=1.1799\n",
      "Epoch 7: 233/256 - loss_mc=-0.0066, loss_t=0.0102, loss_r=0.0053, loss=-0.0051, norm_factor=660.4148, grad_norm=1.4828\n",
      "Epoch 7: 234/256 - loss_mc=-0.0066, loss_t=0.0113, loss_r=0.0043, loss=-0.0050, norm_factor=660.9307, grad_norm=1.5544\n",
      "Epoch 7: 235/256 - loss_mc=-0.0071, loss_t=0.0119, loss_r=0.0036, loss=-0.0056, norm_factor=661.4399, grad_norm=1.4412\n",
      "Epoch 7: 236/256 - loss_mc=-0.0069, loss_t=0.0116, loss_r=0.0043, loss=-0.0053, norm_factor=661.9662, grad_norm=1.7258\n",
      "Epoch 7: 237/256 - loss_mc=-0.0065, loss_t=0.0101, loss_r=0.0046, loss=-0.0050, norm_factor=662.4926, grad_norm=1.9264\n",
      "Epoch 7: 238/256 - loss_mc=-0.0063, loss_t=0.0115, loss_r=0.0042, loss=-0.0047, norm_factor=663.0034, grad_norm=1.2107\n",
      "Epoch 7: 239/256 - loss_mc=-0.0067, loss_t=0.0099, loss_r=0.0041, loss=-0.0053, norm_factor=663.4957, grad_norm=1.4403\n",
      "Epoch 7: 240/256 - loss_mc=-0.0063, loss_t=0.0167, loss_r=0.0041, loss=-0.0042, norm_factor=663.9890, grad_norm=1.4479\n",
      "Epoch 7: 241/256 - loss_mc=-0.0066, loss_t=0.0136, loss_r=0.0043, loss=-0.0048, norm_factor=664.4686, grad_norm=1.3035\n",
      "Epoch 7: 242/256 - loss_mc=-0.0073, loss_t=0.0121, loss_r=0.0032, loss=-0.0058, norm_factor=664.9450, grad_norm=1.3004\n",
      "Epoch 7: 243/256 - loss_mc=-0.0065, loss_t=0.0147, loss_r=0.0046, loss=-0.0046, norm_factor=665.4559, grad_norm=1.2456\n",
      "Epoch 7: 244/256 - loss_mc=-0.0066, loss_t=0.0129, loss_r=0.0039, loss=-0.0049, norm_factor=665.9599, grad_norm=1.3758\n",
      "Epoch 7: 245/256 - loss_mc=-0.0072, loss_t=0.0087, loss_r=0.0034, loss=-0.0060, norm_factor=666.4598, grad_norm=1.0516\n",
      "Epoch 7: 246/256 - loss_mc=-0.0063, loss_t=0.0091, loss_r=0.0036, loss=-0.0050, norm_factor=666.9910, grad_norm=1.1275\n",
      "Epoch 7: 247/256 - loss_mc=-0.0064, loss_t=0.0098, loss_r=0.0042, loss=-0.0050, norm_factor=667.5002, grad_norm=1.2369\n",
      "Epoch 7: 248/256 - loss_mc=-0.0068, loss_t=0.0099, loss_r=0.0037, loss=-0.0054, norm_factor=667.9889, grad_norm=1.1940\n",
      "Epoch 7: 249/256 - loss_mc=-0.0066, loss_t=0.0120, loss_r=0.0039, loss=-0.0050, norm_factor=668.4851, grad_norm=1.4650\n",
      "Epoch 7: 250/256 - loss_mc=-0.0072, loss_t=0.0099, loss_r=0.0031, loss=-0.0059, norm_factor=668.9771, grad_norm=0.9211\n",
      "Epoch 7: 251/256 - loss_mc=-0.0065, loss_t=0.0133, loss_r=0.0042, loss=-0.0047, norm_factor=669.4883, grad_norm=1.7070\n",
      "Epoch 7: 252/256 - loss_mc=-0.0070, loss_t=0.0098, loss_r=0.0037, loss=-0.0056, norm_factor=669.9793, grad_norm=0.6538\n",
      "Epoch 7: 253/256 - loss_mc=-0.0067, loss_t=0.0101, loss_r=0.0044, loss=-0.0052, norm_factor=670.4838, grad_norm=1.7485\n",
      "Epoch 7: 254/256 - loss_mc=-0.0069, loss_t=0.0100, loss_r=0.0037, loss=-0.0055, norm_factor=670.9894, grad_norm=0.8243\n",
      "Epoch 7: 255/256 - loss_mc=-0.0057, loss_t=0.0138, loss_r=0.0045, loss=-0.0039, norm_factor=671.5076, grad_norm=1.8033\n",
      "Epoch 7: 256/256 - loss_mc=-0.0065, loss_t=0.0097, loss_r=0.0043, loss=-0.0051, norm_factor=671.9759, grad_norm=0.8264\n",
      "Epoch 8: 1/256 - loss_mc=-0.0060, loss_t=0.0102, loss_r=0.0050, loss=-0.0045, norm_factor=672.4355, grad_norm=1.6141\n",
      "Epoch 8: 2/256 - loss_mc=-0.0070, loss_t=0.0103, loss_r=0.0037, loss=-0.0056, norm_factor=672.8625, grad_norm=0.8315\n",
      "Epoch 8: 3/256 - loss_mc=-0.0072, loss_t=0.0120, loss_r=0.0038, loss=-0.0056, norm_factor=673.3103, grad_norm=1.6208\n",
      "Epoch 8: 4/256 - loss_mc=-0.0062, loss_t=0.0107, loss_r=0.0042, loss=-0.0047, norm_factor=673.7870, grad_norm=1.3508\n",
      "Epoch 8: 5/256 - loss_mc=-0.0071, loss_t=0.0097, loss_r=0.0037, loss=-0.0058, norm_factor=674.2354, grad_norm=2.0558\n",
      "Epoch 8: 6/256 - loss_mc=-0.0064, loss_t=0.0128, loss_r=0.0045, loss=-0.0046, norm_factor=674.7052, grad_norm=1.2658\n",
      "Epoch 8: 7/256 - loss_mc=-0.0070, loss_t=0.0101, loss_r=0.0038, loss=-0.0056, norm_factor=675.1593, grad_norm=1.4629\n",
      "Epoch 8: 8/256 - loss_mc=-0.0065, loss_t=0.0095, loss_r=0.0039, loss=-0.0052, norm_factor=675.6351, grad_norm=1.0383\n",
      "Epoch 8: 9/256 - loss_mc=-0.0073, loss_t=0.0086, loss_r=0.0034, loss=-0.0062, norm_factor=676.1094, grad_norm=0.7443\n",
      "Epoch 8: 10/256 - loss_mc=-0.0066, loss_t=0.0105, loss_r=0.0042, loss=-0.0051, norm_factor=676.6197, grad_norm=1.1165\n",
      "Epoch 8: 11/256 - loss_mc=-0.0072, loss_t=0.0105, loss_r=0.0036, loss=-0.0058, norm_factor=677.1184, grad_norm=1.2325\n",
      "Epoch 8: 12/256 - loss_mc=-0.0072, loss_t=0.0090, loss_r=0.0036, loss=-0.0060, norm_factor=677.6395, grad_norm=0.8368\n",
      "Epoch 8: 13/256 - loss_mc=-0.0067, loss_t=0.0129, loss_r=0.0041, loss=-0.0050, norm_factor=678.1884, grad_norm=1.3821\n",
      "Epoch 8: 14/256 - loss_mc=-0.0068, loss_t=0.0098, loss_r=0.0040, loss=-0.0054, norm_factor=678.7390, grad_norm=0.9443\n",
      "Epoch 8: 15/256 - loss_mc=-0.0068, loss_t=0.0082, loss_r=0.0039, loss=-0.0056, norm_factor=679.2945, grad_norm=0.7813\n",
      "Epoch 8: 16/256 - loss_mc=-0.0069, loss_t=0.0104, loss_r=0.0036, loss=-0.0055, norm_factor=679.8523, grad_norm=1.1754\n",
      "Epoch 8: 17/256 - loss_mc=-0.0067, loss_t=0.0112, loss_r=0.0040, loss=-0.0052, norm_factor=680.4168, grad_norm=1.3560\n",
      "Epoch 8: 18/256 - loss_mc=-0.0068, loss_t=0.0106, loss_r=0.0042, loss=-0.0053, norm_factor=680.9777, grad_norm=1.2647\n",
      "Epoch 8: 19/256 - loss_mc=-0.0058, loss_t=0.0113, loss_r=0.0045, loss=-0.0043, norm_factor=681.5438, grad_norm=1.3968\n",
      "Epoch 8: 20/256 - loss_mc=-0.0072, loss_t=0.0089, loss_r=0.0033, loss=-0.0060, norm_factor=682.0560, grad_norm=1.1578\n",
      "Epoch 8: 21/256 - loss_mc=-0.0071, loss_t=0.0092, loss_r=0.0033, loss=-0.0058, norm_factor=682.5927, grad_norm=1.7011\n",
      "Epoch 8: 22/256 - loss_mc=-0.0071, loss_t=0.0089, loss_r=0.0031, loss=-0.0059, norm_factor=683.1476, grad_norm=0.8508\n",
      "Epoch 8: 23/256 - loss_mc=-0.0062, loss_t=0.0133, loss_r=0.0046, loss=-0.0044, norm_factor=683.7151, grad_norm=2.1348\n",
      "Epoch 8: 24/256 - loss_mc=-0.0072, loss_t=0.0109, loss_r=0.0032, loss=-0.0058, norm_factor=684.2572, grad_norm=0.9667\n",
      "Epoch 8: 25/256 - loss_mc=-0.0067, loss_t=0.0096, loss_r=0.0038, loss=-0.0054, norm_factor=684.8268, grad_norm=1.5145\n",
      "Epoch 8: 26/256 - loss_mc=-0.0069, loss_t=0.0095, loss_r=0.0034, loss=-0.0056, norm_factor=685.3977, grad_norm=0.4942\n",
      "Epoch 8: 27/256 - loss_mc=-0.0066, loss_t=0.0092, loss_r=0.0043, loss=-0.0052, norm_factor=685.9697, grad_norm=1.5000\n",
      "Epoch 8: 28/256 - loss_mc=-0.0069, loss_t=0.0089, loss_r=0.0039, loss=-0.0056, norm_factor=686.5288, grad_norm=0.6862\n",
      "Epoch 8: 29/256 - loss_mc=-0.0065, loss_t=0.0093, loss_r=0.0044, loss=-0.0051, norm_factor=687.0941, grad_norm=2.0257\n",
      "Epoch 8: 30/256 - loss_mc=-0.0064, loss_t=0.0110, loss_r=0.0041, loss=-0.0048, norm_factor=687.6469, grad_norm=1.4429\n",
      "Epoch 8: 31/256 - loss_mc=-0.0063, loss_t=0.0095, loss_r=0.0040, loss=-0.0050, norm_factor=688.1783, grad_norm=1.6620\n",
      "Epoch 8: 32/256 - loss_mc=-0.0068, loss_t=0.0117, loss_r=0.0038, loss=-0.0052, norm_factor=688.6832, grad_norm=1.5419\n",
      "Epoch 8: 33/256 - loss_mc=-0.0068, loss_t=0.0076, loss_r=0.0037, loss=-0.0057, norm_factor=689.1921, grad_norm=1.4600\n",
      "Epoch 8: 34/256 - loss_mc=-0.0068, loss_t=0.0101, loss_r=0.0041, loss=-0.0053, norm_factor=689.7098, grad_norm=1.5951\n",
      "Epoch 8: 35/256 - loss_mc=-0.0070, loss_t=0.0093, loss_r=0.0034, loss=-0.0057, norm_factor=690.2310, grad_norm=1.3409\n",
      "Epoch 8: 36/256 - loss_mc=-0.0070, loss_t=0.0090, loss_r=0.0036, loss=-0.0058, norm_factor=690.7655, grad_norm=1.0030\n",
      "Epoch 8: 37/256 - loss_mc=-0.0061, loss_t=0.0132, loss_r=0.0045, loss=-0.0044, norm_factor=691.3160, grad_norm=2.2970\n",
      "Epoch 8: 38/256 - loss_mc=-0.0073, loss_t=0.0086, loss_r=0.0032, loss=-0.0061, norm_factor=691.8254, grad_norm=1.4056\n",
      "Epoch 8: 39/256 - loss_mc=-0.0064, loss_t=0.0103, loss_r=0.0043, loss=-0.0050, norm_factor=692.3706, grad_norm=1.7615\n",
      "Epoch 8: 40/256 - loss_mc=-0.0057, loss_t=0.0120, loss_r=0.0044, loss=-0.0041, norm_factor=692.8906, grad_norm=0.8632\n",
      "Epoch 8: 41/256 - loss_mc=-0.0062, loss_t=0.0109, loss_r=0.0043, loss=-0.0047, norm_factor=693.3600, grad_norm=1.3802\n",
      "Epoch 8: 42/256 - loss_mc=-0.0069, loss_t=0.0095, loss_r=0.0037, loss=-0.0056, norm_factor=693.8007, grad_norm=1.1025\n",
      "Epoch 8: 43/256 - loss_mc=-0.0068, loss_t=0.0124, loss_r=0.0037, loss=-0.0052, norm_factor=694.2605, grad_norm=0.9923\n",
      "Epoch 8: 44/256 - loss_mc=-0.0069, loss_t=0.0113, loss_r=0.0035, loss=-0.0055, norm_factor=694.7219, grad_norm=0.9224\n",
      "Epoch 8: 45/256 - loss_mc=-0.0067, loss_t=0.0106, loss_r=0.0041, loss=-0.0052, norm_factor=695.1984, grad_norm=0.9124\n",
      "Epoch 8: 46/256 - loss_mc=-0.0069, loss_t=0.0084, loss_r=0.0039, loss=-0.0057, norm_factor=695.6708, grad_norm=1.0427\n",
      "Epoch 8: 47/256 - loss_mc=-0.0066, loss_t=0.0094, loss_r=0.0042, loss=-0.0052, norm_factor=696.1592, grad_norm=1.1770\n",
      "Epoch 8: 48/256 - loss_mc=-0.0071, loss_t=0.0078, loss_r=0.0032, loss=-0.0060, norm_factor=696.6442, grad_norm=0.6352\n",
      "Epoch 8: 49/256 - loss_mc=-0.0056, loss_t=0.0117, loss_r=0.0043, loss=-0.0040, norm_factor=697.1511, grad_norm=1.3016\n",
      "Epoch 8: 50/256 - loss_mc=-0.0066, loss_t=0.0092, loss_r=0.0035, loss=-0.0053, norm_factor=697.5956, grad_norm=1.1274\n",
      "Epoch 8: 51/256 - loss_mc=-0.0064, loss_t=0.0101, loss_r=0.0044, loss=-0.0049, norm_factor=698.0289, grad_norm=1.4963\n",
      "Epoch 8: 52/256 - loss_mc=-0.0068, loss_t=0.0089, loss_r=0.0035, loss=-0.0056, norm_factor=698.4478, grad_norm=0.9799\n",
      "Epoch 8: 53/256 - loss_mc=-0.0067, loss_t=0.0098, loss_r=0.0037, loss=-0.0053, norm_factor=698.8800, grad_norm=1.1418\n",
      "Epoch 8: 54/256 - loss_mc=-0.0069, loss_t=0.0091, loss_r=0.0035, loss=-0.0057, norm_factor=699.3177, grad_norm=1.2888\n",
      "Epoch 8: 55/256 - loss_mc=-0.0068, loss_t=0.0092, loss_r=0.0040, loss=-0.0055, norm_factor=699.7737, grad_norm=0.8284\n",
      "Epoch 8: 56/256 - loss_mc=-0.0067, loss_t=0.0118, loss_r=0.0038, loss=-0.0052, norm_factor=700.2454, grad_norm=1.7729\n",
      "Epoch 8: 57/256 - loss_mc=-0.0060, loss_t=0.0114, loss_r=0.0036, loss=-0.0045, norm_factor=700.7179, grad_norm=1.0172\n",
      "Epoch 8: 58/256 - loss_mc=-0.0069, loss_t=0.0097, loss_r=0.0035, loss=-0.0056, norm_factor=701.1558, grad_norm=1.9665\n",
      "Epoch 8: 59/256 - loss_mc=-0.0067, loss_t=0.0079, loss_r=0.0036, loss=-0.0056, norm_factor=701.6060, grad_norm=1.1810\n",
      "Epoch 8: 60/256 - loss_mc=-0.0050, loss_t=0.0105, loss_r=0.0044, loss=-0.0035, norm_factor=702.0624, grad_norm=1.4777\n",
      "Epoch 8: 61/256 - loss_mc=-0.0068, loss_t=0.0115, loss_r=0.0037, loss=-0.0053, norm_factor=702.4226, grad_norm=1.6269\n",
      "Epoch 8: 62/256 - loss_mc=-0.0072, loss_t=0.0086, loss_r=0.0031, loss=-0.0061, norm_factor=702.8027, grad_norm=0.9308\n",
      "Epoch 8: 63/256 - loss_mc=-0.0071, loss_t=0.0071, loss_r=0.0037, loss=-0.0060, norm_factor=703.2220, grad_norm=1.5241\n",
      "Epoch 8: 64/256 - loss_mc=-0.0067, loss_t=0.0091, loss_r=0.0037, loss=-0.0055, norm_factor=703.6604, grad_norm=1.2998\n",
      "Epoch 8: 65/256 - loss_mc=-0.0064, loss_t=0.0139, loss_r=0.0035, loss=-0.0047, norm_factor=704.1085, grad_norm=1.4634\n",
      "Epoch 8: 66/256 - loss_mc=-0.0066, loss_t=0.0118, loss_r=0.0033, loss=-0.0051, norm_factor=704.5559, grad_norm=1.6787\n",
      "Epoch 8: 67/256 - loss_mc=-0.0065, loss_t=0.0091, loss_r=0.0037, loss=-0.0052, norm_factor=705.0026, grad_norm=0.8272\n",
      "Epoch 8: 68/256 - loss_mc=-0.0062, loss_t=0.0192, loss_r=0.0043, loss=-0.0038, norm_factor=705.4443, grad_norm=2.1438\n",
      "Epoch 8: 69/256 - loss_mc=-0.0069, loss_t=0.0076, loss_r=0.0037, loss=-0.0058, norm_factor=705.8541, grad_norm=0.7869\n",
      "Epoch 8: 70/256 - loss_mc=-0.0066, loss_t=0.0094, loss_r=0.0046, loss=-0.0052, norm_factor=706.2878, grad_norm=1.8214\n",
      "Epoch 8: 71/256 - loss_mc=-0.0068, loss_t=0.0119, loss_r=0.0034, loss=-0.0053, norm_factor=706.7130, grad_norm=1.4212\n",
      "Epoch 8: 72/256 - loss_mc=-0.0064, loss_t=0.0123, loss_r=0.0042, loss=-0.0047, norm_factor=707.1494, grad_norm=1.3950\n",
      "Epoch 8: 73/256 - loss_mc=-0.0065, loss_t=0.0101, loss_r=0.0041, loss=-0.0051, norm_factor=707.5673, grad_norm=1.8390\n",
      "Epoch 8: 74/256 - loss_mc=-0.0067, loss_t=0.0101, loss_r=0.0039, loss=-0.0053, norm_factor=707.9916, grad_norm=1.4296\n",
      "Epoch 8: 75/256 - loss_mc=-0.0068, loss_t=0.0105, loss_r=0.0041, loss=-0.0053, norm_factor=708.4307, grad_norm=1.7392\n",
      "Epoch 8: 76/256 - loss_mc=-0.0065, loss_t=0.0103, loss_r=0.0041, loss=-0.0050, norm_factor=708.8835, grad_norm=1.3066\n",
      "Epoch 8: 77/256 - loss_mc=-0.0063, loss_t=0.0129, loss_r=0.0041, loss=-0.0046, norm_factor=709.3221, grad_norm=2.1072\n",
      "Epoch 8: 78/256 - loss_mc=-0.0066, loss_t=0.0107, loss_r=0.0036, loss=-0.0051, norm_factor=709.7405, grad_norm=1.2317\n",
      "Epoch 8: 79/256 - loss_mc=-0.0057, loss_t=0.0116, loss_r=0.0044, loss=-0.0041, norm_factor=710.1578, grad_norm=1.6765\n",
      "Epoch 8: 80/256 - loss_mc=-0.0067, loss_t=0.0122, loss_r=0.0039, loss=-0.0051, norm_factor=710.5264, grad_norm=1.7374\n",
      "Epoch 8: 81/256 - loss_mc=-0.0061, loss_t=0.0097, loss_r=0.0052, loss=-0.0046, norm_factor=710.9138, grad_norm=1.7206\n",
      "Epoch 8: 82/256 - loss_mc=-0.0068, loss_t=0.0106, loss_r=0.0036, loss=-0.0054, norm_factor=711.2683, grad_norm=1.5461\n",
      "Epoch 8: 83/256 - loss_mc=-0.0067, loss_t=0.0086, loss_r=0.0039, loss=-0.0054, norm_factor=711.6405, grad_norm=1.5420\n",
      "Epoch 8: 84/256 - loss_mc=-0.0063, loss_t=0.0136, loss_r=0.0045, loss=-0.0045, norm_factor=712.0320, grad_norm=1.4769\n",
      "Epoch 8: 85/256 - loss_mc=-0.0062, loss_t=0.0131, loss_r=0.0043, loss=-0.0044, norm_factor=712.4089, grad_norm=1.8885\n",
      "Epoch 8: 86/256 - loss_mc=-0.0069, loss_t=0.0095, loss_r=0.0034, loss=-0.0056, norm_factor=712.7709, grad_norm=1.8243\n",
      "Epoch 8: 87/256 - loss_mc=-0.0070, loss_t=0.0107, loss_r=0.0033, loss=-0.0056, norm_factor=713.1517, grad_norm=1.5828\n",
      "Epoch 8: 88/256 - loss_mc=-0.0060, loss_t=0.0140, loss_r=0.0045, loss=-0.0042, norm_factor=713.5581, grad_norm=1.9450\n",
      "Epoch 8: 89/256 - loss_mc=-0.0062, loss_t=0.0104, loss_r=0.0046, loss=-0.0047, norm_factor=713.9323, grad_norm=1.8165\n",
      "Epoch 8: 90/256 - loss_mc=-0.0061, loss_t=0.0118, loss_r=0.0040, loss=-0.0046, norm_factor=714.2842, grad_norm=2.0788\n",
      "Epoch 8: 91/256 - loss_mc=-0.0067, loss_t=0.0087, loss_r=0.0038, loss=-0.0054, norm_factor=714.6206, grad_norm=1.6299\n",
      "Epoch 8: 92/256 - loss_mc=-0.0063, loss_t=0.0114, loss_r=0.0039, loss=-0.0047, norm_factor=714.9735, grad_norm=1.5606\n",
      "Epoch 8: 93/256 - loss_mc=-0.0067, loss_t=0.0089, loss_r=0.0034, loss=-0.0055, norm_factor=715.3209, grad_norm=1.5568\n",
      "Epoch 8: 94/256 - loss_mc=-0.0066, loss_t=0.0113, loss_r=0.0041, loss=-0.0050, norm_factor=715.6812, grad_norm=1.5092\n",
      "Epoch 8: 95/256 - loss_mc=-0.0066, loss_t=0.0080, loss_r=0.0033, loss=-0.0054, norm_factor=716.0475, grad_norm=1.9202\n",
      "Epoch 8: 96/256 - loss_mc=-0.0054, loss_t=0.0131, loss_r=0.0039, loss=-0.0037, norm_factor=716.4109, grad_norm=1.5822\n",
      "Epoch 8: 97/256 - loss_mc=-0.0065, loss_t=0.0082, loss_r=0.0036, loss=-0.0053, norm_factor=716.7068, grad_norm=1.7533\n",
      "Epoch 8: 98/256 - loss_mc=-0.0064, loss_t=0.0119, loss_r=0.0039, loss=-0.0048, norm_factor=717.0178, grad_norm=1.1940\n",
      "Epoch 8: 99/256 - loss_mc=-0.0069, loss_t=0.0094, loss_r=0.0032, loss=-0.0056, norm_factor=717.3308, grad_norm=1.4052\n",
      "Epoch 8: 100/256 - loss_mc=-0.0066, loss_t=0.0079, loss_r=0.0037, loss=-0.0054, norm_factor=717.6696, grad_norm=1.6394\n",
      "Epoch 8: 101/256 - loss_mc=-0.0070, loss_t=0.0080, loss_r=0.0035, loss=-0.0058, norm_factor=718.0105, grad_norm=1.4919\n",
      "Epoch 8: 102/256 - loss_mc=-0.0063, loss_t=0.0080, loss_r=0.0041, loss=-0.0051, norm_factor=718.3896, grad_norm=1.0839\n",
      "Epoch 8: 103/256 - loss_mc=-0.0067, loss_t=0.0096, loss_r=0.0034, loss=-0.0054, norm_factor=718.7537, grad_norm=1.0652\n",
      "Epoch 8: 104/256 - loss_mc=-0.0058, loss_t=0.0098, loss_r=0.0039, loss=-0.0044, norm_factor=719.1321, grad_norm=0.9298\n",
      "Epoch 8: 105/256 - loss_mc=-0.0063, loss_t=0.0106, loss_r=0.0038, loss=-0.0048, norm_factor=719.4684, grad_norm=1.0640\n",
      "Epoch 8: 106/256 - loss_mc=-0.0067, loss_t=0.0082, loss_r=0.0036, loss=-0.0055, norm_factor=719.7865, grad_norm=0.9326\n",
      "Epoch 8: 107/256 - loss_mc=-0.0067, loss_t=0.0131, loss_r=0.0036, loss=-0.0050, norm_factor=720.1249, grad_norm=1.1081\n",
      "Epoch 8: 108/256 - loss_mc=-0.0071, loss_t=0.0077, loss_r=0.0035, loss=-0.0060, norm_factor=720.4768, grad_norm=1.2435\n",
      "Epoch 8: 109/256 - loss_mc=-0.0065, loss_t=0.0104, loss_r=0.0033, loss=-0.0052, norm_factor=720.8680, grad_norm=1.6631\n",
      "Epoch 8: 110/256 - loss_mc=-0.0068, loss_t=0.0079, loss_r=0.0036, loss=-0.0057, norm_factor=721.2621, grad_norm=0.7778\n",
      "Epoch 8: 111/256 - loss_mc=-0.0068, loss_t=0.0099, loss_r=0.0039, loss=-0.0054, norm_factor=721.6664, grad_norm=1.6557\n",
      "Epoch 8: 112/256 - loss_mc=-0.0067, loss_t=0.0085, loss_r=0.0039, loss=-0.0055, norm_factor=722.0849, grad_norm=1.0683\n",
      "Epoch 8: 113/256 - loss_mc=-0.0069, loss_t=0.0074, loss_r=0.0035, loss=-0.0058, norm_factor=722.5116, grad_norm=1.7222\n",
      "Epoch 8: 114/256 - loss_mc=-0.0071, loss_t=0.0080, loss_r=0.0034, loss=-0.0060, norm_factor=722.9554, grad_norm=0.9203\n",
      "Epoch 8: 115/256 - loss_mc=-0.0068, loss_t=0.0089, loss_r=0.0033, loss=-0.0056, norm_factor=723.4320, grad_norm=1.3874\n",
      "Epoch 8: 116/256 - loss_mc=-0.0060, loss_t=0.0107, loss_r=0.0042, loss=-0.0046, norm_factor=723.9194, grad_norm=1.5769\n",
      "Epoch 8: 117/256 - loss_mc=-0.0065, loss_t=0.0103, loss_r=0.0033, loss=-0.0052, norm_factor=724.3757, grad_norm=1.5546\n",
      "Epoch 8: 118/256 - loss_mc=-0.0065, loss_t=0.0107, loss_r=0.0039, loss=-0.0050, norm_factor=724.8246, grad_norm=1.4019\n",
      "Epoch 8: 119/256 - loss_mc=-0.0064, loss_t=0.0104, loss_r=0.0036, loss=-0.0050, norm_factor=725.2626, grad_norm=1.5124\n",
      "Epoch 8: 120/256 - loss_mc=-0.0065, loss_t=0.0129, loss_r=0.0041, loss=-0.0048, norm_factor=725.6825, grad_norm=1.6892\n",
      "Epoch 8: 121/256 - loss_mc=-0.0069, loss_t=0.0087, loss_r=0.0033, loss=-0.0057, norm_factor=726.0873, grad_norm=1.2384\n",
      "Epoch 8: 122/256 - loss_mc=-0.0064, loss_t=0.0106, loss_r=0.0038, loss=-0.0050, norm_factor=726.5078, grad_norm=1.6573\n",
      "Epoch 8: 123/256 - loss_mc=-0.0069, loss_t=0.0089, loss_r=0.0037, loss=-0.0056, norm_factor=726.9136, grad_norm=1.2068\n",
      "Epoch 8: 124/256 - loss_mc=-0.0064, loss_t=0.0107, loss_r=0.0038, loss=-0.0049, norm_factor=727.3400, grad_norm=1.3929\n",
      "Epoch 8: 125/256 - loss_mc=-0.0063, loss_t=0.0101, loss_r=0.0037, loss=-0.0049, norm_factor=727.7535, grad_norm=0.9574\n",
      "Epoch 8: 126/256 - loss_mc=-0.0067, loss_t=0.0094, loss_r=0.0033, loss=-0.0054, norm_factor=728.1516, grad_norm=1.5419\n",
      "Epoch 8: 127/256 - loss_mc=-0.0070, loss_t=0.0080, loss_r=0.0031, loss=-0.0059, norm_factor=728.5629, grad_norm=1.1793\n",
      "Epoch 8: 128/256 - loss_mc=-0.0067, loss_t=0.0107, loss_r=0.0034, loss=-0.0053, norm_factor=729.0010, grad_norm=1.3481\n",
      "Epoch 8: 129/256 - loss_mc=-0.0065, loss_t=0.0096, loss_r=0.0036, loss=-0.0052, norm_factor=729.4459, grad_norm=1.6428\n",
      "Epoch 8: 130/256 - loss_mc=-0.0058, loss_t=0.0091, loss_r=0.0038, loss=-0.0045, norm_factor=729.8947, grad_norm=1.4714\n",
      "Epoch 8: 131/256 - loss_mc=-0.0070, loss_t=0.0092, loss_r=0.0033, loss=-0.0057, norm_factor=730.2959, grad_norm=1.4799\n",
      "Epoch 8: 132/256 - loss_mc=-0.0068, loss_t=0.0096, loss_r=0.0033, loss=-0.0055, norm_factor=730.7194, grad_norm=1.1432\n",
      "Epoch 8: 133/256 - loss_mc=-0.0066, loss_t=0.0106, loss_r=0.0035, loss=-0.0052, norm_factor=731.1519, grad_norm=1.7466\n",
      "Epoch 8: 134/256 - loss_mc=-0.0070, loss_t=0.0077, loss_r=0.0033, loss=-0.0059, norm_factor=731.5792, grad_norm=1.0628\n",
      "Epoch 8: 135/256 - loss_mc=-0.0061, loss_t=0.0120, loss_r=0.0040, loss=-0.0046, norm_factor=732.0277, grad_norm=1.2648\n",
      "Epoch 8: 136/256 - loss_mc=-0.0067, loss_t=0.0099, loss_r=0.0038, loss=-0.0054, norm_factor=732.4437, grad_norm=1.5955\n",
      "Epoch 8: 137/256 - loss_mc=-0.0067, loss_t=0.0102, loss_r=0.0034, loss=-0.0054, norm_factor=732.8707, grad_norm=1.3294\n",
      "Epoch 8: 138/256 - loss_mc=-0.0059, loss_t=0.0087, loss_r=0.0038, loss=-0.0047, norm_factor=733.3113, grad_norm=1.2899\n",
      "Epoch 8: 139/256 - loss_mc=-0.0065, loss_t=0.0114, loss_r=0.0045, loss=-0.0049, norm_factor=733.7092, grad_norm=1.5014\n",
      "Epoch 8: 140/256 - loss_mc=-0.0070, loss_t=0.0089, loss_r=0.0032, loss=-0.0058, norm_factor=734.1090, grad_norm=1.1151\n",
      "Epoch 8: 141/256 - loss_mc=-0.0067, loss_t=0.0123, loss_r=0.0034, loss=-0.0052, norm_factor=734.5422, grad_norm=1.0373\n",
      "Epoch 8: 142/256 - loss_mc=-0.0069, loss_t=0.0081, loss_r=0.0035, loss=-0.0057, norm_factor=734.9827, grad_norm=0.8043\n",
      "Epoch 8: 143/256 - loss_mc=-0.0063, loss_t=0.0105, loss_r=0.0037, loss=-0.0049, norm_factor=735.4365, grad_norm=0.9789\n",
      "Epoch 8: 144/256 - loss_mc=-0.0065, loss_t=0.0088, loss_r=0.0041, loss=-0.0052, norm_factor=735.8727, grad_norm=0.9376\n",
      "Epoch 8: 145/256 - loss_mc=-0.0067, loss_t=0.0079, loss_r=0.0037, loss=-0.0056, norm_factor=736.3009, grad_norm=0.8727\n",
      "Epoch 8: 146/256 - loss_mc=-0.0067, loss_t=0.0083, loss_r=0.0038, loss=-0.0055, norm_factor=736.7367, grad_norm=0.8602\n",
      "Epoch 8: 147/256 - loss_mc=-0.0068, loss_t=0.0121, loss_r=0.0033, loss=-0.0053, norm_factor=737.1674, grad_norm=0.8891\n",
      "Epoch 8: 148/256 - loss_mc=-0.0070, loss_t=0.0087, loss_r=0.0032, loss=-0.0058, norm_factor=737.6119, grad_norm=0.9510\n",
      "Epoch 8: 149/256 - loss_mc=-0.0064, loss_t=0.0127, loss_r=0.0038, loss=-0.0047, norm_factor=738.0810, grad_norm=1.2656\n",
      "Epoch 8: 150/256 - loss_mc=-0.0068, loss_t=0.0068, loss_r=0.0034, loss=-0.0057, norm_factor=738.5358, grad_norm=1.1479\n",
      "Epoch 8: 151/256 - loss_mc=-0.0067, loss_t=0.0083, loss_r=0.0033, loss=-0.0056, norm_factor=739.0005, grad_norm=1.2798\n",
      "Epoch 8: 152/256 - loss_mc=-0.0069, loss_t=0.0077, loss_r=0.0035, loss=-0.0058, norm_factor=739.4656, grad_norm=0.9396\n",
      "Epoch 8: 153/256 - loss_mc=-0.0069, loss_t=0.0084, loss_r=0.0035, loss=-0.0057, norm_factor=739.9559, grad_norm=1.1916\n",
      "Epoch 8: 154/256 - loss_mc=-0.0067, loss_t=0.0090, loss_r=0.0036, loss=-0.0054, norm_factor=740.4490, grad_norm=0.8723\n",
      "Epoch 8: 155/256 - loss_mc=-0.0064, loss_t=0.0096, loss_r=0.0036, loss=-0.0051, norm_factor=740.9421, grad_norm=1.2761\n",
      "Epoch 8: 156/256 - loss_mc=-0.0065, loss_t=0.0098, loss_r=0.0037, loss=-0.0052, norm_factor=741.4198, grad_norm=1.2233\n",
      "Epoch 8: 157/256 - loss_mc=-0.0068, loss_t=0.0102, loss_r=0.0030, loss=-0.0055, norm_factor=741.8901, grad_norm=1.4466\n",
      "Epoch 8: 158/256 - loss_mc=-0.0066, loss_t=0.0097, loss_r=0.0036, loss=-0.0052, norm_factor=742.3728, grad_norm=1.0517\n",
      "Epoch 8: 159/256 - loss_mc=-0.0064, loss_t=0.0084, loss_r=0.0043, loss=-0.0051, norm_factor=742.8441, grad_norm=1.0174\n",
      "Epoch 8: 160/256 - loss_mc=-0.0067, loss_t=0.0092, loss_r=0.0032, loss=-0.0055, norm_factor=743.2969, grad_norm=1.3140\n",
      "Epoch 8: 161/256 - loss_mc=-0.0072, loss_t=0.0067, loss_r=0.0032, loss=-0.0062, norm_factor=743.7493, grad_norm=0.8294\n",
      "Epoch 8: 162/256 - loss_mc=-0.0067, loss_t=0.0082, loss_r=0.0033, loss=-0.0056, norm_factor=744.2317, grad_norm=1.0046\n",
      "Epoch 8: 163/256 - loss_mc=-0.0067, loss_t=0.0092, loss_r=0.0035, loss=-0.0055, norm_factor=744.7134, grad_norm=1.2325\n",
      "Epoch 8: 164/256 - loss_mc=-0.0056, loss_t=0.0105, loss_r=0.0058, loss=-0.0040, norm_factor=745.1948, grad_norm=1.3581\n",
      "Epoch 8: 165/256 - loss_mc=-0.0067, loss_t=0.0088, loss_r=0.0033, loss=-0.0055, norm_factor=745.6080, grad_norm=1.7197\n",
      "Epoch 8: 166/256 - loss_mc=-0.0067, loss_t=0.0099, loss_r=0.0033, loss=-0.0054, norm_factor=746.0233, grad_norm=1.3007\n",
      "Epoch 8: 167/256 - loss_mc=-0.0065, loss_t=0.0087, loss_r=0.0036, loss=-0.0053, norm_factor=746.4393, grad_norm=1.1653\n",
      "Epoch 8: 168/256 - loss_mc=-0.0067, loss_t=0.0072, loss_r=0.0039, loss=-0.0056, norm_factor=746.8468, grad_norm=1.0392\n",
      "Epoch 8: 169/256 - loss_mc=-0.0068, loss_t=0.0070, loss_r=0.0031, loss=-0.0058, norm_factor=747.2648, grad_norm=1.2723\n",
      "Epoch 8: 170/256 - loss_mc=-0.0067, loss_t=0.0098, loss_r=0.0034, loss=-0.0054, norm_factor=747.6997, grad_norm=1.1117\n",
      "Epoch 8: 171/256 - loss_mc=-0.0068, loss_t=0.0086, loss_r=0.0032, loss=-0.0056, norm_factor=748.1461, grad_norm=1.2721\n",
      "Epoch 8: 172/256 - loss_mc=-0.0071, loss_t=0.0093, loss_r=0.0031, loss=-0.0059, norm_factor=748.5990, grad_norm=0.8918\n",
      "Epoch 8: 173/256 - loss_mc=-0.0064, loss_t=0.0104, loss_r=0.0036, loss=-0.0050, norm_factor=749.0758, grad_norm=1.1089\n",
      "Epoch 8: 174/256 - loss_mc=-0.0070, loss_t=0.0099, loss_r=0.0034, loss=-0.0057, norm_factor=749.5356, grad_norm=1.0109\n",
      "Epoch 8: 175/256 - loss_mc=-0.0069, loss_t=0.0074, loss_r=0.0033, loss=-0.0058, norm_factor=750.0175, grad_norm=1.3471\n",
      "Epoch 8: 176/256 - loss_mc=-0.0065, loss_t=0.0093, loss_r=0.0036, loss=-0.0052, norm_factor=750.5118, grad_norm=1.1472\n",
      "Epoch 8: 177/256 - loss_mc=-0.0063, loss_t=0.0101, loss_r=0.0036, loss=-0.0050, norm_factor=750.9891, grad_norm=1.8232\n",
      "Epoch 8: 178/256 - loss_mc=-0.0066, loss_t=0.0103, loss_r=0.0033, loss=-0.0053, norm_factor=751.4467, grad_norm=1.5910\n",
      "Epoch 8: 179/256 - loss_mc=-0.0066, loss_t=0.0093, loss_r=0.0036, loss=-0.0053, norm_factor=751.9015, grad_norm=1.7717\n",
      "Epoch 8: 180/256 - loss_mc=-0.0067, loss_t=0.0093, loss_r=0.0034, loss=-0.0055, norm_factor=752.3563, grad_norm=0.7338\n",
      "Epoch 8: 181/256 - loss_mc=-0.0059, loss_t=0.0156, loss_r=0.0044, loss=-0.0039, norm_factor=752.8221, grad_norm=2.0230\n",
      "Epoch 8: 182/256 - loss_mc=-0.0056, loss_t=0.0084, loss_r=0.0043, loss=-0.0043, norm_factor=753.2365, grad_norm=1.0138\n",
      "Epoch 8: 183/256 - loss_mc=-0.0066, loss_t=0.0108, loss_r=0.0036, loss=-0.0052, norm_factor=753.5862, grad_norm=1.6451\n",
      "Epoch 8: 184/256 - loss_mc=-0.0062, loss_t=0.0110, loss_r=0.0043, loss=-0.0047, norm_factor=753.9480, grad_norm=1.3083\n",
      "Epoch 8: 185/256 - loss_mc=-0.0062, loss_t=0.0097, loss_r=0.0039, loss=-0.0049, norm_factor=754.2933, grad_norm=1.8014\n",
      "Epoch 8: 186/256 - loss_mc=-0.0062, loss_t=0.0094, loss_r=0.0039, loss=-0.0049, norm_factor=754.6127, grad_norm=1.2616\n",
      "Epoch 8: 187/256 - loss_mc=-0.0065, loss_t=0.0084, loss_r=0.0037, loss=-0.0053, norm_factor=754.9200, grad_norm=1.4894\n",
      "Epoch 8: 188/256 - loss_mc=-0.0062, loss_t=0.0093, loss_r=0.0037, loss=-0.0049, norm_factor=755.2354, grad_norm=1.2697\n",
      "Epoch 8: 189/256 - loss_mc=-0.0064, loss_t=0.0127, loss_r=0.0036, loss=-0.0047, norm_factor=755.5297, grad_norm=1.7992\n",
      "Epoch 8: 190/256 - loss_mc=-0.0066, loss_t=0.0117, loss_r=0.0035, loss=-0.0051, norm_factor=755.8263, grad_norm=1.1824\n",
      "Epoch 8: 191/256 - loss_mc=-0.0064, loss_t=0.0106, loss_r=0.0039, loss=-0.0050, norm_factor=756.1423, grad_norm=1.8457\n",
      "Epoch 8: 192/256 - loss_mc=-0.0050, loss_t=0.0116, loss_r=0.0109, loss=-0.0027, norm_factor=756.4592, grad_norm=1.7871\n",
      "Epoch 8: 193/256 - loss_mc=-0.0058, loss_t=0.0164, loss_r=0.0048, loss=-0.0037, norm_factor=756.6810, grad_norm=2.2245\n",
      "Epoch 8: 194/256 - loss_mc=-0.0064, loss_t=0.0111, loss_r=0.0036, loss=-0.0049, norm_factor=756.8684, grad_norm=1.7794\n",
      "Epoch 8: 195/256 - loss_mc=-0.0068, loss_t=0.0091, loss_r=0.0031, loss=-0.0056, norm_factor=757.0676, grad_norm=1.7068\n",
      "Epoch 8: 196/256 - loss_mc=-0.0063, loss_t=0.0114, loss_r=0.0034, loss=-0.0048, norm_factor=757.3060, grad_norm=1.7874\n",
      "Epoch 8: 197/256 - loss_mc=-0.0064, loss_t=0.0108, loss_r=0.0040, loss=-0.0049, norm_factor=757.5453, grad_norm=1.7972\n",
      "Epoch 8: 198/256 - loss_mc=-0.0066, loss_t=0.0082, loss_r=0.0038, loss=-0.0054, norm_factor=757.7836, grad_norm=1.6027\n",
      "Epoch 8: 199/256 - loss_mc=-0.0062, loss_t=0.0128, loss_r=0.0041, loss=-0.0045, norm_factor=758.0278, grad_norm=1.3583\n",
      "Epoch 8: 200/256 - loss_mc=-0.0063, loss_t=0.0104, loss_r=0.0039, loss=-0.0049, norm_factor=758.2687, grad_norm=1.5723\n",
      "Epoch 8: 201/256 - loss_mc=-0.0066, loss_t=0.0093, loss_r=0.0030, loss=-0.0053, norm_factor=758.5136, grad_norm=1.5244\n",
      "Epoch 8: 202/256 - loss_mc=-0.0062, loss_t=0.0086, loss_r=0.0037, loss=-0.0049, norm_factor=758.7678, grad_norm=1.4189\n",
      "Epoch 8: 203/256 - loss_mc=-0.0062, loss_t=0.0119, loss_r=0.0037, loss=-0.0047, norm_factor=759.0043, grad_norm=1.3983\n",
      "Epoch 8: 204/256 - loss_mc=-0.0071, loss_t=0.0080, loss_r=0.0029, loss=-0.0060, norm_factor=759.2300, grad_norm=0.8343\n",
      "Epoch 8: 205/256 - loss_mc=-0.0065, loss_t=0.0118, loss_r=0.0035, loss=-0.0050, norm_factor=759.5090, grad_norm=1.3738\n",
      "Epoch 8: 206/256 - loss_mc=-0.0068, loss_t=0.0089, loss_r=0.0029, loss=-0.0057, norm_factor=759.8009, grad_norm=0.9630\n",
      "Epoch 8: 207/256 - loss_mc=-0.0070, loss_t=0.0098, loss_r=0.0032, loss=-0.0057, norm_factor=760.1241, grad_norm=1.3048\n",
      "Epoch 8: 208/256 - loss_mc=-0.0066, loss_t=0.0080, loss_r=0.0036, loss=-0.0054, norm_factor=760.4907, grad_norm=1.2733\n",
      "Epoch 8: 209/256 - loss_mc=-0.0064, loss_t=0.0086, loss_r=0.0034, loss=-0.0052, norm_factor=760.8656, grad_norm=1.3971\n",
      "Epoch 8: 210/256 - loss_mc=-0.0065, loss_t=0.0101, loss_r=0.0035, loss=-0.0052, norm_factor=761.2393, grad_norm=1.7291\n",
      "Epoch 8: 211/256 - loss_mc=-0.0030, loss_t=0.0087, loss_r=0.0037, loss=-0.0018, norm_factor=761.6355, grad_norm=1.1704\n",
      "Epoch 8: 212/256 - loss_mc=-0.0067, loss_t=0.0108, loss_r=0.0034, loss=-0.0053, norm_factor=761.7924, grad_norm=1.4196\n",
      "Epoch 8: 213/256 - loss_mc=-0.0068, loss_t=0.0084, loss_r=0.0033, loss=-0.0056, norm_factor=761.9819, grad_norm=1.3533\n",
      "Epoch 8: 214/256 - loss_mc=-0.0068, loss_t=0.0076, loss_r=0.0032, loss=-0.0058, norm_factor=762.2004, grad_norm=1.0699\n",
      "Epoch 8: 215/256 - loss_mc=-0.0066, loss_t=0.0101, loss_r=0.0032, loss=-0.0053, norm_factor=762.4603, grad_norm=1.2231\n",
      "Epoch 8: 216/256 - loss_mc=-0.0062, loss_t=0.0118, loss_r=0.0036, loss=-0.0046, norm_factor=762.7414, grad_norm=1.5621\n",
      "Epoch 8: 217/256 - loss_mc=-0.0064, loss_t=0.0104, loss_r=0.0036, loss=-0.0050, norm_factor=763.0077, grad_norm=1.8061\n",
      "Epoch 8: 218/256 - loss_mc=-0.0068, loss_t=0.0093, loss_r=0.0031, loss=-0.0055, norm_factor=763.2815, grad_norm=1.2215\n",
      "Epoch 8: 219/256 - loss_mc=-0.0063, loss_t=0.0108, loss_r=0.0037, loss=-0.0048, norm_factor=763.5803, grad_norm=1.9642\n",
      "Epoch 8: 220/256 - loss_mc=-0.0067, loss_t=0.0113, loss_r=0.0032, loss=-0.0052, norm_factor=763.8783, grad_norm=1.4958\n",
      "Epoch 8: 221/256 - loss_mc=-0.0066, loss_t=0.0078, loss_r=0.0037, loss=-0.0055, norm_factor=764.1893, grad_norm=1.2632\n",
      "Epoch 8: 222/256 - loss_mc=-0.0065, loss_t=0.0142, loss_r=0.0033, loss=-0.0047, norm_factor=764.5089, grad_norm=0.7595\n",
      "Epoch 8: 223/256 - loss_mc=-0.0066, loss_t=0.0102, loss_r=0.0035, loss=-0.0052, norm_factor=764.8308, grad_norm=1.2119\n",
      "Epoch 8: 224/256 - loss_mc=-0.0065, loss_t=0.0074, loss_r=0.0037, loss=-0.0054, norm_factor=765.1748, grad_norm=1.3116\n",
      "Epoch 8: 225/256 - loss_mc=-0.0066, loss_t=0.0089, loss_r=0.0035, loss=-0.0053, norm_factor=765.5173, grad_norm=1.3830\n",
      "Epoch 8: 226/256 - loss_mc=-0.0063, loss_t=0.0123, loss_r=0.0039, loss=-0.0047, norm_factor=765.8669, grad_norm=1.6111\n",
      "Epoch 8: 227/256 - loss_mc=-0.0065, loss_t=0.0082, loss_r=0.0036, loss=-0.0053, norm_factor=766.2040, grad_norm=1.2975\n",
      "Epoch 8: 228/256 - loss_mc=-0.0068, loss_t=0.0086, loss_r=0.0032, loss=-0.0056, norm_factor=766.5477, grad_norm=1.2200\n",
      "Epoch 8: 229/256 - loss_mc=-0.0068, loss_t=0.0096, loss_r=0.0032, loss=-0.0055, norm_factor=766.9192, grad_norm=1.3458\n",
      "Epoch 8: 230/256 - loss_mc=-0.0067, loss_t=0.0085, loss_r=0.0034, loss=-0.0055, norm_factor=767.3033, grad_norm=0.9617\n",
      "Epoch 8: 231/256 - loss_mc=-0.0070, loss_t=0.0077, loss_r=0.0031, loss=-0.0059, norm_factor=767.6959, grad_norm=0.8249\n",
      "Epoch 8: 232/256 - loss_mc=-0.0069, loss_t=0.0078, loss_r=0.0030, loss=-0.0058, norm_factor=768.1211, grad_norm=1.2069\n",
      "Epoch 8: 233/256 - loss_mc=-0.0068, loss_t=0.0062, loss_r=0.0034, loss=-0.0059, norm_factor=768.5786, grad_norm=1.0719\n",
      "Epoch 8: 234/256 - loss_mc=-0.0066, loss_t=0.0101, loss_r=0.0038, loss=-0.0052, norm_factor=769.0529, grad_norm=0.9747\n",
      "Epoch 8: 235/256 - loss_mc=-0.0068, loss_t=0.0078, loss_r=0.0034, loss=-0.0057, norm_factor=769.5347, grad_norm=0.9935\n",
      "Epoch 8: 236/256 - loss_mc=-0.0070, loss_t=0.0071, loss_r=0.0030, loss=-0.0060, norm_factor=770.0309, grad_norm=0.8462\n",
      "Epoch 8: 237/256 - loss_mc=-0.0067, loss_t=0.0072, loss_r=0.0034, loss=-0.0057, norm_factor=770.5455, grad_norm=1.3567\n",
      "Epoch 8: 238/256 - loss_mc=-0.0070, loss_t=0.0078, loss_r=0.0029, loss=-0.0059, norm_factor=771.0586, grad_norm=0.9641\n",
      "Epoch 8: 239/256 - loss_mc=-0.0069, loss_t=0.0094, loss_r=0.0030, loss=-0.0057, norm_factor=771.5890, grad_norm=1.2413\n",
      "Epoch 8: 240/256 - loss_mc=-0.0068, loss_t=0.0073, loss_r=0.0028, loss=-0.0058, norm_factor=772.1396, grad_norm=0.8296\n",
      "Epoch 8: 241/256 - loss_mc=-0.0064, loss_t=0.0088, loss_r=0.0033, loss=-0.0052, norm_factor=772.6904, grad_norm=1.0631\n",
      "Epoch 8: 242/256 - loss_mc=-0.0069, loss_t=0.0070, loss_r=0.0029, loss=-0.0059, norm_factor=773.2151, grad_norm=1.2024\n",
      "Epoch 8: 243/256 - loss_mc=-0.0068, loss_t=0.0073, loss_r=0.0033, loss=-0.0058, norm_factor=773.7469, grad_norm=1.0427\n",
      "Epoch 8: 244/256 - loss_mc=-0.0068, loss_t=0.0080, loss_r=0.0033, loss=-0.0056, norm_factor=774.2820, grad_norm=1.1531\n",
      "Epoch 8: 245/256 - loss_mc=-0.0062, loss_t=0.0094, loss_r=0.0038, loss=-0.0049, norm_factor=774.8137, grad_norm=0.9173\n",
      "Epoch 8: 246/256 - loss_mc=-0.0069, loss_t=0.0068, loss_r=0.0032, loss=-0.0059, norm_factor=775.3107, grad_norm=1.1626\n",
      "Epoch 8: 247/256 - loss_mc=0.0032, loss_t=0.0101, loss_r=0.0033, loss=0.0045, norm_factor=775.8169, grad_norm=1.4551\n",
      "Epoch 8: 248/256 - loss_mc=-0.0067, loss_t=0.0068, loss_r=0.0027, loss=-0.0058, norm_factor=775.6050, grad_norm=1.5500\n",
      "Epoch 8: 249/256 - loss_mc=-0.0065, loss_t=0.0082, loss_r=0.0034, loss=-0.0053, norm_factor=775.4633, grad_norm=1.3564\n",
      "Epoch 8: 250/256 - loss_mc=-0.0071, loss_t=0.0079, loss_r=0.0030, loss=-0.0060, norm_factor=775.3718, grad_norm=1.1277\n",
      "Epoch 8: 251/256 - loss_mc=-0.0068, loss_t=0.0098, loss_r=0.0031, loss=-0.0055, norm_factor=775.3608, grad_norm=1.0797\n",
      "Epoch 8: 252/256 - loss_mc=-0.0069, loss_t=0.0079, loss_r=0.0030, loss=-0.0058, norm_factor=775.4087, grad_norm=1.2768\n",
      "Epoch 8: 253/256 - loss_mc=-0.0063, loss_t=0.0087, loss_r=0.0045, loss=-0.0049, norm_factor=775.5146, grad_norm=1.0845\n",
      "Epoch 8: 254/256 - loss_mc=-0.0063, loss_t=0.0089, loss_r=0.0033, loss=-0.0050, norm_factor=775.6346, grad_norm=1.4496\n",
      "Epoch 8: 255/256 - loss_mc=-0.0066, loss_t=0.0070, loss_r=0.0032, loss=-0.0056, norm_factor=775.7664, grad_norm=0.9135\n",
      "Epoch 8: 256/256 - loss_mc=-0.0065, loss_t=0.0110, loss_r=0.0032, loss=-0.0051, norm_factor=775.9280, grad_norm=0.9632\n",
      "Epoch 9: 1/256 - loss_mc=-0.0064, loss_t=0.0086, loss_r=0.0035, loss=-0.0052, norm_factor=776.1204, grad_norm=1.1346\n",
      "Epoch 9: 2/256 - loss_mc=-0.0069, loss_t=0.0088, loss_r=0.0030, loss=-0.0057, norm_factor=776.3248, grad_norm=0.9483\n",
      "Epoch 9: 3/256 - loss_mc=-0.0068, loss_t=0.0090, loss_r=0.0031, loss=-0.0056, norm_factor=776.5771, grad_norm=1.8224\n",
      "Epoch 9: 4/256 - loss_mc=-0.0069, loss_t=0.0088, loss_r=0.0029, loss=-0.0057, norm_factor=776.8547, grad_norm=0.6088\n",
      "Epoch 9: 5/256 - loss_mc=-0.0067, loss_t=0.0106, loss_r=0.0035, loss=-0.0053, norm_factor=777.1670, grad_norm=1.8069\n",
      "Epoch 9: 6/256 - loss_mc=-0.0069, loss_t=0.0082, loss_r=0.0031, loss=-0.0057, norm_factor=777.4962, grad_norm=1.6987\n",
      "Epoch 9: 7/256 - loss_mc=-0.0071, loss_t=0.0075, loss_r=0.0028, loss=-0.0061, norm_factor=777.8591, grad_norm=1.1913\n",
      "Epoch 9: 8/256 - loss_mc=-0.0064, loss_t=0.0106, loss_r=0.0031, loss=-0.0050, norm_factor=778.2594, grad_norm=1.6107\n",
      "Epoch 9: 9/256 - loss_mc=-0.0063, loss_t=0.0103, loss_r=0.0035, loss=-0.0049, norm_factor=778.6400, grad_norm=1.3063\n",
      "Epoch 9: 10/256 - loss_mc=-0.0065, loss_t=0.0110, loss_r=0.0032, loss=-0.0051, norm_factor=779.0137, grad_norm=1.6553\n",
      "Epoch 9: 11/256 - loss_mc=-0.0066, loss_t=0.0083, loss_r=0.0039, loss=-0.0053, norm_factor=779.3900, grad_norm=1.4080\n",
      "Epoch 9: 12/256 - loss_mc=-0.0064, loss_t=0.0090, loss_r=0.0035, loss=-0.0051, norm_factor=779.7743, grad_norm=1.4558\n",
      "Epoch 9: 13/256 - loss_mc=-0.0064, loss_t=0.0100, loss_r=0.0038, loss=-0.0050, norm_factor=780.1467, grad_norm=1.7934\n",
      "Epoch 9: 14/256 - loss_mc=-0.0066, loss_t=0.0108, loss_r=0.0029, loss=-0.0052, norm_factor=780.5017, grad_norm=1.3813\n",
      "Epoch 9: 15/256 - loss_mc=-0.0069, loss_t=0.0085, loss_r=0.0033, loss=-0.0057, norm_factor=780.8641, grad_norm=1.6945\n",
      "Epoch 9: 16/256 - loss_mc=-0.0066, loss_t=0.0088, loss_r=0.0032, loss=-0.0054, norm_factor=781.2493, grad_norm=1.2468\n",
      "Epoch 9: 17/256 - loss_mc=-0.0062, loss_t=0.0097, loss_r=0.0035, loss=-0.0049, norm_factor=781.6340, grad_norm=1.8277\n",
      "Epoch 9: 18/256 - loss_mc=-0.0070, loss_t=0.0082, loss_r=0.0030, loss=-0.0059, norm_factor=781.9967, grad_norm=1.2570\n",
      "Epoch 9: 19/256 - loss_mc=-0.0061, loss_t=0.0091, loss_r=0.0040, loss=-0.0048, norm_factor=782.4014, grad_norm=1.4796\n",
      "Epoch 9: 20/256 - loss_mc=-0.0068, loss_t=0.0089, loss_r=0.0034, loss=-0.0056, norm_factor=782.7832, grad_norm=1.4726\n",
      "Epoch 9: 21/256 - loss_mc=-0.0055, loss_t=0.0114, loss_r=0.0035, loss=-0.0040, norm_factor=783.1812, grad_norm=1.8829\n",
      "Epoch 9: 22/256 - loss_mc=-0.0067, loss_t=0.0089, loss_r=0.0035, loss=-0.0055, norm_factor=783.5010, grad_norm=1.5636\n",
      "Epoch 9: 23/256 - loss_mc=-0.0064, loss_t=0.0094, loss_r=0.0035, loss=-0.0051, norm_factor=783.8386, grad_norm=2.0137\n",
      "Epoch 9: 24/256 - loss_mc=-0.0061, loss_t=0.0100, loss_r=0.0035, loss=-0.0048, norm_factor=784.1735, grad_norm=1.7093\n",
      "Epoch 9: 25/256 - loss_mc=-0.0066, loss_t=0.0098, loss_r=0.0030, loss=-0.0053, norm_factor=784.4888, grad_norm=1.6854\n",
      "Epoch 9: 26/256 - loss_mc=-0.0067, loss_t=0.0085, loss_r=0.0033, loss=-0.0056, norm_factor=784.8229, grad_norm=1.4679\n",
      "Epoch 9: 27/256 - loss_mc=-0.0064, loss_t=0.0104, loss_r=0.0034, loss=-0.0050, norm_factor=785.1796, grad_norm=1.8828\n",
      "Epoch 9: 28/256 - loss_mc=-0.0069, loss_t=0.0089, loss_r=0.0030, loss=-0.0057, norm_factor=785.5306, grad_norm=1.2234\n",
      "Epoch 9: 29/256 - loss_mc=-0.0068, loss_t=0.0109, loss_r=0.0030, loss=-0.0054, norm_factor=785.9010, grad_norm=1.9557\n",
      "Epoch 9: 30/256 - loss_mc=-0.0060, loss_t=0.0115, loss_r=0.0032, loss=-0.0045, norm_factor=786.2856, grad_norm=2.0345\n",
      "Epoch 9: 31/256 - loss_mc=-0.0060, loss_t=0.0098, loss_r=0.0036, loss=-0.0047, norm_factor=786.6263, grad_norm=1.8508\n",
      "Epoch 9: 32/256 - loss_mc=-0.0060, loss_t=0.0109, loss_r=0.0036, loss=-0.0046, norm_factor=786.9366, grad_norm=2.2134\n",
      "Epoch 9: 33/256 - loss_mc=-0.0068, loss_t=0.0080, loss_r=0.0028, loss=-0.0057, norm_factor=787.2203, grad_norm=1.5967\n",
      "Epoch 9: 34/256 - loss_mc=-0.0066, loss_t=0.0097, loss_r=0.0031, loss=-0.0053, norm_factor=787.5347, grad_norm=2.1182\n",
      "Epoch 9: 35/256 - loss_mc=-0.0064, loss_t=0.0095, loss_r=0.0039, loss=-0.0050, norm_factor=787.8646, grad_norm=1.3696\n",
      "Epoch 9: 36/256 - loss_mc=-0.0058, loss_t=0.0193, loss_r=0.0030, loss=-0.0036, norm_factor=788.1909, grad_norm=1.5893\n",
      "Epoch 9: 37/256 - loss_mc=-0.0065, loss_t=0.0084, loss_r=0.0032, loss=-0.0053, norm_factor=788.4826, grad_norm=1.8867\n",
      "Epoch 9: 38/256 - loss_mc=-0.0069, loss_t=0.0112, loss_r=0.0032, loss=-0.0054, norm_factor=788.7831, grad_norm=1.3245\n",
      "Epoch 9: 39/256 - loss_mc=-0.0061, loss_t=0.0113, loss_r=0.0036, loss=-0.0046, norm_factor=789.1075, grad_norm=2.6511\n",
      "Epoch 9: 40/256 - loss_mc=-0.0065, loss_t=0.0088, loss_r=0.0035, loss=-0.0053, norm_factor=789.4113, grad_norm=1.2925\n",
      "Epoch 9: 41/256 - loss_mc=-0.0062, loss_t=0.0105, loss_r=0.0030, loss=-0.0048, norm_factor=789.7158, grad_norm=2.6501\n",
      "Epoch 9: 42/256 - loss_mc=-0.0067, loss_t=0.0087, loss_r=0.0031, loss=-0.0055, norm_factor=790.0022, grad_norm=0.9475\n",
      "Epoch 9: 43/256 - loss_mc=-0.0059, loss_t=0.0092, loss_r=0.0032, loss=-0.0047, norm_factor=790.3083, grad_norm=2.2603\n",
      "Epoch 9: 44/256 - loss_mc=-0.0071, loss_t=0.0075, loss_r=0.0028, loss=-0.0060, norm_factor=790.5728, grad_norm=1.2161\n",
      "Epoch 9: 45/256 - loss_mc=-0.0060, loss_t=0.0097, loss_r=0.0037, loss=-0.0046, norm_factor=790.8839, grad_norm=2.7580\n",
      "Epoch 9: 46/256 - loss_mc=-0.0065, loss_t=0.0101, loss_r=0.0034, loss=-0.0052, norm_factor=791.1611, grad_norm=1.9102\n",
      "Epoch 9: 47/256 - loss_mc=-0.0065, loss_t=0.0070, loss_r=0.0032, loss=-0.0054, norm_factor=791.4490, grad_norm=2.5082\n",
      "Epoch 9: 48/256 - loss_mc=-0.0063, loss_t=0.0099, loss_r=0.0031, loss=-0.0050, norm_factor=791.7397, grad_norm=1.1664\n",
      "Epoch 9: 49/256 - loss_mc=-0.0061, loss_t=0.0095, loss_r=0.0033, loss=-0.0048, norm_factor=792.0275, grad_norm=2.7660\n",
      "Epoch 9: 50/256 - loss_mc=-0.0061, loss_t=0.0095, loss_r=0.0032, loss=-0.0049, norm_factor=792.2903, grad_norm=1.3969\n",
      "Epoch 9: 51/256 - loss_mc=-0.0060, loss_t=0.0105, loss_r=0.0037, loss=-0.0046, norm_factor=792.5302, grad_norm=2.3311\n",
      "Epoch 9: 52/256 - loss_mc=-0.0067, loss_t=0.0103, loss_r=0.0032, loss=-0.0053, norm_factor=792.7410, grad_norm=1.2683\n",
      "Epoch 9: 53/256 - loss_mc=-0.0067, loss_t=0.0089, loss_r=0.0034, loss=-0.0054, norm_factor=792.9802, grad_norm=2.2359\n",
      "Epoch 9: 54/256 - loss_mc=-0.0062, loss_t=0.0104, loss_r=0.0038, loss=-0.0048, norm_factor=793.2480, grad_norm=1.1417\n",
      "Epoch 9: 55/256 - loss_mc=-0.0061, loss_t=0.0115, loss_r=0.0035, loss=-0.0046, norm_factor=793.5105, grad_norm=2.4075\n",
      "Epoch 9: 56/256 - loss_mc=-0.0063, loss_t=0.0094, loss_r=0.0031, loss=-0.0051, norm_factor=793.7495, grad_norm=1.0770\n",
      "Epoch 9: 57/256 - loss_mc=-0.0065, loss_t=0.0082, loss_r=0.0034, loss=-0.0053, norm_factor=793.9937, grad_norm=1.9446\n",
      "Epoch 9: 58/256 - loss_mc=-0.0064, loss_t=0.0086, loss_r=0.0036, loss=-0.0051, norm_factor=794.2494, grad_norm=1.0957\n",
      "Epoch 9: 59/256 - loss_mc=-0.0065, loss_t=0.0085, loss_r=0.0035, loss=-0.0053, norm_factor=794.4993, grad_norm=1.1375\n",
      "Epoch 9: 60/256 - loss_mc=-0.0064, loss_t=0.0104, loss_r=0.0031, loss=-0.0050, norm_factor=794.7529, grad_norm=1.2852\n",
      "Epoch 9: 61/256 - loss_mc=-0.0059, loss_t=0.0105, loss_r=0.0032, loss=-0.0045, norm_factor=794.9955, grad_norm=1.6514\n",
      "Epoch 9: 62/256 - loss_mc=-0.0067, loss_t=0.0083, loss_r=0.0031, loss=-0.0055, norm_factor=795.2103, grad_norm=1.0363\n",
      "Epoch 9: 63/256 - loss_mc=-0.0068, loss_t=0.0090, loss_r=0.0028, loss=-0.0056, norm_factor=795.4423, grad_norm=1.7342\n",
      "Epoch 9: 64/256 - loss_mc=-0.0066, loss_t=0.0089, loss_r=0.0032, loss=-0.0054, norm_factor=795.7113, grad_norm=1.1051\n",
      "Epoch 9: 65/256 - loss_mc=-0.0066, loss_t=0.0088, loss_r=0.0030, loss=-0.0054, norm_factor=795.9995, grad_norm=1.7008\n",
      "Epoch 9: 66/256 - loss_mc=-0.0066, loss_t=0.0103, loss_r=0.0029, loss=-0.0053, norm_factor=796.3041, grad_norm=1.2410\n",
      "Epoch 9: 67/256 - loss_mc=-0.0066, loss_t=0.0098, loss_r=0.0031, loss=-0.0053, norm_factor=796.6236, grad_norm=1.4526\n",
      "Epoch 9: 68/256 - loss_mc=-0.0067, loss_t=0.0085, loss_r=0.0030, loss=-0.0056, norm_factor=796.9644, grad_norm=1.0152\n",
      "Epoch 9: 69/256 - loss_mc=-0.0067, loss_t=0.0072, loss_r=0.0031, loss=-0.0057, norm_factor=797.3311, grad_norm=1.4154\n",
      "Epoch 9: 70/256 - loss_mc=-0.0066, loss_t=0.0071, loss_r=0.0034, loss=-0.0056, norm_factor=797.7179, grad_norm=1.1171\n",
      "Epoch 9: 71/256 - loss_mc=-0.0064, loss_t=0.0086, loss_r=0.0040, loss=-0.0051, norm_factor=798.1171, grad_norm=1.0908\n",
      "Epoch 9: 72/256 - loss_mc=-0.0069, loss_t=0.0067, loss_r=0.0031, loss=-0.0059, norm_factor=798.5001, grad_norm=1.1666\n",
      "Epoch 9: 73/256 - loss_mc=-0.0066, loss_t=0.0082, loss_r=0.0035, loss=-0.0055, norm_factor=798.9036, grad_norm=1.3388\n",
      "Epoch 9: 74/256 - loss_mc=-0.0067, loss_t=0.0092, loss_r=0.0032, loss=-0.0055, norm_factor=799.3145, grad_norm=1.2636\n",
      "Epoch 9: 75/256 - loss_mc=-0.0071, loss_t=0.0074, loss_r=0.0026, loss=-0.0061, norm_factor=799.7396, grad_norm=1.2382\n",
      "Epoch 9: 76/256 - loss_mc=-0.0064, loss_t=0.0113, loss_r=0.0032, loss=-0.0050, norm_factor=800.1996, grad_norm=0.9872\n",
      "Epoch 9: 77/256 - loss_mc=-0.0066, loss_t=0.0080, loss_r=0.0031, loss=-0.0055, norm_factor=800.6454, grad_norm=1.3408\n",
      "Epoch 9: 78/256 - loss_mc=-0.0070, loss_t=0.0070, loss_r=0.0031, loss=-0.0060, norm_factor=801.0986, grad_norm=0.7161\n",
      "Epoch 9: 79/256 - loss_mc=-0.0069, loss_t=0.0090, loss_r=0.0029, loss=-0.0057, norm_factor=801.5867, grad_norm=1.3577\n",
      "Epoch 9: 80/256 - loss_mc=-0.0069, loss_t=0.0091, loss_r=0.0028, loss=-0.0057, norm_factor=802.0996, grad_norm=0.7230\n",
      "Epoch 9: 81/256 - loss_mc=-0.0067, loss_t=0.0096, loss_r=0.0029, loss=-0.0054, norm_factor=802.6326, grad_norm=1.1731\n",
      "Epoch 9: 82/256 - loss_mc=-0.0068, loss_t=0.0106, loss_r=0.0025, loss=-0.0055, norm_factor=803.1566, grad_norm=1.1297\n",
      "Epoch 9: 83/256 - loss_mc=-0.0070, loss_t=0.0069, loss_r=0.0024, loss=-0.0061, norm_factor=803.6908, grad_norm=0.5338\n",
      "Epoch 9: 84/256 - loss_mc=-0.0065, loss_t=0.0077, loss_r=0.0030, loss=-0.0054, norm_factor=804.2554, grad_norm=1.4297\n",
      "Epoch 9: 85/256 - loss_mc=-0.0069, loss_t=0.0089, loss_r=0.0029, loss=-0.0057, norm_factor=804.7911, grad_norm=1.1996\n",
      "Epoch 9: 86/256 - loss_mc=-0.0068, loss_t=0.0081, loss_r=0.0027, loss=-0.0058, norm_factor=805.3423, grad_norm=1.4700\n",
      "Epoch 9: 87/256 - loss_mc=-0.0066, loss_t=0.0069, loss_r=0.0031, loss=-0.0056, norm_factor=805.9043, grad_norm=1.2361\n",
      "Epoch 9: 88/256 - loss_mc=-0.0063, loss_t=0.0094, loss_r=0.0033, loss=-0.0050, norm_factor=806.4554, grad_norm=1.5643\n",
      "Epoch 9: 89/256 - loss_mc=-0.0066, loss_t=0.0070, loss_r=0.0032, loss=-0.0055, norm_factor=806.9784, grad_norm=1.1495\n",
      "Epoch 9: 90/256 - loss_mc=-0.0066, loss_t=0.0082, loss_r=0.0031, loss=-0.0055, norm_factor=807.4874, grad_norm=1.6820\n",
      "Epoch 9: 91/256 - loss_mc=-0.0067, loss_t=0.0079, loss_r=0.0031, loss=-0.0056, norm_factor=807.9941, grad_norm=1.3580\n",
      "Epoch 9: 92/256 - loss_mc=-0.0066, loss_t=0.0083, loss_r=0.0030, loss=-0.0055, norm_factor=808.4989, grad_norm=1.3236\n",
      "Epoch 9: 93/256 - loss_mc=-0.0067, loss_t=0.0114, loss_r=0.0030, loss=-0.0053, norm_factor=809.0002, grad_norm=2.1994\n",
      "Epoch 9: 94/256 - loss_mc=-0.0068, loss_t=0.0072, loss_r=0.0028, loss=-0.0058, norm_factor=809.4949, grad_norm=1.7517\n",
      "Epoch 9: 95/256 - loss_mc=-0.0070, loss_t=0.0072, loss_r=0.0030, loss=-0.0060, norm_factor=810.0038, grad_norm=1.4352\n",
      "Epoch 9: 96/256 - loss_mc=-0.0061, loss_t=0.0121, loss_r=0.0035, loss=-0.0045, norm_factor=810.5445, grad_norm=2.0536\n",
      "Epoch 9: 97/256 - loss_mc=-0.0057, loss_t=0.0086, loss_r=0.0036, loss=-0.0045, norm_factor=811.0438, grad_norm=1.2282\n",
      "Epoch 9: 98/256 - loss_mc=-0.0066, loss_t=0.0084, loss_r=0.0032, loss=-0.0054, norm_factor=811.4642, grad_norm=2.2195\n",
      "Epoch 9: 99/256 - loss_mc=-0.0063, loss_t=0.0081, loss_r=0.0030, loss=-0.0052, norm_factor=811.8790, grad_norm=1.5901\n",
      "Epoch 9: 100/256 - loss_mc=-0.0066, loss_t=0.0079, loss_r=0.0030, loss=-0.0055, norm_factor=812.2870, grad_norm=1.8457\n",
      "Epoch 9: 101/256 - loss_mc=-0.0066, loss_t=0.0080, loss_r=0.0032, loss=-0.0054, norm_factor=812.6971, grad_norm=1.2127\n",
      "Epoch 9: 102/256 - loss_mc=-0.0067, loss_t=0.0073, loss_r=0.0029, loss=-0.0057, norm_factor=813.1185, grad_norm=1.4709\n",
      "Epoch 9: 103/256 - loss_mc=-0.0066, loss_t=0.0076, loss_r=0.0031, loss=-0.0056, norm_factor=813.5500, grad_norm=1.4277\n",
      "Epoch 9: 104/256 - loss_mc=-0.0065, loss_t=0.0075, loss_r=0.0030, loss=-0.0054, norm_factor=813.9788, grad_norm=1.6560\n",
      "Epoch 9: 105/256 - loss_mc=-0.0069, loss_t=0.0079, loss_r=0.0027, loss=-0.0058, norm_factor=814.3946, grad_norm=1.4750\n",
      "Epoch 9: 106/256 - loss_mc=-0.0069, loss_t=0.0083, loss_r=0.0027, loss=-0.0058, norm_factor=814.8339, grad_norm=1.3580\n",
      "Epoch 9: 107/256 - loss_mc=-0.0068, loss_t=0.0081, loss_r=0.0029, loss=-0.0057, norm_factor=815.2944, grad_norm=1.4265\n",
      "Epoch 9: 108/256 - loss_mc=-0.0065, loss_t=0.0058, loss_r=0.0027, loss=-0.0056, norm_factor=815.7784, grad_norm=0.7960\n",
      "Epoch 9: 109/256 - loss_mc=-0.0065, loss_t=0.0101, loss_r=0.0031, loss=-0.0052, norm_factor=816.2488, grad_norm=1.5650\n",
      "Epoch 9: 110/256 - loss_mc=-0.0066, loss_t=0.0085, loss_r=0.0030, loss=-0.0055, norm_factor=816.7149, grad_norm=1.0116\n",
      "Epoch 9: 111/256 - loss_mc=-0.0056, loss_t=0.0064, loss_r=0.0038, loss=-0.0046, norm_factor=817.1794, grad_norm=0.9742\n",
      "Epoch 9: 112/256 - loss_mc=-0.0067, loss_t=0.0089, loss_r=0.0033, loss=-0.0054, norm_factor=817.5636, grad_norm=1.1395\n",
      "Epoch 9: 113/256 - loss_mc=-0.0065, loss_t=0.0080, loss_r=0.0039, loss=-0.0053, norm_factor=817.9706, grad_norm=1.1848\n",
      "Epoch 9: 114/256 - loss_mc=-0.0068, loss_t=0.0073, loss_r=0.0028, loss=-0.0058, norm_factor=818.3790, grad_norm=0.6219\n",
      "Epoch 9: 115/256 - loss_mc=-0.0065, loss_t=0.0083, loss_r=0.0028, loss=-0.0054, norm_factor=818.8131, grad_norm=1.2187\n",
      "Epoch 9: 116/256 - loss_mc=-0.0065, loss_t=0.0106, loss_r=0.0028, loss=-0.0051, norm_factor=819.2468, grad_norm=1.0438\n",
      "Epoch 9: 117/256 - loss_mc=-0.0065, loss_t=0.0081, loss_r=0.0033, loss=-0.0054, norm_factor=819.6769, grad_norm=1.5196\n",
      "Epoch 9: 118/256 - loss_mc=-0.0066, loss_t=0.0089, loss_r=0.0031, loss=-0.0054, norm_factor=820.0927, grad_norm=1.1321\n",
      "Epoch 9: 119/256 - loss_mc=-0.0026, loss_t=0.0124, loss_r=0.0096, loss=-0.0004, norm_factor=820.5097, grad_norm=0.9482\n",
      "Epoch 9: 120/256 - loss_mc=-0.0068, loss_t=0.0083, loss_r=0.0028, loss=-0.0057, norm_factor=820.5840, grad_norm=1.0621\n",
      "Epoch 9: 121/256 - loss_mc=-0.0060, loss_t=0.0101, loss_r=0.0039, loss=-0.0046, norm_factor=820.7108, grad_norm=1.4481\n",
      "Epoch 9: 122/256 - loss_mc=-0.0056, loss_t=0.0099, loss_r=0.0032, loss=-0.0043, norm_factor=820.8170, grad_norm=1.9347\n",
      "Epoch 9: 123/256 - loss_mc=-0.0065, loss_t=0.0088, loss_r=0.0030, loss=-0.0053, norm_factor=820.8757, grad_norm=1.2597\n",
      "Epoch 9: 124/256 - loss_mc=-0.0064, loss_t=0.0078, loss_r=0.0030, loss=-0.0053, norm_factor=820.9564, grad_norm=0.9287\n",
      "Epoch 9: 125/256 - loss_mc=-0.0065, loss_t=0.0088, loss_r=0.0033, loss=-0.0053, norm_factor=821.0535, grad_norm=1.3570\n",
      "Epoch 9: 126/256 - loss_mc=-0.0068, loss_t=0.0084, loss_r=0.0027, loss=-0.0057, norm_factor=821.1682, grad_norm=1.0672\n",
      "Epoch 9: 127/256 - loss_mc=-0.0067, loss_t=0.0070, loss_r=0.0028, loss=-0.0057, norm_factor=821.3361, grad_norm=1.2049\n",
      "Epoch 9: 128/256 - loss_mc=-0.0062, loss_t=0.0123, loss_r=0.0036, loss=-0.0046, norm_factor=821.5552, grad_norm=1.3697\n",
      "Epoch 9: 129/256 - loss_mc=-0.0068, loss_t=0.0068, loss_r=0.0030, loss=-0.0058, norm_factor=821.7701, grad_norm=1.0168\n",
      "Epoch 9: 130/256 - loss_mc=-0.0067, loss_t=0.0056, loss_r=0.0033, loss=-0.0058, norm_factor=822.0276, grad_norm=0.7765\n",
      "Epoch 9: 131/256 - loss_mc=-0.0066, loss_t=0.0084, loss_r=0.0028, loss=-0.0055, norm_factor=822.3168, grad_norm=1.1766\n",
      "Epoch 9: 132/256 - loss_mc=-0.0066, loss_t=0.0081, loss_r=0.0031, loss=-0.0055, norm_factor=822.6300, grad_norm=1.1749\n",
      "Epoch 9: 133/256 - loss_mc=-0.0059, loss_t=0.0093, loss_r=0.0035, loss=-0.0046, norm_factor=822.9553, grad_norm=1.3346\n",
      "Epoch 9: 134/256 - loss_mc=-0.0068, loss_t=0.0086, loss_r=0.0028, loss=-0.0057, norm_factor=823.2321, grad_norm=1.4182\n",
      "Epoch 9: 135/256 - loss_mc=-0.0066, loss_t=0.0081, loss_r=0.0028, loss=-0.0055, norm_factor=823.5344, grad_norm=1.5174\n",
      "Epoch 9: 136/256 - loss_mc=-0.0067, loss_t=0.0093, loss_r=0.0030, loss=-0.0054, norm_factor=823.8439, grad_norm=1.4496\n",
      "Epoch 9: 137/256 - loss_mc=-0.0065, loss_t=0.0087, loss_r=0.0031, loss=-0.0053, norm_factor=824.1742, grad_norm=1.7501\n",
      "Epoch 9: 138/256 - loss_mc=-0.0065, loss_t=0.0083, loss_r=0.0034, loss=-0.0053, norm_factor=824.5042, grad_norm=1.7867\n",
      "Epoch 9: 139/256 - loss_mc=-0.0068, loss_t=0.0060, loss_r=0.0029, loss=-0.0059, norm_factor=824.8317, grad_norm=0.9161\n",
      "Epoch 9: 140/256 - loss_mc=-0.0068, loss_t=0.0067, loss_r=0.0027, loss=-0.0058, norm_factor=825.1927, grad_norm=1.8056\n",
      "Epoch 9: 141/256 - loss_mc=-0.0061, loss_t=0.0082, loss_r=0.0034, loss=-0.0049, norm_factor=825.5851, grad_norm=1.5611\n",
      "Epoch 9: 142/256 - loss_mc=-0.0067, loss_t=0.0074, loss_r=0.0030, loss=-0.0057, norm_factor=825.9486, grad_norm=0.8207\n",
      "Epoch 9: 143/256 - loss_mc=-0.0065, loss_t=0.0085, loss_r=0.0030, loss=-0.0054, norm_factor=826.3359, grad_norm=2.0405\n",
      "Epoch 9: 144/256 - loss_mc=-0.0065, loss_t=0.0089, loss_r=0.0030, loss=-0.0054, norm_factor=826.7289, grad_norm=1.1757\n",
      "Epoch 9: 145/256 - loss_mc=-0.0064, loss_t=0.0088, loss_r=0.0032, loss=-0.0052, norm_factor=827.1310, grad_norm=1.5494\n",
      "Epoch 9: 146/256 - loss_mc=-0.0066, loss_t=0.0087, loss_r=0.0030, loss=-0.0054, norm_factor=827.5166, grad_norm=1.7467\n",
      "Epoch 9: 147/256 - loss_mc=-0.0064, loss_t=0.0078, loss_r=0.0032, loss=-0.0053, norm_factor=827.9076, grad_norm=1.7647\n",
      "Epoch 9: 148/256 - loss_mc=-0.0065, loss_t=0.0098, loss_r=0.0032, loss=-0.0053, norm_factor=828.2948, grad_norm=1.7983\n",
      "Epoch 9: 149/256 - loss_mc=-0.0060, loss_t=0.0078, loss_r=0.0031, loss=-0.0049, norm_factor=828.6758, grad_norm=1.1422\n",
      "Epoch 9: 150/256 - loss_mc=-0.0067, loss_t=0.0088, loss_r=0.0029, loss=-0.0056, norm_factor=829.0145, grad_norm=2.2190\n",
      "Epoch 9: 151/256 - loss_mc=-0.0068, loss_t=0.0074, loss_r=0.0028, loss=-0.0058, norm_factor=829.3687, grad_norm=1.2038\n",
      "Epoch 9: 152/256 - loss_mc=-0.0062, loss_t=0.0105, loss_r=0.0030, loss=-0.0049, norm_factor=829.7561, grad_norm=1.8956\n",
      "Epoch 9: 153/256 - loss_mc=-0.0066, loss_t=0.0089, loss_r=0.0029, loss=-0.0054, norm_factor=830.1315, grad_norm=1.4714\n",
      "Epoch 9: 154/256 - loss_mc=-0.0062, loss_t=0.0094, loss_r=0.0032, loss=-0.0049, norm_factor=830.5253, grad_norm=2.6210\n",
      "Epoch 9: 155/256 - loss_mc=-0.0068, loss_t=0.0061, loss_r=0.0024, loss=-0.0060, norm_factor=830.8849, grad_norm=1.2925\n",
      "Epoch 9: 156/256 - loss_mc=-0.0055, loss_t=0.0122, loss_r=0.0040, loss=-0.0039, norm_factor=831.2644, grad_norm=2.8992\n",
      "Epoch 9: 157/256 - loss_mc=-0.0066, loss_t=0.0079, loss_r=0.0025, loss=-0.0055, norm_factor=831.5677, grad_norm=1.0043\n",
      "Epoch 9: 158/256 - loss_mc=-0.0063, loss_t=0.0073, loss_r=0.0028, loss=-0.0053, norm_factor=831.8903, grad_norm=2.1531\n",
      "Epoch 9: 159/256 - loss_mc=-0.0065, loss_t=0.0084, loss_r=0.0030, loss=-0.0053, norm_factor=832.2021, grad_norm=1.8893\n",
      "Epoch 9: 160/256 - loss_mc=-0.0064, loss_t=0.0068, loss_r=0.0029, loss=-0.0054, norm_factor=832.5111, grad_norm=1.6166\n",
      "Epoch 9: 161/256 - loss_mc=-0.0049, loss_t=0.0135, loss_r=0.0042, loss=-0.0032, norm_factor=832.8168, grad_norm=2.0926\n",
      "Epoch 9: 162/256 - loss_mc=-0.0063, loss_t=0.0089, loss_r=0.0028, loss=-0.0051, norm_factor=832.9972, grad_norm=2.2208\n",
      "Epoch 9: 163/256 - loss_mc=-0.0064, loss_t=0.0080, loss_r=0.0027, loss=-0.0054, norm_factor=833.1731, grad_norm=1.9565\n",
      "Epoch 9: 164/256 - loss_mc=-0.0065, loss_t=0.0077, loss_r=0.0030, loss=-0.0054, norm_factor=833.3602, grad_norm=2.2002\n",
      "Epoch 9: 165/256 - loss_mc=-0.0063, loss_t=0.0102, loss_r=0.0025, loss=-0.0050, norm_factor=833.5713, grad_norm=2.0678\n",
      "Epoch 9: 166/256 - loss_mc=-0.0065, loss_t=0.0076, loss_r=0.0027, loss=-0.0055, norm_factor=833.7882, grad_norm=1.8194\n",
      "Epoch 9: 167/256 - loss_mc=-0.0059, loss_t=0.0093, loss_r=0.0032, loss=-0.0047, norm_factor=834.0282, grad_norm=1.9471\n",
      "Epoch 9: 168/256 - loss_mc=-0.0065, loss_t=0.0078, loss_r=0.0030, loss=-0.0054, norm_factor=834.2388, grad_norm=1.6722\n",
      "Epoch 9: 169/256 - loss_mc=-0.0064, loss_t=0.0081, loss_r=0.0028, loss=-0.0053, norm_factor=834.4652, grad_norm=1.2316\n",
      "Epoch 9: 170/256 - loss_mc=-0.0070, loss_t=0.0083, loss_r=0.0023, loss=-0.0059, norm_factor=834.6990, grad_norm=1.5037\n",
      "Epoch 9: 171/256 - loss_mc=-0.0068, loss_t=0.0088, loss_r=0.0027, loss=-0.0057, norm_factor=834.9796, grad_norm=1.3831\n",
      "Epoch 9: 172/256 - loss_mc=-0.0067, loss_t=0.0077, loss_r=0.0029, loss=-0.0056, norm_factor=835.2952, grad_norm=1.5061\n",
      "Epoch 9: 173/256 - loss_mc=-0.0061, loss_t=0.0078, loss_r=0.0029, loss=-0.0050, norm_factor=835.6267, grad_norm=1.7490\n",
      "Epoch 9: 174/256 - loss_mc=-0.0070, loss_t=0.0062, loss_r=0.0023, loss=-0.0062, norm_factor=835.9337, grad_norm=0.7834\n",
      "Epoch 9: 175/256 - loss_mc=-0.0064, loss_t=0.0065, loss_r=0.0030, loss=-0.0055, norm_factor=836.3016, grad_norm=1.6776\n",
      "Epoch 9: 176/256 - loss_mc=-0.0065, loss_t=0.0087, loss_r=0.0029, loss=-0.0054, norm_factor=836.6721, grad_norm=1.3736\n",
      "Epoch 9: 177/256 - loss_mc=-0.0066, loss_t=0.0086, loss_r=0.0025, loss=-0.0055, norm_factor=837.0570, grad_norm=1.3302\n",
      "Epoch 9: 178/256 - loss_mc=-0.0061, loss_t=0.0106, loss_r=0.0035, loss=-0.0047, norm_factor=837.4599, grad_norm=1.2885\n",
      "Epoch 9: 179/256 - loss_mc=-0.0066, loss_t=0.0065, loss_r=0.0032, loss=-0.0056, norm_factor=837.8320, grad_norm=0.9665\n",
      "Epoch 9: 180/256 - loss_mc=-0.0065, loss_t=0.0068, loss_r=0.0031, loss=-0.0055, norm_factor=838.2144, grad_norm=1.1988\n",
      "Epoch 9: 181/256 - loss_mc=-0.0066, loss_t=0.0078, loss_r=0.0028, loss=-0.0056, norm_factor=838.5952, grad_norm=1.1429\n",
      "Epoch 9: 182/256 - loss_mc=-0.0068, loss_t=0.0066, loss_r=0.0026, loss=-0.0059, norm_factor=838.9861, grad_norm=1.3276\n",
      "Epoch 9: 183/256 - loss_mc=-0.0064, loss_t=0.0068, loss_r=0.0029, loss=-0.0055, norm_factor=839.3939, grad_norm=1.3901\n",
      "Epoch 9: 184/256 - loss_mc=-0.0066, loss_t=0.0059, loss_r=0.0029, loss=-0.0057, norm_factor=839.8002, grad_norm=1.3200\n",
      "Epoch 9: 185/256 - loss_mc=-0.0061, loss_t=0.0073, loss_r=0.0031, loss=-0.0050, norm_factor=840.2068, grad_norm=1.5048\n",
      "Epoch 9: 186/256 - loss_mc=-0.0065, loss_t=0.0098, loss_r=0.0029, loss=-0.0053, norm_factor=840.5662, grad_norm=1.7244\n",
      "Epoch 9: 187/256 - loss_mc=-0.0063, loss_t=0.0073, loss_r=0.0028, loss=-0.0053, norm_factor=840.9340, grad_norm=2.1935\n",
      "Epoch 9: 188/256 - loss_mc=-0.0065, loss_t=0.0088, loss_r=0.0029, loss=-0.0053, norm_factor=841.2976, grad_norm=1.9236\n",
      "Epoch 9: 189/256 - loss_mc=-0.0065, loss_t=0.0072, loss_r=0.0030, loss=-0.0055, norm_factor=841.6662, grad_norm=1.2375\n",
      "Epoch 9: 190/256 - loss_mc=-0.0068, loss_t=0.0069, loss_r=0.0028, loss=-0.0059, norm_factor=842.0435, grad_norm=1.4786\n",
      "Epoch 9: 191/256 - loss_mc=-0.0063, loss_t=0.0071, loss_r=0.0027, loss=-0.0053, norm_factor=842.4636, grad_norm=1.5751\n",
      "Epoch 9: 192/256 - loss_mc=-0.0064, loss_t=0.0089, loss_r=0.0030, loss=-0.0052, norm_factor=842.8611, grad_norm=1.7690\n",
      "Epoch 9: 193/256 - loss_mc=-0.0064, loss_t=0.0103, loss_r=0.0026, loss=-0.0051, norm_factor=843.2389, grad_norm=1.6888\n",
      "Epoch 9: 194/256 - loss_mc=-0.0065, loss_t=0.0092, loss_r=0.0032, loss=-0.0052, norm_factor=843.6085, grad_norm=2.1293\n",
      "Epoch 9: 195/256 - loss_mc=-0.0055, loss_t=0.0080, loss_r=0.0026, loss=-0.0044, norm_factor=843.9857, grad_norm=2.3816\n",
      "Epoch 9: 196/256 - loss_mc=-0.0064, loss_t=0.0083, loss_r=0.0029, loss=-0.0053, norm_factor=844.2723, grad_norm=1.9176\n",
      "Epoch 9: 197/256 - loss_mc=-0.0064, loss_t=0.0061, loss_r=0.0029, loss=-0.0055, norm_factor=844.5576, grad_norm=1.7107\n",
      "Epoch 9: 198/256 - loss_mc=-0.0066, loss_t=0.0075, loss_r=0.0027, loss=-0.0056, norm_factor=844.8441, grad_norm=1.8334\n",
      "Epoch 9: 199/256 - loss_mc=-0.0068, loss_t=0.0072, loss_r=0.0024, loss=-0.0059, norm_factor=845.1614, grad_norm=1.1709\n",
      "Epoch 9: 200/256 - loss_mc=-0.0066, loss_t=0.0082, loss_r=0.0026, loss=-0.0055, norm_factor=845.5125, grad_norm=1.8427\n",
      "Epoch 9: 201/256 - loss_mc=-0.0038, loss_t=0.0069, loss_r=0.0027, loss=-0.0029, norm_factor=845.8694, grad_norm=1.4130\n",
      "Epoch 9: 202/256 - loss_mc=-0.0063, loss_t=0.0077, loss_r=0.0027, loss=-0.0053, norm_factor=845.9989, grad_norm=1.9426\n",
      "Epoch 9: 203/256 - loss_mc=-0.0063, loss_t=0.0080, loss_r=0.0031, loss=-0.0052, norm_factor=846.1364, grad_norm=1.7469\n",
      "Epoch 9: 204/256 - loss_mc=-0.0063, loss_t=0.0083, loss_r=0.0029, loss=-0.0052, norm_factor=846.2859, grad_norm=2.0537\n",
      "Epoch 9: 205/256 - loss_mc=-0.0068, loss_t=0.0073, loss_r=0.0026, loss=-0.0058, norm_factor=846.4351, grad_norm=1.8340\n",
      "Epoch 9: 206/256 - loss_mc=-0.0063, loss_t=0.0086, loss_r=0.0029, loss=-0.0052, norm_factor=846.6364, grad_norm=1.9513\n",
      "Epoch 9: 207/256 - loss_mc=-0.0064, loss_t=0.0074, loss_r=0.0030, loss=-0.0054, norm_factor=846.8365, grad_norm=1.5163\n",
      "Epoch 9: 208/256 - loss_mc=-0.0063, loss_t=0.0072, loss_r=0.0030, loss=-0.0053, norm_factor=847.0625, grad_norm=1.9930\n",
      "Epoch 9: 209/256 - loss_mc=-0.0057, loss_t=0.0082, loss_r=0.0044, loss=-0.0045, norm_factor=847.2852, grad_norm=1.8436\n",
      "Epoch 9: 210/256 - loss_mc=-0.0064, loss_t=0.0076, loss_r=0.0027, loss=-0.0053, norm_factor=847.4536, grad_norm=1.6801\n",
      "Epoch 9: 211/256 - loss_mc=-0.0061, loss_t=0.0085, loss_r=0.0033, loss=-0.0050, norm_factor=847.6298, grad_norm=1.8253\n",
      "Epoch 9: 212/256 - loss_mc=-0.0065, loss_t=0.0098, loss_r=0.0026, loss=-0.0053, norm_factor=847.7955, grad_norm=1.6797\n",
      "Epoch 9: 213/256 - loss_mc=-0.0066, loss_t=0.0077, loss_r=0.0028, loss=-0.0056, norm_factor=847.9862, grad_norm=1.2766\n",
      "Epoch 9: 214/256 - loss_mc=-0.0062, loss_t=0.0093, loss_r=0.0031, loss=-0.0049, norm_factor=848.2017, grad_norm=1.9428\n",
      "Epoch 9: 215/256 - loss_mc=-0.0069, loss_t=0.0058, loss_r=0.0027, loss=-0.0060, norm_factor=848.4010, grad_norm=1.0951\n",
      "Epoch 9: 216/256 - loss_mc=-0.0065, loss_t=0.0083, loss_r=0.0030, loss=-0.0054, norm_factor=848.6560, grad_norm=1.3891\n",
      "Epoch 9: 217/256 - loss_mc=-0.0066, loss_t=0.0069, loss_r=0.0029, loss=-0.0056, norm_factor=848.9294, grad_norm=1.2327\n",
      "Epoch 9: 218/256 - loss_mc=-0.0066, loss_t=0.0077, loss_r=0.0025, loss=-0.0056, norm_factor=849.2325, grad_norm=1.5871\n",
      "Epoch 9: 219/256 - loss_mc=-0.0065, loss_t=0.0078, loss_r=0.0027, loss=-0.0055, norm_factor=849.5634, grad_norm=1.6407\n",
      "Epoch 9: 220/256 - loss_mc=-0.0067, loss_t=0.0082, loss_r=0.0027, loss=-0.0056, norm_factor=849.9061, grad_norm=1.2550\n",
      "Epoch 9: 221/256 - loss_mc=-0.0055, loss_t=0.0087, loss_r=0.0035, loss=-0.0043, norm_factor=850.2760, grad_norm=1.3890\n",
      "Epoch 9: 222/256 - loss_mc=-0.0065, loss_t=0.0106, loss_r=0.0028, loss=-0.0052, norm_factor=850.5620, grad_norm=1.9392\n",
      "Epoch 9: 223/256 - loss_mc=-0.0065, loss_t=0.0080, loss_r=0.0029, loss=-0.0054, norm_factor=850.8682, grad_norm=1.6331\n",
      "Epoch 9: 224/256 - loss_mc=-0.0065, loss_t=0.0091, loss_r=0.0034, loss=-0.0053, norm_factor=851.1808, grad_norm=1.7428\n",
      "Epoch 9: 225/256 - loss_mc=-0.0060, loss_t=0.0118, loss_r=0.0032, loss=-0.0045, norm_factor=851.5002, grad_norm=1.4567\n",
      "Epoch 9: 226/256 - loss_mc=-0.0065, loss_t=0.0102, loss_r=0.0031, loss=-0.0052, norm_factor=851.7871, grad_norm=2.4305\n",
      "Epoch 9: 227/256 - loss_mc=-0.0064, loss_t=0.0083, loss_r=0.0027, loss=-0.0053, norm_factor=852.0904, grad_norm=1.0139\n",
      "Epoch 9: 228/256 - loss_mc=-0.0063, loss_t=0.0091, loss_r=0.0031, loss=-0.0050, norm_factor=852.3963, grad_norm=2.5741\n",
      "Epoch 9: 229/256 - loss_mc=-0.0064, loss_t=0.0079, loss_r=0.0031, loss=-0.0053, norm_factor=852.6936, grad_norm=1.0300\n",
      "Epoch 9: 230/256 - loss_mc=-0.0064, loss_t=0.0077, loss_r=0.0029, loss=-0.0053, norm_factor=853.0042, grad_norm=1.6036\n",
      "Epoch 9: 231/256 - loss_mc=-0.0066, loss_t=0.0081, loss_r=0.0029, loss=-0.0055, norm_factor=853.3170, grad_norm=1.2297\n",
      "Epoch 9: 232/256 - loss_mc=-0.0068, loss_t=0.0067, loss_r=0.0025, loss=-0.0059, norm_factor=853.6472, grad_norm=1.4393\n",
      "Epoch 9: 233/256 - loss_mc=-0.0064, loss_t=0.0106, loss_r=0.0031, loss=-0.0050, norm_factor=854.0085, grad_norm=1.6504\n",
      "Epoch 9: 234/256 - loss_mc=-0.0065, loss_t=0.0084, loss_r=0.0031, loss=-0.0054, norm_factor=854.3688, grad_norm=1.9184\n",
      "Epoch 9: 235/256 - loss_mc=-0.0062, loss_t=0.0057, loss_r=0.0036, loss=-0.0053, norm_factor=854.7343, grad_norm=1.5327\n",
      "Epoch 9: 236/256 - loss_mc=-0.0058, loss_t=0.0091, loss_r=0.0033, loss=-0.0046, norm_factor=855.0812, grad_norm=2.0654\n",
      "Epoch 9: 237/256 - loss_mc=-0.0060, loss_t=0.0072, loss_r=0.0027, loss=-0.0050, norm_factor=855.3597, grad_norm=1.7223\n",
      "Epoch 9: 238/256 - loss_mc=-0.0063, loss_t=0.0076, loss_r=0.0032, loss=-0.0052, norm_factor=855.5951, grad_norm=1.8352\n",
      "Epoch 9: 239/256 - loss_mc=-0.0063, loss_t=0.0082, loss_r=0.0026, loss=-0.0052, norm_factor=855.8224, grad_norm=2.2930\n",
      "Epoch 9: 240/256 - loss_mc=-0.0067, loss_t=0.0068, loss_r=0.0025, loss=-0.0057, norm_factor=856.0494, grad_norm=1.0552\n",
      "Epoch 9: 241/256 - loss_mc=-0.0062, loss_t=0.0083, loss_r=0.0033, loss=-0.0051, norm_factor=856.3063, grad_norm=2.5850\n",
      "Epoch 9: 242/256 - loss_mc=-0.0059, loss_t=0.0094, loss_r=0.0035, loss=-0.0046, norm_factor=856.5449, grad_norm=2.3090\n",
      "Epoch 9: 243/256 - loss_mc=-0.0066, loss_t=0.0071, loss_r=0.0026, loss=-0.0056, norm_factor=856.7538, grad_norm=1.7241\n",
      "Epoch 9: 244/256 - loss_mc=-0.0066, loss_t=0.0073, loss_r=0.0025, loss=-0.0056, norm_factor=856.9899, grad_norm=1.9243\n",
      "Epoch 9: 245/256 - loss_mc=-0.0052, loss_t=0.0101, loss_r=0.0102, loss=-0.0032, norm_factor=857.2445, grad_norm=2.1700\n",
      "Epoch 9: 246/256 - loss_mc=-0.0065, loss_t=0.0069, loss_r=0.0028, loss=-0.0055, norm_factor=857.3839, grad_norm=1.8136\n",
      "Epoch 9: 247/256 - loss_mc=-0.0049, loss_t=0.0092, loss_r=0.0028, loss=-0.0037, norm_factor=857.5532, grad_norm=2.1312\n",
      "Epoch 9: 248/256 - loss_mc=-0.0064, loss_t=0.0073, loss_r=0.0030, loss=-0.0054, norm_factor=857.6093, grad_norm=1.4998\n",
      "Epoch 9: 249/256 - loss_mc=-0.0056, loss_t=0.0072, loss_r=0.0034, loss=-0.0045, norm_factor=857.6960, grad_norm=1.2765\n",
      "Epoch 9: 250/256 - loss_mc=-0.0063, loss_t=0.0091, loss_r=0.0028, loss=-0.0052, norm_factor=857.7358, grad_norm=1.9369\n",
      "Epoch 9: 251/256 - loss_mc=-0.0064, loss_t=0.0085, loss_r=0.0028, loss=-0.0052, norm_factor=857.7955, grad_norm=1.6603\n",
      "Epoch 9: 252/256 - loss_mc=-0.0066, loss_t=0.0061, loss_r=0.0024, loss=-0.0058, norm_factor=857.8800, grad_norm=1.7466\n",
      "Epoch 9: 253/256 - loss_mc=-0.0064, loss_t=0.0095, loss_r=0.0030, loss=-0.0051, norm_factor=858.0015, grad_norm=1.6785\n",
      "Epoch 9: 254/256 - loss_mc=-0.0064, loss_t=0.0079, loss_r=0.0027, loss=-0.0053, norm_factor=858.1320, grad_norm=1.9865\n",
      "Epoch 9: 255/256 - loss_mc=-0.0068, loss_t=0.0064, loss_r=0.0028, loss=-0.0059, norm_factor=858.2848, grad_norm=1.0173\n",
      "Epoch 9: 256/256 - loss_mc=-0.0061, loss_t=0.0096, loss_r=0.0031, loss=-0.0048, norm_factor=858.4991, grad_norm=2.1549\n",
      "Epoch 10: 1/256 - loss_mc=-0.0066, loss_t=0.0072, loss_r=0.0030, loss=-0.0056, norm_factor=858.6967, grad_norm=1.2168\n",
      "Epoch 10: 2/256 - loss_mc=-0.0067, loss_t=0.0067, loss_r=0.0026, loss=-0.0057, norm_factor=858.9310, grad_norm=1.7307\n",
      "Epoch 10: 3/256 - loss_mc=-0.0065, loss_t=0.0074, loss_r=0.0028, loss=-0.0055, norm_factor=859.2034, grad_norm=0.9857\n",
      "Epoch 10: 4/256 - loss_mc=-0.0064, loss_t=0.0058, loss_r=0.0027, loss=-0.0056, norm_factor=859.4874, grad_norm=1.4840\n",
      "Epoch 10: 5/256 - loss_mc=-0.0068, loss_t=0.0058, loss_r=0.0027, loss=-0.0059, norm_factor=859.7747, grad_norm=1.4366\n",
      "Epoch 10: 6/256 - loss_mc=-0.0063, loss_t=0.0078, loss_r=0.0025, loss=-0.0053, norm_factor=860.1096, grad_norm=1.5910\n",
      "Epoch 10: 7/256 - loss_mc=-0.0064, loss_t=0.0076, loss_r=0.0054, loss=-0.0051, norm_factor=860.4452, grad_norm=1.2882\n",
      "Epoch 10: 8/256 - loss_mc=-0.0061, loss_t=0.0108, loss_r=0.0029, loss=-0.0048, norm_factor=860.7867, grad_norm=2.0819\n",
      "Epoch 10: 9/256 - loss_mc=-0.0048, loss_t=0.0099, loss_r=0.0037, loss=-0.0035, norm_factor=861.0937, grad_norm=1.6027\n",
      "Epoch 10: 10/256 - loss_mc=-0.0067, loss_t=0.0070, loss_r=0.0030, loss=-0.0057, norm_factor=861.2661, grad_norm=1.8011\n",
      "Epoch 10: 11/256 - loss_mc=-0.0066, loss_t=0.0071, loss_r=0.0024, loss=-0.0056, norm_factor=861.4836, grad_norm=1.1145\n",
      "Epoch 10: 12/256 - loss_mc=-0.0065, loss_t=0.0084, loss_r=0.0030, loss=-0.0053, norm_factor=861.7281, grad_norm=2.1338\n",
      "Epoch 10: 13/256 - loss_mc=-0.0066, loss_t=0.0079, loss_r=0.0023, loss=-0.0056, norm_factor=861.9838, grad_norm=1.7528\n",
      "Epoch 10: 14/256 - loss_mc=-0.0067, loss_t=0.0074, loss_r=0.0026, loss=-0.0057, norm_factor=862.2623, grad_norm=1.5090\n",
      "Epoch 10: 15/256 - loss_mc=-0.0067, loss_t=0.0052, loss_r=0.0024, loss=-0.0060, norm_factor=862.5825, grad_norm=1.1605\n",
      "Epoch 10: 16/256 - loss_mc=-0.0066, loss_t=0.0072, loss_r=0.0028, loss=-0.0056, norm_factor=862.9424, grad_norm=1.7302\n",
      "Epoch 10: 17/256 - loss_mc=-0.0064, loss_t=0.0068, loss_r=0.0027, loss=-0.0054, norm_factor=863.3192, grad_norm=1.4697\n",
      "Epoch 10: 18/256 - loss_mc=-0.0062, loss_t=0.0104, loss_r=0.0027, loss=-0.0049, norm_factor=863.7020, grad_norm=2.0548\n",
      "Epoch 10: 19/256 - loss_mc=-0.0063, loss_t=0.0089, loss_r=0.0029, loss=-0.0051, norm_factor=864.0609, grad_norm=1.4628\n",
      "Epoch 10: 20/256 - loss_mc=-0.0066, loss_t=0.0091, loss_r=0.0026, loss=-0.0054, norm_factor=864.3947, grad_norm=2.3526\n",
      "Epoch 10: 21/256 - loss_mc=-0.0066, loss_t=0.0075, loss_r=0.0026, loss=-0.0056, norm_factor=864.7373, grad_norm=1.4644\n",
      "Epoch 10: 22/256 - loss_mc=-0.0062, loss_t=0.0081, loss_r=0.0029, loss=-0.0051, norm_factor=865.0953, grad_norm=2.2352\n",
      "Epoch 10: 23/256 - loss_mc=-0.0059, loss_t=0.0071, loss_r=0.0030, loss=-0.0049, norm_factor=865.4460, grad_norm=0.9559\n",
      "Epoch 10: 24/256 - loss_mc=-0.0065, loss_t=0.0077, loss_r=0.0028, loss=-0.0054, norm_factor=865.7477, grad_norm=1.7448\n",
      "Epoch 10: 25/256 - loss_mc=-0.0065, loss_t=0.0062, loss_r=0.0027, loss=-0.0056, norm_factor=866.0591, grad_norm=1.5212\n",
      "Epoch 10: 26/256 - loss_mc=-0.0069, loss_t=0.0077, loss_r=0.0024, loss=-0.0059, norm_factor=866.3934, grad_norm=1.1743\n",
      "Epoch 10: 27/256 - loss_mc=-0.0065, loss_t=0.0074, loss_r=0.0026, loss=-0.0055, norm_factor=866.7788, grad_norm=2.2061\n",
      "Epoch 10: 28/256 - loss_mc=-0.0064, loss_t=0.0075, loss_r=0.0031, loss=-0.0054, norm_factor=867.1833, grad_norm=1.3248\n",
      "Epoch 10: 29/256 - loss_mc=-0.0066, loss_t=0.0078, loss_r=0.0029, loss=-0.0055, norm_factor=867.5820, grad_norm=1.9355\n",
      "Epoch 10: 30/256 - loss_mc=-0.0066, loss_t=0.0069, loss_r=0.0026, loss=-0.0057, norm_factor=867.9872, grad_norm=0.8966\n",
      "Epoch 10: 31/256 - loss_mc=-0.0066, loss_t=0.0085, loss_r=0.0026, loss=-0.0055, norm_factor=868.4225, grad_norm=1.9446\n",
      "Epoch 10: 32/256 - loss_mc=-0.0069, loss_t=0.0057, loss_r=0.0025, loss=-0.0061, norm_factor=868.8864, grad_norm=0.8449\n",
      "Epoch 10: 33/256 - loss_mc=-0.0067, loss_t=0.0074, loss_r=0.0024, loss=-0.0058, norm_factor=869.3901, grad_norm=1.5624\n",
      "Epoch 10: 34/256 - loss_mc=-0.0066, loss_t=0.0059, loss_r=0.0025, loss=-0.0058, norm_factor=869.9042, grad_norm=1.2477\n",
      "Epoch 10: 35/256 - loss_mc=-0.0067, loss_t=0.0073, loss_r=0.0027, loss=-0.0057, norm_factor=870.4160, grad_norm=0.9643\n",
      "Epoch 10: 36/256 - loss_mc=-0.0066, loss_t=0.0077, loss_r=0.0026, loss=-0.0056, norm_factor=870.9388, grad_norm=1.3977\n",
      "Epoch 10: 37/256 - loss_mc=-0.0065, loss_t=0.0059, loss_r=0.0029, loss=-0.0056, norm_factor=871.4620, grad_norm=0.9803\n",
      "Epoch 10: 38/256 - loss_mc=-0.0063, loss_t=0.0069, loss_r=0.0034, loss=-0.0053, norm_factor=871.9829, grad_norm=1.7727\n",
      "Epoch 10: 39/256 - loss_mc=-0.0069, loss_t=0.0073, loss_r=0.0023, loss=-0.0059, norm_factor=872.4843, grad_norm=0.8446\n",
      "Epoch 10: 40/256 - loss_mc=-0.0065, loss_t=0.0068, loss_r=0.0025, loss=-0.0056, norm_factor=873.0181, grad_norm=1.2836\n",
      "Epoch 10: 41/256 - loss_mc=-0.0068, loss_t=0.0068, loss_r=0.0024, loss=-0.0058, norm_factor=873.5527, grad_norm=0.9608\n",
      "Epoch 10: 42/256 - loss_mc=-0.0068, loss_t=0.0084, loss_r=0.0023, loss=-0.0058, norm_factor=874.1031, grad_norm=1.5742\n",
      "Epoch 10: 43/256 - loss_mc=-0.0066, loss_t=0.0070, loss_r=0.0028, loss=-0.0056, norm_factor=874.6676, grad_norm=0.8634\n",
      "Epoch 10: 44/256 - loss_mc=-0.0063, loss_t=0.0069, loss_r=0.0033, loss=-0.0053, norm_factor=875.2283, grad_norm=1.5650\n",
      "Epoch 10: 45/256 - loss_mc=-0.0068, loss_t=0.0055, loss_r=0.0026, loss=-0.0060, norm_factor=875.7545, grad_norm=1.2677\n",
      "Epoch 10: 46/256 - loss_mc=-0.0069, loss_t=0.0065, loss_r=0.0024, loss=-0.0060, norm_factor=876.2980, grad_norm=1.0399\n",
      "Epoch 10: 47/256 - loss_mc=-0.0065, loss_t=0.0069, loss_r=0.0027, loss=-0.0055, norm_factor=876.8587, grad_norm=0.8017\n",
      "Epoch 10: 48/256 - loss_mc=-0.0063, loss_t=0.0104, loss_r=0.0031, loss=-0.0049, norm_factor=877.4080, grad_norm=1.5369\n",
      "Epoch 10: 49/256 - loss_mc=-0.0066, loss_t=0.0059, loss_r=0.0021, loss=-0.0057, norm_factor=877.9277, grad_norm=0.7733\n",
      "Epoch 10: 50/256 - loss_mc=-0.0063, loss_t=0.0069, loss_r=0.0026, loss=-0.0053, norm_factor=878.4460, grad_norm=1.4806\n",
      "Epoch 10: 51/256 - loss_mc=-0.0065, loss_t=0.0063, loss_r=0.0026, loss=-0.0056, norm_factor=878.9500, grad_norm=1.0081\n",
      "Epoch 10: 52/256 - loss_mc=-0.0064, loss_t=0.0078, loss_r=0.0027, loss=-0.0053, norm_factor=879.4623, grad_norm=1.5015\n",
      "Epoch 10: 53/256 - loss_mc=-0.0067, loss_t=0.0052, loss_r=0.0025, loss=-0.0059, norm_factor=879.9620, grad_norm=0.9656\n",
      "Epoch 10: 54/256 - loss_mc=-0.0067, loss_t=0.0073, loss_r=0.0023, loss=-0.0057, norm_factor=880.4778, grad_norm=1.4952\n",
      "Epoch 10: 55/256 - loss_mc=-0.0067, loss_t=0.0081, loss_r=0.0023, loss=-0.0057, norm_factor=881.0123, grad_norm=1.5523\n",
      "Epoch 10: 56/256 - loss_mc=-0.0065, loss_t=0.0061, loss_r=0.0025, loss=-0.0056, norm_factor=881.5568, grad_norm=1.5858\n",
      "Epoch 10: 57/256 - loss_mc=-0.0064, loss_t=0.0073, loss_r=0.0028, loss=-0.0054, norm_factor=882.0945, grad_norm=1.3990\n",
      "Epoch 10: 58/256 - loss_mc=-0.0063, loss_t=0.0069, loss_r=0.0027, loss=-0.0054, norm_factor=882.6134, grad_norm=1.4864\n",
      "Epoch 10: 59/256 - loss_mc=-0.0065, loss_t=0.0080, loss_r=0.0029, loss=-0.0055, norm_factor=883.1088, grad_norm=1.9028\n",
      "Epoch 10: 60/256 - loss_mc=-0.0067, loss_t=0.0067, loss_r=0.0027, loss=-0.0057, norm_factor=883.6083, grad_norm=1.7042\n",
      "Epoch 10: 61/256 - loss_mc=-0.0063, loss_t=0.0097, loss_r=0.0032, loss=-0.0050, norm_factor=884.1254, grad_norm=1.7487\n",
      "Epoch 10: 62/256 - loss_mc=-0.0063, loss_t=0.0097, loss_r=0.0030, loss=-0.0050, norm_factor=884.6121, grad_norm=2.0969\n",
      "Epoch 10: 63/256 - loss_mc=-0.0068, loss_t=0.0092, loss_r=0.0025, loss=-0.0056, norm_factor=885.0772, grad_norm=1.6495\n",
      "Epoch 10: 64/256 - loss_mc=-0.0062, loss_t=0.0083, loss_r=0.0027, loss=-0.0051, norm_factor=885.5748, grad_norm=1.9715\n",
      "Epoch 10: 65/256 - loss_mc=-0.0064, loss_t=0.0077, loss_r=0.0029, loss=-0.0054, norm_factor=886.0465, grad_norm=1.3806\n",
      "Epoch 10: 66/256 - loss_mc=-0.0061, loss_t=0.0078, loss_r=0.0031, loss=-0.0050, norm_factor=886.4965, grad_norm=1.9651\n",
      "Epoch 10: 67/256 - loss_mc=-0.0069, loss_t=0.0072, loss_r=0.0023, loss=-0.0059, norm_factor=886.9022, grad_norm=1.4272\n",
      "Epoch 10: 68/256 - loss_mc=-0.0059, loss_t=0.0082, loss_r=0.0032, loss=-0.0047, norm_factor=887.3392, grad_norm=1.8533\n",
      "Epoch 10: 69/256 - loss_mc=-0.0066, loss_t=0.0064, loss_r=0.0025, loss=-0.0057, norm_factor=887.7133, grad_norm=1.4196\n",
      "Epoch 10: 70/256 - loss_mc=-0.0066, loss_t=0.0080, loss_r=0.0025, loss=-0.0055, norm_factor=888.0861, grad_norm=1.8943\n",
      "Epoch 10: 71/256 - loss_mc=-0.0065, loss_t=0.0067, loss_r=0.0025, loss=-0.0056, norm_factor=888.4705, grad_norm=1.6586\n",
      "Epoch 10: 72/256 - loss_mc=-0.0063, loss_t=0.0081, loss_r=0.0029, loss=-0.0052, norm_factor=888.8671, grad_norm=1.6525\n",
      "Epoch 10: 73/256 - loss_mc=-0.0066, loss_t=0.0068, loss_r=0.0022, loss=-0.0057, norm_factor=889.2512, grad_norm=1.4499\n",
      "Epoch 10: 74/256 - loss_mc=-0.0061, loss_t=0.0094, loss_r=0.0029, loss=-0.0049, norm_factor=889.6567, grad_norm=1.4972\n",
      "Epoch 10: 75/256 - loss_mc=-0.0063, loss_t=0.0066, loss_r=0.0027, loss=-0.0054, norm_factor=890.0207, grad_norm=1.3279\n",
      "Epoch 10: 76/256 - loss_mc=-0.0068, loss_t=0.0077, loss_r=0.0024, loss=-0.0058, norm_factor=890.3734, grad_norm=0.9359\n",
      "Epoch 10: 77/256 - loss_mc=-0.0063, loss_t=0.0088, loss_r=0.0026, loss=-0.0052, norm_factor=890.7613, grad_norm=2.1055\n",
      "Epoch 10: 78/256 - loss_mc=-0.0064, loss_t=0.0097, loss_r=0.0025, loss=-0.0052, norm_factor=891.1575, grad_norm=2.0187\n",
      "Epoch 10: 79/256 - loss_mc=-0.0064, loss_t=0.0077, loss_r=0.0025, loss=-0.0053, norm_factor=891.5441, grad_norm=1.9997\n",
      "Epoch 10: 80/256 - loss_mc=-0.0064, loss_t=0.0070, loss_r=0.0029, loss=-0.0054, norm_factor=891.9265, grad_norm=1.3554\n",
      "Epoch 10: 81/256 - loss_mc=-0.0063, loss_t=0.0071, loss_r=0.0028, loss=-0.0053, norm_factor=892.3059, grad_norm=2.0637\n",
      "Epoch 10: 82/256 - loss_mc=-0.0065, loss_t=0.0056, loss_r=0.0024, loss=-0.0057, norm_factor=892.6729, grad_norm=1.1588\n",
      "Epoch 10: 83/256 - loss_mc=-0.0061, loss_t=0.0080, loss_r=0.0030, loss=-0.0050, norm_factor=893.0563, grad_norm=1.8137\n",
      "Epoch 10: 84/256 - loss_mc=-0.0063, loss_t=0.0091, loss_r=0.0026, loss=-0.0052, norm_factor=893.4044, grad_norm=1.3171\n",
      "Epoch 10: 85/256 - loss_mc=-0.0066, loss_t=0.0077, loss_r=0.0024, loss=-0.0056, norm_factor=893.7448, grad_norm=1.6223\n",
      "Epoch 10: 86/256 - loss_mc=-0.0062, loss_t=0.0099, loss_r=0.0027, loss=-0.0050, norm_factor=894.1081, grad_norm=1.3682\n",
      "Epoch 10: 87/256 - loss_mc=-0.0064, loss_t=0.0067, loss_r=0.0023, loss=-0.0055, norm_factor=894.4567, grad_norm=1.7565\n",
      "Epoch 10: 88/256 - loss_mc=-0.0061, loss_t=0.0076, loss_r=0.0027, loss=-0.0051, norm_factor=894.8081, grad_norm=1.4390\n",
      "Epoch 10: 89/256 - loss_mc=-0.0061, loss_t=0.0071, loss_r=0.0028, loss=-0.0051, norm_factor=895.1414, grad_norm=1.3761\n",
      "Epoch 10: 90/256 - loss_mc=-0.0065, loss_t=0.0073, loss_r=0.0025, loss=-0.0055, norm_factor=895.4476, grad_norm=1.3979\n",
      "Epoch 10: 91/256 - loss_mc=-0.0064, loss_t=0.0062, loss_r=0.0027, loss=-0.0055, norm_factor=895.7606, grad_norm=1.3324\n",
      "Epoch 10: 92/256 - loss_mc=-0.0066, loss_t=0.0086, loss_r=0.0027, loss=-0.0054, norm_factor=896.0662, grad_norm=1.4999\n",
      "Epoch 10: 93/256 - loss_mc=-0.0062, loss_t=0.0088, loss_r=0.0028, loss=-0.0050, norm_factor=896.3961, grad_norm=1.8869\n",
      "Epoch 10: 94/256 - loss_mc=-0.0065, loss_t=0.0069, loss_r=0.0026, loss=-0.0056, norm_factor=896.7009, grad_norm=1.2953\n",
      "Epoch 10: 95/256 - loss_mc=-0.0061, loss_t=0.0104, loss_r=0.0032, loss=-0.0047, norm_factor=897.0283, grad_norm=2.1650\n",
      "Epoch 10: 96/256 - loss_mc=-0.0062, loss_t=0.0087, loss_r=0.0033, loss=-0.0050, norm_factor=897.3265, grad_norm=2.1074\n",
      "Epoch 10: 97/256 - loss_mc=-0.0064, loss_t=0.0079, loss_r=0.0026, loss=-0.0054, norm_factor=897.6279, grad_norm=1.8160\n",
      "Epoch 10: 98/256 - loss_mc=-0.0063, loss_t=0.0093, loss_r=0.0028, loss=-0.0051, norm_factor=897.9378, grad_norm=2.5410\n",
      "Epoch 10: 99/256 - loss_mc=-0.0062, loss_t=0.0095, loss_r=0.0028, loss=-0.0049, norm_factor=898.2430, grad_norm=2.2497\n",
      "Epoch 10: 100/256 - loss_mc=-0.0060, loss_t=0.0088, loss_r=0.0033, loss=-0.0048, norm_factor=898.5135, grad_norm=2.1692\n",
      "Epoch 10: 101/256 - loss_mc=-0.0026, loss_t=0.0085, loss_r=0.0033, loss=-0.0014, norm_factor=898.7435, grad_norm=2.0799\n",
      "Epoch 10: 102/256 - loss_mc=-0.0059, loss_t=0.0090, loss_r=0.0032, loss=-0.0047, norm_factor=898.5881, grad_norm=2.1938\n",
      "Epoch 10: 103/256 - loss_mc=-0.0064, loss_t=0.0083, loss_r=0.0027, loss=-0.0053, norm_factor=898.4311, grad_norm=1.9678\n",
      "Epoch 10: 104/256 - loss_mc=-0.0065, loss_t=0.0088, loss_r=0.0024, loss=-0.0053, norm_factor=898.3233, grad_norm=1.7603\n",
      "Epoch 10: 105/256 - loss_mc=-0.0061, loss_t=0.0105, loss_r=0.0031, loss=-0.0048, norm_factor=898.2759, grad_norm=2.3065\n",
      "Epoch 10: 106/256 - loss_mc=-0.0065, loss_t=0.0078, loss_r=0.0026, loss=-0.0055, norm_factor=898.2501, grad_norm=1.9879\n",
      "Epoch 10: 107/256 - loss_mc=-0.0062, loss_t=0.0096, loss_r=0.0030, loss=-0.0049, norm_factor=898.2842, grad_norm=2.3569\n",
      "Epoch 10: 108/256 - loss_mc=-0.0059, loss_t=0.0083, loss_r=0.0031, loss=-0.0048, norm_factor=898.3303, grad_norm=1.6485\n",
      "Epoch 10: 109/256 - loss_mc=-0.0057, loss_t=0.0097, loss_r=0.0037, loss=-0.0044, norm_factor=898.3627, grad_norm=1.7642\n",
      "Epoch 10: 110/256 - loss_mc=-0.0061, loss_t=0.0074, loss_r=0.0030, loss=-0.0051, norm_factor=898.3650, grad_norm=1.6383\n",
      "Epoch 10: 111/256 - loss_mc=-0.0064, loss_t=0.0083, loss_r=0.0026, loss=-0.0053, norm_factor=898.3708, grad_norm=1.3069\n",
      "Epoch 10: 112/256 - loss_mc=-0.0034, loss_t=0.0126, loss_r=0.0033, loss=-0.0018, norm_factor=898.4017, grad_norm=1.9900\n",
      "Epoch 10: 113/256 - loss_mc=-0.0066, loss_t=0.0066, loss_r=0.0026, loss=-0.0056, norm_factor=898.1457, grad_norm=1.0912\n",
      "Epoch 10: 114/256 - loss_mc=-0.0056, loss_t=0.0091, loss_r=0.0032, loss=-0.0044, norm_factor=897.9597, grad_norm=2.0265\n",
      "Epoch 10: 115/256 - loss_mc=-0.0065, loss_t=0.0066, loss_r=0.0026, loss=-0.0055, norm_factor=897.7676, grad_norm=1.5521\n",
      "Epoch 10: 116/256 - loss_mc=-0.0062, loss_t=0.0078, loss_r=0.0027, loss=-0.0051, norm_factor=897.6437, grad_norm=1.6994\n",
      "Epoch 10: 117/256 - loss_mc=-0.0063, loss_t=0.0077, loss_r=0.0027, loss=-0.0053, norm_factor=897.5460, grad_norm=1.5387\n",
      "Epoch 10: 118/256 - loss_mc=-0.0063, loss_t=0.0105, loss_r=0.0027, loss=-0.0050, norm_factor=897.4956, grad_norm=1.6968\n",
      "Epoch 10: 119/256 - loss_mc=-0.0062, loss_t=0.0089, loss_r=0.0028, loss=-0.0051, norm_factor=897.4843, grad_norm=2.0963\n",
      "Epoch 10: 120/256 - loss_mc=-0.0065, loss_t=0.0079, loss_r=0.0026, loss=-0.0054, norm_factor=897.5065, grad_norm=1.2896\n",
      "Epoch 10: 121/256 - loss_mc=-0.0064, loss_t=0.0078, loss_r=0.0026, loss=-0.0054, norm_factor=897.5681, grad_norm=1.7948\n",
      "Epoch 10: 122/256 - loss_mc=-0.0061, loss_t=0.0087, loss_r=0.0029, loss=-0.0050, norm_factor=897.6626, grad_norm=2.1818\n",
      "Epoch 10: 123/256 - loss_mc=-0.0060, loss_t=0.0087, loss_r=0.0032, loss=-0.0048, norm_factor=897.7383, grad_norm=1.6287\n",
      "Epoch 10: 124/256 - loss_mc=-0.0065, loss_t=0.0065, loss_r=0.0026, loss=-0.0056, norm_factor=897.8031, grad_norm=1.6873\n",
      "Epoch 10: 125/256 - loss_mc=-0.0066, loss_t=0.0079, loss_r=0.0026, loss=-0.0055, norm_factor=897.9032, grad_norm=1.0850\n",
      "Epoch 10: 126/256 - loss_mc=-0.0062, loss_t=0.0085, loss_r=0.0031, loss=-0.0050, norm_factor=898.0408, grad_norm=2.1578\n",
      "Epoch 10: 127/256 - loss_mc=-0.0067, loss_t=0.0065, loss_r=0.0025, loss=-0.0058, norm_factor=898.1830, grad_norm=1.0842\n",
      "Epoch 10: 128/256 - loss_mc=-0.0064, loss_t=0.0066, loss_r=0.0028, loss=-0.0055, norm_factor=898.3824, grad_norm=1.3812\n",
      "Epoch 10: 129/256 - loss_mc=-0.0063, loss_t=0.0079, loss_r=0.0030, loss=-0.0052, norm_factor=898.6123, grad_norm=1.3351\n",
      "Epoch 10: 130/256 - loss_mc=-0.0065, loss_t=0.0079, loss_r=0.0025, loss=-0.0054, norm_factor=898.8501, grad_norm=0.9709\n",
      "Epoch 10: 131/256 - loss_mc=-0.0062, loss_t=0.0100, loss_r=0.0029, loss=-0.0049, norm_factor=899.1044, grad_norm=1.2801\n",
      "Epoch 10: 132/256 - loss_mc=-0.0067, loss_t=0.0085, loss_r=0.0023, loss=-0.0056, norm_factor=899.3340, grad_norm=1.1309\n",
      "Epoch 10: 133/256 - loss_mc=-0.0066, loss_t=0.0079, loss_r=0.0025, loss=-0.0056, norm_factor=899.5970, grad_norm=1.0364\n",
      "Epoch 10: 134/256 - loss_mc=-0.0061, loss_t=0.0060, loss_r=0.0028, loss=-0.0052, norm_factor=899.8896, grad_norm=0.9968\n",
      "Epoch 10: 135/256 - loss_mc=-0.0067, loss_t=0.0054, loss_r=0.0025, loss=-0.0059, norm_factor=900.1512, grad_norm=1.0907\n",
      "Epoch 10: 136/256 - loss_mc=-0.0066, loss_t=0.0062, loss_r=0.0024, loss=-0.0058, norm_factor=900.4448, grad_norm=1.1062\n",
      "Epoch 10: 137/256 - loss_mc=-0.0056, loss_t=0.0068, loss_r=0.0025, loss=-0.0047, norm_factor=900.7703, grad_norm=1.1819\n",
      "Epoch 10: 138/256 - loss_mc=-0.0063, loss_t=0.0068, loss_r=0.0027, loss=-0.0053, norm_factor=901.0201, grad_norm=1.2311\n",
      "Epoch 10: 139/256 - loss_mc=-0.0063, loss_t=0.0093, loss_r=0.0026, loss=-0.0051, norm_factor=901.2761, grad_norm=1.4571\n",
      "Epoch 10: 140/256 - loss_mc=-0.0066, loss_t=0.0072, loss_r=0.0026, loss=-0.0056, norm_factor=901.5487, grad_norm=1.2842\n",
      "Epoch 10: 141/256 - loss_mc=-0.0065, loss_t=0.0070, loss_r=0.0024, loss=-0.0056, norm_factor=901.8647, grad_norm=1.4978\n",
      "Epoch 10: 142/256 - loss_mc=-0.0067, loss_t=0.0058, loss_r=0.0022, loss=-0.0059, norm_factor=902.2025, grad_norm=1.2867\n",
      "Epoch 10: 143/256 - loss_mc=-0.0066, loss_t=0.0075, loss_r=0.0023, loss=-0.0056, norm_factor=902.5763, grad_norm=1.3658\n",
      "Epoch 10: 144/256 - loss_mc=-0.0061, loss_t=0.0073, loss_r=0.0025, loss=-0.0051, norm_factor=902.9580, grad_norm=1.2183\n",
      "Epoch 10: 145/256 - loss_mc=-0.0064, loss_t=0.0074, loss_r=0.0028, loss=-0.0053, norm_factor=903.3135, grad_norm=1.0950\n",
      "Epoch 10: 146/256 - loss_mc=-0.0068, loss_t=0.0063, loss_r=0.0025, loss=-0.0059, norm_factor=903.6755, grad_norm=0.7754\n",
      "Epoch 10: 147/256 - loss_mc=-0.0065, loss_t=0.0060, loss_r=0.0028, loss=-0.0056, norm_factor=904.0669, grad_norm=1.1920\n",
      "Epoch 10: 148/256 - loss_mc=-0.0066, loss_t=0.0055, loss_r=0.0023, loss=-0.0059, norm_factor=904.4606, grad_norm=1.2525\n",
      "Epoch 10: 149/256 - loss_mc=-0.0070, loss_t=0.0067, loss_r=0.0021, loss=-0.0061, norm_factor=904.8908, grad_norm=1.3837\n",
      "Epoch 10: 150/256 - loss_mc=-0.0059, loss_t=0.0072, loss_r=0.0028, loss=-0.0049, norm_factor=905.3719, grad_norm=1.5334\n",
      "Epoch 10: 151/256 - loss_mc=-0.0060, loss_t=0.0071, loss_r=0.0041, loss=-0.0048, norm_factor=905.8019, grad_norm=1.1882\n",
      "Epoch 10: 152/256 - loss_mc=-0.0060, loss_t=0.0068, loss_r=0.0029, loss=-0.0051, norm_factor=906.1719, grad_norm=1.4210\n",
      "Epoch 10: 153/256 - loss_mc=-0.0066, loss_t=0.0059, loss_r=0.0028, loss=-0.0057, norm_factor=906.5079, grad_norm=0.9035\n",
      "Epoch 10: 154/256 - loss_mc=-0.0063, loss_t=0.0075, loss_r=0.0026, loss=-0.0053, norm_factor=906.8530, grad_norm=2.0505\n",
      "Epoch 10: 155/256 - loss_mc=-0.0063, loss_t=0.0081, loss_r=0.0029, loss=-0.0052, norm_factor=907.1747, grad_norm=1.7610\n",
      "Epoch 10: 156/256 - loss_mc=-0.0067, loss_t=0.0057, loss_r=0.0022, loss=-0.0059, norm_factor=907.5007, grad_norm=1.5019\n",
      "Epoch 10: 157/256 - loss_mc=-0.0063, loss_t=0.0065, loss_r=0.0029, loss=-0.0054, norm_factor=907.8671, grad_norm=1.3570\n",
      "Epoch 10: 158/256 - loss_mc=-0.0068, loss_t=0.0068, loss_r=0.0021, loss=-0.0059, norm_factor=908.2179, grad_norm=1.6570\n",
      "Epoch 10: 159/256 - loss_mc=-0.0065, loss_t=0.0062, loss_r=0.0026, loss=-0.0056, norm_factor=908.6062, grad_norm=1.0984\n",
      "Epoch 10: 160/256 - loss_mc=-0.0060, loss_t=0.0075, loss_r=0.0028, loss=-0.0049, norm_factor=909.0059, grad_norm=1.7709\n",
      "Epoch 10: 161/256 - loss_mc=-0.0064, loss_t=0.0068, loss_r=0.0027, loss=-0.0054, norm_factor=909.3633, grad_norm=1.0647\n",
      "Epoch 10: 162/256 - loss_mc=-0.0066, loss_t=0.0066, loss_r=0.0026, loss=-0.0057, norm_factor=909.7234, grad_norm=1.5408\n",
      "Epoch 10: 163/256 - loss_mc=-0.0065, loss_t=0.0067, loss_r=0.0025, loss=-0.0056, norm_factor=910.1003, grad_norm=1.2249\n",
      "Epoch 10: 164/256 - loss_mc=-0.0065, loss_t=0.0076, loss_r=0.0024, loss=-0.0055, norm_factor=910.4916, grad_norm=1.4125\n",
      "Epoch 10: 165/256 - loss_mc=-0.0065, loss_t=0.0055, loss_r=0.0025, loss=-0.0057, norm_factor=910.9025, grad_norm=1.2208\n",
      "Epoch 10: 166/256 - loss_mc=-0.0062, loss_t=0.0070, loss_r=0.0028, loss=-0.0053, norm_factor=911.3160, grad_norm=1.3818\n",
      "Epoch 10: 167/256 - loss_mc=-0.0067, loss_t=0.0066, loss_r=0.0023, loss=-0.0058, norm_factor=911.7006, grad_norm=1.3624\n",
      "Epoch 10: 168/256 - loss_mc=-0.0064, loss_t=0.0061, loss_r=0.0026, loss=-0.0055, norm_factor=912.1194, grad_norm=1.2005\n",
      "Epoch 10: 169/256 - loss_mc=-0.0065, loss_t=0.0062, loss_r=0.0026, loss=-0.0056, norm_factor=912.5431, grad_norm=0.9937\n",
      "Epoch 10: 170/256 - loss_mc=-0.0065, loss_t=0.0071, loss_r=0.0023, loss=-0.0056, norm_factor=912.9646, grad_norm=1.4352\n",
      "Epoch 10: 171/256 - loss_mc=-0.0066, loss_t=0.0057, loss_r=0.0021, loss=-0.0058, norm_factor=913.3752, grad_norm=1.0581\n",
      "Epoch 10: 172/256 - loss_mc=-0.0066, loss_t=0.0062, loss_r=0.0024, loss=-0.0058, norm_factor=913.8035, grad_norm=1.3737\n",
      "Epoch 10: 173/256 - loss_mc=-0.0067, loss_t=0.0065, loss_r=0.0021, loss=-0.0059, norm_factor=914.2546, grad_norm=1.2042\n",
      "Epoch 10: 174/256 - loss_mc=-0.0065, loss_t=0.0071, loss_r=0.0023, loss=-0.0056, norm_factor=914.7424, grad_norm=1.0928\n",
      "Epoch 10: 175/256 - loss_mc=-0.0068, loss_t=0.0061, loss_r=0.0020, loss=-0.0060, norm_factor=915.2317, grad_norm=1.4638\n",
      "Epoch 10: 176/256 - loss_mc=-0.0069, loss_t=0.0052, loss_r=0.0021, loss=-0.0061, norm_factor=915.7393, grad_norm=0.8507\n",
      "Epoch 10: 177/256 - loss_mc=-0.0059, loss_t=0.0078, loss_r=0.0025, loss=-0.0049, norm_factor=916.2717, grad_norm=1.5461\n",
      "Epoch 10: 178/256 - loss_mc=-0.0066, loss_t=0.0060, loss_r=0.0024, loss=-0.0057, norm_factor=916.7434, grad_norm=0.8808\n",
      "Epoch 10: 179/256 - loss_mc=-0.0067, loss_t=0.0073, loss_r=0.0024, loss=-0.0057, norm_factor=917.2180, grad_norm=1.2078\n",
      "Epoch 10: 180/256 - loss_mc=-0.0064, loss_t=0.0088, loss_r=0.0024, loss=-0.0053, norm_factor=917.7094, grad_norm=1.3918\n",
      "Epoch 10: 181/256 - loss_mc=-0.0063, loss_t=0.0056, loss_r=0.0025, loss=-0.0055, norm_factor=918.1879, grad_norm=1.5280\n",
      "Epoch 10: 182/256 - loss_mc=-0.0064, loss_t=0.0061, loss_r=0.0026, loss=-0.0056, norm_factor=918.6482, grad_norm=1.1946\n",
      "Epoch 10: 183/256 - loss_mc=-0.0065, loss_t=0.0072, loss_r=0.0024, loss=-0.0055, norm_factor=919.1078, grad_norm=1.6246\n",
      "Epoch 10: 184/256 - loss_mc=-0.0066, loss_t=0.0054, loss_r=0.0024, loss=-0.0058, norm_factor=919.5764, grad_norm=1.1495\n",
      "Epoch 10: 185/256 - loss_mc=-0.0061, loss_t=0.0072, loss_r=0.0028, loss=-0.0051, norm_factor=920.0620, grad_norm=1.7737\n",
      "Epoch 10: 186/256 - loss_mc=-0.0065, loss_t=0.0086, loss_r=0.0024, loss=-0.0054, norm_factor=920.4994, grad_norm=1.3004\n",
      "Epoch 10: 187/256 - loss_mc=-0.0065, loss_t=0.0063, loss_r=0.0024, loss=-0.0057, norm_factor=920.9447, grad_norm=1.7659\n",
      "Epoch 10: 188/256 - loss_mc=-0.0063, loss_t=0.0063, loss_r=0.0025, loss=-0.0054, norm_factor=921.3985, grad_norm=1.4610\n",
      "Epoch 10: 189/256 - loss_mc=-0.0062, loss_t=0.0063, loss_r=0.0027, loss=-0.0053, norm_factor=921.8258, grad_norm=1.6026\n",
      "Epoch 10: 190/256 - loss_mc=-0.0066, loss_t=0.0070, loss_r=0.0024, loss=-0.0057, norm_factor=922.2262, grad_norm=1.4921\n",
      "Epoch 10: 191/256 - loss_mc=-0.0062, loss_t=0.0061, loss_r=0.0026, loss=-0.0054, norm_factor=922.6589, grad_norm=1.7124\n",
      "Epoch 10: 192/256 - loss_mc=-0.0063, loss_t=0.0070, loss_r=0.0025, loss=-0.0054, norm_factor=923.0709, grad_norm=1.5275\n",
      "Epoch 10: 193/256 - loss_mc=-0.0064, loss_t=0.0088, loss_r=0.0025, loss=-0.0053, norm_factor=923.4760, grad_norm=1.9593\n",
      "Epoch 10: 194/256 - loss_mc=-0.0068, loss_t=0.0055, loss_r=0.0020, loss=-0.0061, norm_factor=923.8843, grad_norm=1.2204\n",
      "Epoch 10: 195/256 - loss_mc=-0.0063, loss_t=0.0069, loss_r=0.0026, loss=-0.0053, norm_factor=924.3318, grad_norm=1.7120\n",
      "Epoch 10: 196/256 - loss_mc=-0.0066, loss_t=0.0083, loss_r=0.0025, loss=-0.0055, norm_factor=924.7682, grad_norm=1.4992\n",
      "Epoch 10: 197/256 - loss_mc=-0.0066, loss_t=0.0065, loss_r=0.0024, loss=-0.0057, norm_factor=925.2162, grad_norm=1.3116\n",
      "Epoch 10: 198/256 - loss_mc=-0.0061, loss_t=0.0085, loss_r=0.0029, loss=-0.0049, norm_factor=925.6825, grad_norm=1.5035\n",
      "Epoch 10: 199/256 - loss_mc=-0.0066, loss_t=0.0066, loss_r=0.0024, loss=-0.0057, norm_factor=926.0986, grad_norm=1.1557\n",
      "Epoch 10: 200/256 - loss_mc=-0.0063, loss_t=0.0057, loss_r=0.0026, loss=-0.0055, norm_factor=926.5352, grad_norm=1.5478\n",
      "Epoch 10: 201/256 - loss_mc=-0.0067, loss_t=0.0070, loss_r=0.0025, loss=-0.0057, norm_factor=926.9639, grad_norm=1.3227\n",
      "Epoch 10: 202/256 - loss_mc=-0.0065, loss_t=0.0062, loss_r=0.0024, loss=-0.0057, norm_factor=927.4247, grad_norm=1.8799\n",
      "Epoch 10: 203/256 - loss_mc=-0.0057, loss_t=0.0075, loss_r=0.0034, loss=-0.0046, norm_factor=927.8873, grad_norm=1.3437\n",
      "Epoch 10: 204/256 - loss_mc=-0.0064, loss_t=0.0066, loss_r=0.0024, loss=-0.0055, norm_factor=928.2576, grad_norm=2.1920\n",
      "Epoch 10: 205/256 - loss_mc=-0.0064, loss_t=0.0069, loss_r=0.0026, loss=-0.0054, norm_factor=928.6278, grad_norm=1.6697\n",
      "Epoch 10: 206/256 - loss_mc=-0.0063, loss_t=0.0080, loss_r=0.0027, loss=-0.0052, norm_factor=928.9930, grad_norm=1.7633\n",
      "Epoch 10: 207/256 - loss_mc=-0.0064, loss_t=0.0055, loss_r=0.0027, loss=-0.0056, norm_factor=929.3409, grad_norm=1.3696\n",
      "Epoch 10: 208/256 - loss_mc=-0.0064, loss_t=0.0057, loss_r=0.0027, loss=-0.0056, norm_factor=929.7000, grad_norm=1.5975\n",
      "Epoch 10: 209/256 - loss_mc=-0.0059, loss_t=0.0082, loss_r=0.0024, loss=-0.0049, norm_factor=930.0682, grad_norm=1.3883\n",
      "Epoch 10: 210/256 - loss_mc=-0.0064, loss_t=0.0071, loss_r=0.0025, loss=-0.0055, norm_factor=930.3782, grad_norm=1.3496\n",
      "Epoch 10: 211/256 - loss_mc=-0.0063, loss_t=0.0068, loss_r=0.0025, loss=-0.0054, norm_factor=930.7029, grad_norm=1.2193\n",
      "Epoch 10: 212/256 - loss_mc=-0.0061, loss_t=0.0067, loss_r=0.0039, loss=-0.0051, norm_factor=931.0200, grad_norm=1.6661\n",
      "Epoch 10: 213/256 - loss_mc=-0.0061, loss_t=0.0069, loss_r=0.0024, loss=-0.0052, norm_factor=931.3190, grad_norm=1.0405\n",
      "Epoch 10: 214/256 - loss_mc=-0.0063, loss_t=0.0065, loss_r=0.0026, loss=-0.0054, norm_factor=931.5907, grad_norm=1.5043\n",
      "Epoch 10: 215/256 - loss_mc=-0.0067, loss_t=0.0054, loss_r=0.0022, loss=-0.0059, norm_factor=931.8485, grad_norm=1.2559\n",
      "Epoch 10: 216/256 - loss_mc=-0.0061, loss_t=0.0063, loss_r=0.0025, loss=-0.0052, norm_factor=932.1426, grad_norm=1.8893\n",
      "Epoch 10: 217/256 - loss_mc=-0.0061, loss_t=0.0066, loss_r=0.0024, loss=-0.0052, norm_factor=932.4233, grad_norm=1.4790\n",
      "Epoch 10: 218/256 - loss_mc=-0.0061, loss_t=0.0062, loss_r=0.0020, loss=-0.0053, norm_factor=932.6948, grad_norm=1.5787\n",
      "Epoch 10: 219/256 - loss_mc=-0.0062, loss_t=0.0065, loss_r=0.0026, loss=-0.0053, norm_factor=932.9589, grad_norm=1.0440\n",
      "Epoch 10: 220/256 - loss_mc=-0.0060, loss_t=0.0066, loss_r=0.0028, loss=-0.0051, norm_factor=933.2225, grad_norm=1.3607\n",
      "Epoch 10: 221/256 - loss_mc=-0.0060, loss_t=0.0054, loss_r=0.0030, loss=-0.0051, norm_factor=933.4659, grad_norm=0.8864\n",
      "Epoch 10: 222/256 - loss_mc=-0.0064, loss_t=0.0059, loss_r=0.0023, loss=-0.0056, norm_factor=933.6659, grad_norm=1.5020\n",
      "Epoch 10: 223/256 - loss_mc=-0.0065, loss_t=0.0063, loss_r=0.0024, loss=-0.0056, norm_factor=933.8803, grad_norm=0.7956\n",
      "Epoch 10: 224/256 - loss_mc=-0.0065, loss_t=0.0069, loss_r=0.0022, loss=-0.0056, norm_factor=934.1094, grad_norm=1.4003\n",
      "Epoch 10: 225/256 - loss_mc=-0.0066, loss_t=0.0068, loss_r=0.0022, loss=-0.0057, norm_factor=934.3601, grad_norm=1.0006\n",
      "Epoch 10: 226/256 - loss_mc=-0.0066, loss_t=0.0046, loss_r=0.0022, loss=-0.0059, norm_factor=934.6526, grad_norm=1.3559\n",
      "Epoch 10: 227/256 - loss_mc=-0.0060, loss_t=0.0062, loss_r=0.0023, loss=-0.0051, norm_factor=934.9669, grad_norm=0.9039\n",
      "Epoch 10: 228/256 - loss_mc=-0.0064, loss_t=0.0077, loss_r=0.0028, loss=-0.0054, norm_factor=935.2370, grad_norm=1.2968\n",
      "Epoch 10: 229/256 - loss_mc=-0.0065, loss_t=0.0061, loss_r=0.0024, loss=-0.0057, norm_factor=935.5168, grad_norm=1.0628\n",
      "Epoch 10: 230/256 - loss_mc=-0.0068, loss_t=0.0062, loss_r=0.0021, loss=-0.0060, norm_factor=935.8184, grad_norm=1.4888\n",
      "Epoch 10: 231/256 - loss_mc=-0.0067, loss_t=0.0046, loss_r=0.0022, loss=-0.0060, norm_factor=936.1769, grad_norm=0.6880\n",
      "Epoch 10: 232/256 - loss_mc=-0.0063, loss_t=0.0057, loss_r=0.0022, loss=-0.0055, norm_factor=936.5664, grad_norm=1.4912\n",
      "Epoch 10: 233/256 - loss_mc=-0.0058, loss_t=0.0083, loss_r=0.0026, loss=-0.0047, norm_factor=936.9399, grad_norm=1.1054\n",
      "Epoch 10: 234/256 - loss_mc=-0.0062, loss_t=0.0070, loss_r=0.0024, loss=-0.0053, norm_factor=937.2397, grad_norm=1.1929\n",
      "Epoch 10: 235/256 - loss_mc=-0.0065, loss_t=0.0060, loss_r=0.0028, loss=-0.0056, norm_factor=937.5319, grad_norm=1.5666\n",
      "Epoch 10: 236/256 - loss_mc=-0.0064, loss_t=0.0076, loss_r=0.0025, loss=-0.0054, norm_factor=937.8428, grad_norm=1.4347\n",
      "Epoch 10: 237/256 - loss_mc=-0.0062, loss_t=0.0065, loss_r=0.0028, loss=-0.0053, norm_factor=938.1732, grad_norm=1.8172\n",
      "Epoch 10: 238/256 - loss_mc=-0.0067, loss_t=0.0051, loss_r=0.0021, loss=-0.0060, norm_factor=938.4924, grad_norm=1.0771\n",
      "Epoch 10: 239/256 - loss_mc=-0.0063, loss_t=0.0058, loss_r=0.0024, loss=-0.0055, norm_factor=938.8467, grad_norm=2.1126\n",
      "Epoch 10: 240/256 - loss_mc=-0.0068, loss_t=0.0055, loss_r=0.0020, loss=-0.0061, norm_factor=939.2062, grad_norm=0.9839\n",
      "Epoch 10: 241/256 - loss_mc=-0.0064, loss_t=0.0061, loss_r=0.0026, loss=-0.0055, norm_factor=939.6190, grad_norm=1.5399\n",
      "Epoch 10: 242/256 - loss_mc=-0.0064, loss_t=0.0063, loss_r=0.0025, loss=-0.0055, norm_factor=940.0247, grad_norm=1.4217\n",
      "Epoch 10: 243/256 - loss_mc=-0.0067, loss_t=0.0062, loss_r=0.0021, loss=-0.0058, norm_factor=940.4302, grad_norm=1.3471\n",
      "Epoch 10: 244/256 - loss_mc=-0.0062, loss_t=0.0070, loss_r=0.0025, loss=-0.0053, norm_factor=940.8673, grad_norm=1.5254\n",
      "Epoch 10: 245/256 - loss_mc=-0.0063, loss_t=0.0089, loss_r=0.0024, loss=-0.0051, norm_factor=941.2867, grad_norm=1.7399\n",
      "Epoch 10: 246/256 - loss_mc=-0.0059, loss_t=0.0061, loss_r=0.0026, loss=-0.0050, norm_factor=941.6890, grad_norm=1.3697\n",
      "Epoch 10: 247/256 - loss_mc=-0.0065, loss_t=0.0069, loss_r=0.0022, loss=-0.0056, norm_factor=942.0324, grad_norm=1.6672\n",
      "Epoch 10: 248/256 - loss_mc=-0.0064, loss_t=0.0076, loss_r=0.0024, loss=-0.0054, norm_factor=942.3961, grad_norm=1.5625\n",
      "Epoch 10: 249/256 - loss_mc=-0.0066, loss_t=0.0064, loss_r=0.0022, loss=-0.0057, norm_factor=942.7748, grad_norm=1.3214\n",
      "Epoch 10: 250/256 - loss_mc=-0.0069, loss_t=0.0056, loss_r=0.0020, loss=-0.0061, norm_factor=943.1800, grad_norm=1.4443\n",
      "Epoch 10: 251/256 - loss_mc=-0.0065, loss_t=0.0068, loss_r=0.0022, loss=-0.0056, norm_factor=943.6274, grad_norm=1.4952\n",
      "Epoch 10: 252/256 - loss_mc=-0.0060, loss_t=0.0075, loss_r=0.0026, loss=-0.0050, norm_factor=944.0935, grad_norm=1.4183\n",
      "Epoch 10: 253/256 - loss_mc=-0.0066, loss_t=0.0056, loss_r=0.0022, loss=-0.0059, norm_factor=944.5089, grad_norm=0.9477\n",
      "Epoch 10: 254/256 - loss_mc=-0.0064, loss_t=0.0073, loss_r=0.0025, loss=-0.0054, norm_factor=944.9519, grad_norm=1.1578\n",
      "Epoch 10: 255/256 - loss_mc=-0.0062, loss_t=0.0089, loss_r=0.0027, loss=-0.0050, norm_factor=945.3765, grad_norm=1.7435\n",
      "Epoch 10: 256/256 - loss_mc=-0.0066, loss_t=0.0060, loss_r=0.0022, loss=-0.0057, norm_factor=945.7561, grad_norm=0.9787\n"
     ]
    }
   ],
   "source": [
    "# start training\n",
    "for epoch_id in range(n_epoch):\n",
    "    for iter_id, (batch_in_pose, batch_out_pose) in enumerate(loader):  # for each training step\n",
    "        batch_cam_mats = cam_mats.expand(batch_in_pose.size(0), -1, -1)\n",
    "        _, _, pose_opt_plus, _, pose_sample_logweights, cost_tgt, norm_factor = model.forward_train(\n",
    "            batch_in_pose,\n",
    "            batch_cam_mats,\n",
    "            batch_out_pose)\n",
    "\n",
    "        # monte carlo pose loss\n",
    "        loss_mc = mc_loss_fun(\n",
    "            pose_sample_logweights,\n",
    "            cost_tgt, \n",
    "            norm_factor)\n",
    "\n",
    "        # derivative regularization\n",
    "        dist_t = (pose_opt_plus[:, :3] - batch_out_pose[:, :3]).norm(dim=-1)\n",
    "        beta = 1.0\n",
    "        loss_t = torch.where(dist_t < beta, 0.5 * dist_t.square() / beta,\n",
    "                             dist_t - 0.5 * beta)\n",
    "        loss_t = loss_t.mean()\n",
    "\n",
    "        dot_quat = (pose_opt_plus[:, None, 3:] @ batch_out_pose[:, 3:, None]).squeeze(-1).squeeze(-1)\n",
    "        loss_r = (1 - dot_quat.square()) * 2\n",
    "        loss_r = loss_r.mean()\n",
    "\n",
    "        loss = loss_mc + 0.1 * loss_t + 0.1 * loss_r\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        grad_norm = []\n",
    "        for p in model.parameters():\n",
    "            if (p.grad is None) or (not p.requires_grad):\n",
    "                continue\n",
    "            else:\n",
    "                grad_norm.append(torch.norm(p.grad.detach()))\n",
    "        grad_norm = torch.norm(torch.stack(grad_norm))\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        print('Epoch {}: {}/{} - loss_mc={:.4f}, loss_t={:.4f}, loss_r={:.4f}, loss={:.4f}, norm_factor={:.4f}, grad_norm={:.4f}'.format(\n",
    "            epoch_id + 1, iter_id + 1, len(loader), loss_mc, loss_t, loss_r, loss, norm_factor, grad_norm))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EPro-PnP-rel",
   "language": "python",
   "name": "epro-pnp-rel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}